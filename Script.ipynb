{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import xgboost as xgb\n",
    "\n",
    "import pickle\n",
    "\n",
    "from hyperopt import hp, fmin, tpe\n",
    "\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, RepeatVector, TimeDistributed, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.compat.v1.losses import mean_squared_error\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as TFIDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preparation du text pour l'entrainement du modèle Word2Vec et TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_DF(DF):\n",
    "    DF_help=DF.apply(func = lambda S:S.lower())\n",
    "    DF_help=remplacer_site_DF(DF_help)\n",
    "    DF_help=DF_help.apply(func = lambda S:S.strip())\n",
    "    DF_help=espacer_virgule_DF(DF_help)\n",
    "    DF_help=espacer_parenthèse_DF(DF_help)\n",
    "    DF_help=DF_help.apply(lambda text:text.replace('\"',''))\n",
    "    return prepare_sentences_help(DF_help)\n",
    "\n",
    "def get_longest_feedback(List):\n",
    "    return max([len(l) for l in List])\n",
    "\n",
    "def prepare_sentences_List(DF):\n",
    "    \n",
    "    List=[sentence for paragraph in DF.values.tolist() for sentence in paragraph]\n",
    "    return List\n",
    "\n",
    "def prepare_sentences_help(DF):\n",
    "    DF_help=DF.apply(func = lambda S:[s.split(' ') for s in S.split('.')])\n",
    "    DF_help = DF_help.apply(func = lambda paragraphe : [ [word for word in sentence if not(word in [' ',''])]for sentence in paragraphe ])\n",
    "    DF_help = DF_help.apply(func = lambda paragraphe : [ sentence for sentence in paragraphe if not(sentence in [[' '],['']] or len(sentence)==0) ])\n",
    "    \n",
    "    #DF_help=DF_help.apply(func=lambda paragraph :[ sentence[1:] if sentence[0]=='' else sentence for sentence in paragraph])\n",
    "    return DF_help\n",
    "\n",
    "def remplacer_site(String):       \n",
    "    for index in [m.start() for m in re.finditer('.', String)]:\n",
    "        if String[:index].rfind('http')>String[:index].rfind(' '):\n",
    "            String=String[:index]+'&'+String[index+1:]\n",
    "    return String\n",
    "\n",
    "def remplacer_site_DF(DF):\n",
    "    DF=DF.apply(func= lambda S : remplacer_site(S))\n",
    "    return DF       \n",
    "\n",
    "def espacer_point_DF(DF):\n",
    "    DF=DF.apply(func = lambda S:S.replace('.',' .'))\n",
    "    return DF\n",
    "\n",
    "def espacer_virgule_DF(DF):\n",
    "    DF_help=DF.apply(func = lambda S:S.replace(\",\",\" ,\"))\n",
    "    return DF_help\n",
    "\n",
    "def espacer_parenthèse_DF(DF):\n",
    "    DF=DF.apply(func = lambda S:S.replace('(','( '))\n",
    "    DF=DF.apply(func = lambda S:S.replace(')',' )'))\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Encodage des données textuelles en vecteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generate_dict(sentences,window,size):\n",
    "    model=Word2Vec(sentences, size=size, window=window, min_count=1)\n",
    "    return model\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "cette fonction encode les paragraphe de la colonne feedback sous la forme d'une suite de vecteurs encodant chacun une phrase,\n",
    "l'encodage d'une phrase est obtenue grâce à la moyenne des encodages des mots composant la phrase, ces encodages étant pondérés\n",
    "par le coéfficient tf-idf des mots.\n",
    "\"\"\"\n",
    "\n",
    "def sentence_2v(DF,dico,tfidf,size_embeding, size_paragraph):\n",
    "    DF_bis=DF.apply(func = sentence_2V_help , dico=dico, tfidf=tfidf, size_embeding=size_embeding, size_paragraph=size_paragraph) \n",
    "    return DF_bis\n",
    "\n",
    "def sentence_2V_help(paragraphe,dico,tfidf,size_embeding,size_paragraph):\n",
    "    vectorized_paragraphe=[]\n",
    "    for sentence in paragraphe:\n",
    "        \n",
    "        freq_vec=tfidf.transform([' '.join(sentence)])\n",
    "        vocab = tfidf.vocabulary_\n",
    "        word_coord=dict((word,vocab[word]) for word in sentence )\n",
    "        vectorized_paragraphe.append(np.average([freq_vec[0,word_coord[word]]*dico.get_vector(word) for word in sentence], axis=0))    \n",
    "    vectorized_paragraphe=np.stack(vectorized_paragraphe+[np.zeros(size_embeding) for i in range (size_paragraph-len(paragraphe))],axis=0)\n",
    "    return vectorized_paragraphe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Construction d'un modèle d'analyse de sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_model_sentiment( size_encoding, max_legnth_para, numClasses, lstmUnits):\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(LSTM(120,input_shape=(max_legnth_para,size_encoding), activation='relu', return_sequences=True ))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(120,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(50,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(numClasses,activation='sigmoid'))\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n",
    "\n",
    "    model.compile(\n",
    "                loss='mean_squared_error',\n",
    "                optimizer=opt,\n",
    "                metrics=['mean_absolute_error'],)\n",
    "    model=model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Construction d'un autoencodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_auto(input_shape, code_size):\n",
    "    input_img = Input(shape=(input_shape,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = Dense(code_size, activation='relu')(input_img)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = Dense(input_shape, activation='sigmoid')(encoded)\n",
    "    \n",
    "    autoencoder = Model(input_img,decoded)\n",
    "    encoder = Model(input_img, encoded)\n",
    "    \n",
    "    encoded_input = Input(shape=(code_size,))\n",
    "    decoder_layer = autoencoder.layers[-1]\n",
    "    decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
    "    \n",
    "    return autoencoder,encoder,decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Construction d'un autoencoder sequentiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_seq_auto(size_sequence, size_embeding, code_size):\n",
    "    input_img = Input(shape=(size_sequence, size_embeding))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    encoded = LSTM(code_size, activation='relu')(input_img)\n",
    "    # \"decoded\" is the lossy reconstruction of the input\n",
    "    decoded = RepeatVector(size_sequence)(encoded)\n",
    "    decoded = LSTM(input_shape, activation='sigmoid', return_sequences= True)(decoded)\n",
    "    decoded = TimeDistributed(Dense(size_embeding))(decoded)\n",
    "    \n",
    "    autoencoder = Model(input_img,decoded)\n",
    "    encoder = Model(input_img, encoded)\n",
    "    \n",
    "    encoded_input = Input(shape=(code_size,))\n",
    "    Layers=autoencoder.layers[-3:]\n",
    "    Layers.reverse()\n",
    "    decoder_layer = list_to_nn(Layers,encoded_input)\n",
    "    decoder = Model(encoded_input, decoder_layer)\n",
    "    \n",
    "    return autoencoder,encoder,decoder\n",
    "\n",
    "def list_to_nn(Layers,inputLayer):\n",
    "    if Layers==[]:\n",
    "        return inputLayer\n",
    "    else :\n",
    "        return Layers[0](list_to_nn(Layers[1:],inputLayer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Construction du modèle de recommendation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_model_recomendation(input_shape, output_shape, size_L1, size_L2, size_L3,size_L4):\n",
    "    input_img = Input(shape = (input_shape,))\n",
    "    # \"encoded\" is the encoded representation of the input\n",
    "    Layer1 = Dense(size_L1, activation = 'relu')(input_img)\n",
    "    Dropout_Layer1 = Dropout(0.1)(Layer1)\n",
    "    Layer2 = Dense(size_L2, activation = 'relu')(Dropout_Layer1)\n",
    "    Dropout_Layer2=Dropout(0.1)(Layer2)\n",
    "    Layer3 = Dense(size_L3, activation = 'relu')(Dropout_Layer2)\n",
    "    Dropout_Layer3=Dropout(0.1)(Layer3)\n",
    "    Layer4 = Dense(size_L3, activation = 'relu')(Dropout_Layer3)\n",
    "    output= Dense(output_shape, activation='softmax')(Layer4)\n",
    "\n",
    "    model = Model(input_img, output)\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Extraction de la donnée textuelle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_info=pd.read_csv('band_content.csv', header = 0).drop(['biography_en'], axis=1)\n",
    "influencer_info=pd.read_csv('influencer_content.csv', header = 0).drop(['description_en','preferences_en'], axis=1)\n",
    "submission=pd.read_csv('submission_history.csv', header = 0)\n",
    "\n",
    "band_info['biography_fr']=band_info['biography_fr'].fillna('').apply(func = lambda R : R.replace('\\n',''))\n",
    "influencer_info['description_fr']=influencer_info['description_fr'].fillna('').apply(func = lambda R : R.replace('\\n',' '))\n",
    "influencer_info['preferences_fr']=influencer_info['preferences_fr'].fillna('').apply(func = lambda R : R.replace('\\n',' '))\n",
    "submission['influencer_feedback']=submission['influencer_feedback'].fillna('').apply(func = lambda R : R.replace('\\n',''))\n",
    "\n",
    "band_info['biography_fr']=prepare_DF(band_info['biography_fr'])\n",
    "influencer_info['description_fr']=prepare_DF(influencer_info['description_fr'])\n",
    "influencer_info['preferences_fr']=prepare_DF(influencer_info['preferences_fr'])\n",
    "submission['influencer_feedback']=prepare_DF(submission['influencer_feedback'])\n",
    "\n",
    "band_bio=band_info['biography_fr']\n",
    "band_bio.columns=['text']\n",
    "influencer_bio=influencer_info['description_fr']\n",
    "influencer_bio.columns=['text']\n",
    "influencer_pref=influencer_info['preferences_fr']\n",
    "influencer_pref.columns=['text']\n",
    "submission_feedback=submission['influencer_feedback']\n",
    "submission_feedback.columns=['text']\n",
    "text=pd.concat([band_bio, influencer_bio, influencer_pref, submission_feedback], keys=['band_bio', 'influ_bio', 'influ_pref','feedback'])\n",
    "List_sentences=prepare_sentences_List(text)\n",
    "List_sentences_tfidf=[' '.join(sentence) for sentence in List_sentences]\n",
    "\n",
    "\n",
    "Max_size_band_bio=max(text.loc['band_bio'].apply(func = lambda L : len(L)))\n",
    "Max_size_influencer_bio=max(text.loc['influ_bio'].apply(func = lambda L : len(L)))\n",
    "Max_size_influencer_pref=max(text.loc['influ_pref'].apply(func = lambda L : len(L)))\n",
    "Max_size_feedback=max(text.loc['feedback'].apply(func = lambda L : len(L)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Création et entraînement des modèles de vectorisation du text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "window_size=2\n",
    "embeding_size=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function tokenizer at 0x000000001ACE8C18>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dico = generate_dict(List_sentences, window_size, embeding_size)\n",
    "Dico = dico.wv\n",
    "\n",
    "def tokenizer(string):\n",
    "    return string.split(\" \")\n",
    "\n",
    "tfidf = TFIDF(analyzer = 'word', tokenizer = tokenizer)\n",
    "tfidf.fit(List_sentences_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Sauvegardede du dictionnaire word2vec et du modèle tf-idf\"\"\"\n",
    "fname = get_tmpfile(\"wordvectors.kv\")\n",
    "Dico.save(fname)\n",
    "\n",
    "with open('tfidf.pk', 'wb') as fin:\n",
    "    pickle.dump(tfidf, fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chargement du dictionnaire word2vec\n",
    "\"\"\"\n",
    "fname = get_tmpfile(\"wordvectors.kv\")\n",
    "Dico = KeyedVectors.load(fname, mmap='r')\n",
    "\n",
    "with open('tfidf.pk', 'rb') as fout:\n",
    "    tfidf = pickle.load(fout) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Passage du text aux vecteurs\n",
    "band_info['biography_fr'] = sentence_2v(band_info['biography_fr'],Dico,tfidf,embeding_size,Max_size_band_bio)\n",
    "influencer_info['description_fr'] = sentence_2v(influencer_info['description_fr'],Dico,tfidf,embeding_size,Max_size_influencer_bio)\n",
    "influencer_info['preferences_fr'] = sentence_2v(influencer_info['preferences_fr'],Dico,tfidf,embeding_size,Max_size_influencer_pref)\n",
    "submission['influencer_feedback'] = sentence_2v(submission['influencer_feedback'],Dico,tfidf,embeding_size,Max_size_feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sauvegarde de la version vectorisée de la donnée textuelle\n",
    "band_info.to_pickle('band_info_Vectorized_text.csv')\n",
    "influencer_info.to_pickle('influencer_info_Vectorized_text.csv')\n",
    "submission.to_pickle('submission_Vectorized_text.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Stacking: encodage du feedback des influenceurs par la sortie d'un modèle d'analyse de sentiment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "num_Lstm=10\n",
    "num_class=1\n",
    "embeding_size=40\n",
    "Xtrain=np.stack(submission['influencer_feedback'].tolist(),axis=0)\n",
    "Ytrain=np.stack(submission['score'].tolist(),axis=0)\n",
    "Model_sentiment=build_model_sentiment(embeding_size, Max_size_feedback, num_class, num_Lstm)\n",
    "Model_sentiment.fit(Xtrain,Ytrain , epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sauvegarde du modèle\n",
    "\"\"\"\n",
    "\n",
    "json_config = Model_sentiment.to_json()\n",
    "with open('model_sentiment_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# Save weights to disk\n",
    "Model_sentiment.save_weights('Models/model_sentiment_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chargement du modèle\n",
    "\"\"\"\n",
    "with open('model_sentiment_config.json') as json_file:\n",
    "    json_config = json_file.read()\n",
    "Model_sentiment = tf.keras.models.model_from_json(json_config)\n",
    "Model_sentiment.load_weights('Models/model_sentiment_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Encodage du feedback grace au modèle d'analyse de sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "submission['influencer_feedback']=Model_sentiment.predict(np.stack(submission['influencer_feedback'].values.tolist()))\n",
    "submission.to_pickle('submission_stacked.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodage des données grâce aux autoencodeurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_info=pd.read_pickle('band_info_Vectorized_text.csv')\n",
    "band_bio=band_info['biography_fr']\n",
    "influencer_info=pd.read_pickle('influencer_info_Vectorized_text.csv')\n",
    "influencer_bio=influencer_info['description_fr']\n",
    "submission=pd.read_pickle('submission_stacked.csv')\n",
    "\n",
    "Max_size_band_bio=band_info['biography_fr'].iloc[0].shape[0]\n",
    "Max_size_influencer_bio=influencer_info['description_fr'].iloc[0].shape[0]\n",
    "Max_size_influencer_pref=influencer_info['preferences_fr'].iloc[0].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Données non séquentielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Données représentant les artistes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Création du modèle et des données de travail\n",
    "\"\"\"\n",
    "band_non_seq=band_info.drop(labels = ['id','band_id','biography_fr'], axis = 1)\n",
    "Data_band=band_non_seq.values\n",
    "input_shape=band_non_seq.shape[1]\n",
    "code_size_band=20\n",
    "\n",
    "band_auto,band_encoder,band_decoder= build_auto(input_shape,code_size_band)\n",
    "band_auto.compile(optimizer='adam', loss='binary_crossentropy',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#cross_val_score(band_auto, Data, Data, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9502 samples\n",
      "Epoch 1/2\n",
      "9502/9502 [==============================] - 3s 364us/sample - loss: 0.3414 - mean_absolute_error: 0.2407\n",
      "Epoch 2/2\n",
      "9502/9502 [==============================] - 1s 71us/sample - loss: 0.1309 - mean_absolute_error: 0.0805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x3033fdbc8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Entraînement du modèle\n",
    "\"\"\"\n",
    "band_auto.fit(Data_band, Data_band,\n",
    "                epochs=2,\n",
    "                batch_size=20,\n",
    "                shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sauvegarde du modèle\n",
    "\"\"\"\n",
    "json_config = band_encoder.to_json()\n",
    "with open('Models/band_encoder_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# Save weights to disk\n",
    "band_encoder.save_weights('Models/band_encoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chargement du modèle\n",
    "\"\"\"\n",
    "with open('Models/band_encoder_config.json') as json_file:\n",
    "    json_config = json_file.read()\n",
    "band_encoder = tf.keras.models.model_from_json(json_config)\n",
    "band_encoder.load_weights('Models/band_encoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_data_band = np.hstack((band_info['band_id'].values[...,np.newaxis],band_encoder.predict(np.stack(band_non_seq.values.tolist()))))\n",
    "encoded_band = pd.DataFrame(encoded_data_band,columns=['band_id']+['Varirabl_band_'+str(i) for i in  range (code_size_band)])\n",
    "encoded_band['band_id'] = encoded_band['band_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Données représentant les influenceurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Création du modèle et des données de travail\n",
    "\"\"\"\n",
    "influencer_non_seq=influencer_info.drop(labels = ['id','influencer_id','description_fr','preferences_fr'], axis = 1)\n",
    "Data=band_non_seq.values\n",
    "input_shape=band_non_seq.shape[1]\n",
    "code_size_influ=20\n",
    "\n",
    "influencer_auto,influencer_encoder,influencer_decoder= build_auto(input_shape,code_size_influ)\n",
    "influencer_auto.compile(optimizer='adam', loss='binary_crossentropy',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9502 samples\n",
      "Epoch 1/2\n",
      "9502/9502 [==============================] - 6s 668us/sample - loss: 0.3420 - mean_absolute_error: 0.2423\n",
      "Epoch 2/2\n",
      "9502/9502 [==============================] - 1s 79us/sample - loss: 0.1315 - mean_absolute_error: 0.0807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x61dab0ac8>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Entraînement du modèle\n",
    "\"\"\"\n",
    "influencer_auto.fit(Data, Data,\n",
    "                epochs=2,\n",
    "                batch_size=20,\n",
    "                shuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sauvegarde du modèle\n",
    "\"\"\"\n",
    "json_config = influencer_encoder.to_json()\n",
    "with open('influencer_encoder_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# Save weights to disk\n",
    "influencer_encoder.save_weights('Models/influencer_encoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Chargement du modèle\n",
    "\"\"\"\n",
    "with open('influencer_encoder_config.json') as json_file:\n",
    "    json_config = json_file.read()\n",
    "influencer_encoder = tf.keras.models.model_from_json(json_config)\n",
    "influencer_encoder.load_weights('Models/influencer_encoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_data_influencer = np.hstack((influencer_info['influencer_id'].values[...,np.newaxis],influencer_encoder.predict(np.stack(influencer_non_seq.values.tolist()))))\n",
    "encoded_influencer = pd.DataFrame(encoded_data_influencer,columns=['influencer_id']+['Varirabl_influencer_'+str(i) for i in  range (code_size_influ)])\n",
    "encoded_influencer['influencer_id'] = encoded_influencer['influencer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données séquentielles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boigraphie des artiste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'tensorflow.python.keras.layers.recurrent_v2.LSTM'>, <class 'tensorflow.python.keras.layers.core.RepeatVector'>]\n",
      "[<class 'tensorflow.python.keras.layers.core.RepeatVector'>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Création du modèle et des données de travail\n",
    "\"\"\"\n",
    "band_bio=band_info['biography_fr']\n",
    "Data=np.stack(band_bio.tolist(),axis=0)\n",
    "size_sequence=Max_size_band_bio\n",
    "embeding_size=40\n",
    "code_size_seq_band=100\n",
    "\n",
    "band_seq_auto,band_seq_encoder,band_seq_decoder=build_seq_auto(size_sequence,embeding_size,code_size_seq_band)\n",
    "band_seq_auto.compile(optimizer='adam', loss='mse',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9502 samples\n",
      "Epoch 1/2\n",
      "9502/9502 [==============================] - 124s 13ms/sample - loss: 0.0018 - mean_absolute_error: 0.0062\n",
      "Epoch 2/2\n",
      "9502/9502 [==============================] - 124s 13ms/sample - loss: 0.0018 - mean_absolute_error: 0.0062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x6c8a0dc8>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Entraînement du modèle\n",
    "\"\"\"\n",
    "auto.fit(Data, Data,\n",
    "                epochs=2,\n",
    "                batch_size=10,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sauvegarde du modèle\n",
    "\"\"\"\n",
    "json_config = band_seq_encoder.to_json()\n",
    "with open('Models/band_seq_encoder_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# Save weights to disk\n",
    "band_seq_encoder.save_weights('Models/band_seq_encoder_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Chargement du modèle\n",
    "\"\"\"\n",
    "with open('Models/band_seq_encoder_config.json') as json_file:\n",
    "    json_config = json_file.read()\n",
    "band_seq_encoder = tf.keras.models.model_from_json(json_config)\n",
    "band_seq_encoder.load_weights('Models/band_seq_encoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_band_bio = np.hstack((band_info['band_id'].values[..., np.newaxis], band_seq_encoder.predict(np.stack(band_bio.values.tolist()))))\n",
    "encoded_band_bio = pd.DataFrame(encoded_data_band_bio, columns=['band_id']+['Varirabl_desc_'+str(i) for i in  range (code_size_seq_band)])\n",
    "encoded_band_bio['bandr_id'] = encoded_band_bio['band_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptions des influenceurs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'tensorflow.python.keras.layers.recurrent_v2.LSTM'>, <class 'tensorflow.python.keras.layers.core.RepeatVector'>]\n",
      "[<class 'tensorflow.python.keras.layers.core.RepeatVector'>]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Création du modèle et des données de travail\n",
    "\"\"\"\n",
    "influencer_bio=influencer_info['description_fr']\n",
    "Data=np.stack(influencer_bio.tolist(),axis=0)\n",
    "size_sequence=Max_size_influencer_bio\n",
    "embeding_size=40\n",
    "code_size=100\n",
    "\n",
    "influencer_seq_auto,influencer_seq_encode,influencer_seq_decode=build_seq_auto(size_sequence,embeding_size,code_size)\n",
    "influencer_seq_auto.compile(optimizer='adam', loss='mse',metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1073 samples\n",
      "Epoch 1/2\n",
      "1073/1073 [==============================] - 7s 6ms/sample - loss: 0.0115 - mean_absolute_error: 0.0444\n",
      "Epoch 2/2\n",
      "1073/1073 [==============================] - 5s 5ms/sample - loss: 0.0066 - mean_absolute_error: 0.0255 1s - loss: 0.0068 - mean_a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x508faa88>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Entraînement du modèle\n",
    "\"\"\"\n",
    "influencer_seq_auto.fit(Data, Data,\n",
    "                epochs=2,\n",
    "                batch_size=10,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sauvegarde du modèle\n",
    "\"\"\"\n",
    "json_config = influencer_seq_encode.to_json()\n",
    "with open('Models/influencer_seq_encoder_config.json', 'w') as json_file:\n",
    "    json_file.write(json_config)\n",
    "# Save weights to disk\n",
    "influencer_seq_encode.save_weights('Models/influencer_seq_encoder_weights.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Chargement du modèle\n",
    "\"\"\"\n",
    "with open('Models/influencer_seq_encoder_config.json') as json_file:\n",
    "    json_config = json_file.read()\n",
    "influencer_seq_encode = tf.keras.models.model_from_json(json_config)\n",
    "influencer_seq_encode.load_weights('Models/influencer_seq_encoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_influencer_desc = np.hstack((influencer_info['influencer_id'].values[...,np.newaxis],influencer_seq_encode.predict(np.stack(influencer_bio.values.tolist()))))\n",
    "encoded_influencer_desc = pd.DataFrame(encoded_data_influencer_desc, columns=['influencer_id']+['Varirabl_desc_'+str(i) for i in  range (code_size)])\n",
    "encoded_influencer_desc['influencer_id'] = encoded_influencer_desc['influencer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Concatenation des données séquentielles et non séquentielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "On concatène les tableaux contenant l'encodage des données non séquentille à ceux qui contiennent l'encodage des données\n",
    "séquentielles.  \n",
    "\"\"\"\n",
    "encoded_influencer=pd.merge(encoded_influencer, encoded_influencer_desc, on = 'influencer_id')\n",
    "encoded_band=pd.merge(encoded_band, encoded_band_bio, on = 'band_id')\n",
    "\n",
    "encoded_band.to_pickle('encoded_band.csv')\n",
    "encoded_influencer.to_pickle('encoded_influencer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prédiction du score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tentative de classification en utilisant XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_band = pd.read_pickle('encoded_band.csv')\n",
    "encoded_influencer = pd.read_pickle('encoded_influencer.csv')\n",
    "\n",
    "submission = pd.read_pickle('submission_stacked.csv')[['score', 'band_id', 'influencer_id']]\n",
    "one_hot_score = pd.get_dummies(submission['score'],prefix='score')\n",
    "submission = pd.concat([submission,one_hot_score], axis = 1, sort = False).drop('score', axis = 1)\n",
    "\n",
    "Data = submission.merge(encoded_band, on = ['band_id'], how = 'left')\n",
    "Data = Data.merge(encoded_influencer, on = ['influencer_id'], how = 'left')\n",
    "\n",
    "\n",
    "X=Data.drop(['band_id','influencer_id','score_0.0', 'score_0.25', 'score_0.5', 'score_1.0'], axis = 1)\n",
    "Y=Data[['score_0.0', 'score_0.25', 'score_0.5','score_1.0']]\n",
    "#Y=Data['score']\n",
    "#X=Data.drop(['band_id','influencer_id','score'], axis = 1)\n",
    "             \n",
    "Xtest=X.iloc[70000:]\n",
    "Ytest=Y.iloc[70000:]\n",
    "\n",
    "X=X.iloc[:70000]\n",
    "Y=Y.iloc[:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def hyperopt_obj_XGB(params):\n",
    "    max_depth=params['max_depth']\n",
    "    learning_rate=params['learning_rate']\n",
    "    n_estimators=params['n_estimators']\n",
    "    min_child_weight=params['min_child_weight']\n",
    "    model = xgb.XGBClassifier(objective = 'multi:softmax', num_class=4, \n",
    "                              max_depth = max_depth, \n",
    "                              learning_rate = 1/learning_rate,\n",
    "                              n_estimators = n_estimators,\n",
    "                              min_child_weight = min_child_weight,\n",
    "                              )\n",
    "    model.fit(X=X.values, y=Y.values, eval_set=[(Xtest.values,Ytest.values)])\n",
    "    \n",
    "    res = model.evals_result()\n",
    "    del model\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[1]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[2]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[3]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[4]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[5]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[6]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[7]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[8]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[9]\tvalidation_0-merror:0.34525                                                \n",
      "\n",
      "[10]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[11]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[12]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[13]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[14]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[15]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[16]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[17]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[18]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[19]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[20]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[21]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[22]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[23]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[24]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[25]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[26]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[27]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[28]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[29]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[30]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[31]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[32]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[33]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[34]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[35]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[36]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[37]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[38]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[39]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[40]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[41]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[42]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[43]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[44]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[45]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[46]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[47]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[48]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[49]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[50]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[51]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[52]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[53]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[54]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[55]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[56]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[57]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[58]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[59]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[60]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[61]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[62]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[63]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[64]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[65]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[66]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[67]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[68]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[69]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[70]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[71]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[72]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[73]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[74]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[75]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[76]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[77]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[78]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[79]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[80]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[81]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[82]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[83]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[84]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[85]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[86]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[87]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[88]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[89]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[90]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[91]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[92]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[93]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[94]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[95]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[96]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[97]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[98]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[99]\tvalidation_0-merror:0.34525                                               \n",
      "\n",
      "[100]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "[101]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "[102]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "[103]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "[104]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "[105]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "[106]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "[107]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "[108]\tvalidation_0-merror:0.34525                                              \n",
      "\n",
      "  0%|                                     | 0/30 [11:40<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'status'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6697a79cabcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     'min_child_weight':hp.choice('min_child_weight', [i for i in range (1,10)])}\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperopt_obj_XGB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    420\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[0;32m    421\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    239\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                         \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mdict_rval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_rval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mSTATUS_STRINGS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mInvalidResultStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'status'"
     ]
    }
   ],
   "source": [
    "space={'max_depth':hp.choice('max_depth', [i for i in range(2,11)]),\n",
    "    'learning_rate':hp.loguniform('learning_rate', 10, 10000),\n",
    "    'n_estimators':hp.choice('n_estimators', [i for i in range (50,150)]),\n",
    "    'min_child_weight':hp.choice('min_child_weight', [i for i in range (1,10)])}\n",
    "fmin(hyperopt_obj_XGB, space = space, algo=tpe.suggest, max_evals=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.324092\n",
      "[1]\tvalidation_0-merror:0.318328\n",
      "[2]\tvalidation_0-merror:0.312564\n",
      "[3]\tvalidation_0-merror:0.300744\n",
      "[4]\tvalidation_0-merror:0.303517\n",
      "[5]\tvalidation_0-merror:0.302787\n",
      "[6]\tvalidation_0-merror:0.29768\n",
      "[7]\tvalidation_0-merror:0.300817\n",
      "[8]\tvalidation_0-merror:0.298701\n",
      "[9]\tvalidation_0-merror:0.298701\n",
      "[10]\tvalidation_0-merror:0.291697\n",
      "[11]\tvalidation_0-merror:0.29177\n",
      "[12]\tvalidation_0-merror:0.29177\n",
      "[13]\tvalidation_0-merror:0.29177\n",
      "[14]\tvalidation_0-merror:0.29177\n",
      "[15]\tvalidation_0-merror:0.292135\n",
      "[16]\tvalidation_0-merror:0.291478\n",
      "[17]\tvalidation_0-merror:0.292208\n",
      "[18]\tvalidation_0-merror:0.292281\n",
      "[19]\tvalidation_0-merror:0.29177\n",
      "[20]\tvalidation_0-merror:0.291551\n",
      "[21]\tvalidation_0-merror:0.291113\n",
      "[22]\tvalidation_0-merror:0.29177\n",
      "[23]\tvalidation_0-merror:0.291113\n",
      "[24]\tvalidation_0-merror:0.291332\n",
      "[25]\tvalidation_0-merror:0.289216\n",
      "[26]\tvalidation_0-merror:0.285058\n",
      "[27]\tvalidation_0-merror:0.285131\n",
      "[28]\tvalidation_0-merror:0.282212\n",
      "[29]\tvalidation_0-merror:0.281628\n",
      "[30]\tvalidation_0-merror:0.284912\n",
      "[31]\tvalidation_0-merror:0.285058\n",
      "[32]\tvalidation_0-merror:0.280972\n",
      "[33]\tvalidation_0-merror:0.281045\n",
      "[34]\tvalidation_0-merror:0.281045\n",
      "[35]\tvalidation_0-merror:0.278418\n",
      "[36]\tvalidation_0-merror:0.278126\n",
      "[37]\tvalidation_0-merror:0.276448\n",
      "[38]\tvalidation_0-merror:0.276011\n",
      "[39]\tvalidation_0-merror:0.276156\n",
      "[40]\tvalidation_0-merror:0.276229\n",
      "[41]\tvalidation_0-merror:0.276011\n",
      "[42]\tvalidation_0-merror:0.275865\n",
      "[43]\tvalidation_0-merror:0.275719\n",
      "[44]\tvalidation_0-merror:0.274697\n",
      "[45]\tvalidation_0-merror:0.274697\n",
      "[46]\tvalidation_0-merror:0.275208\n",
      "[47]\tvalidation_0-merror:0.274478\n",
      "[48]\tvalidation_0-merror:0.273895\n",
      "[49]\tvalidation_0-merror:0.274114\n",
      "[50]\tvalidation_0-merror:0.271414\n",
      "[51]\tvalidation_0-merror:0.27032\n",
      "[52]\tvalidation_0-merror:0.270247\n",
      "[53]\tvalidation_0-merror:0.270611\n",
      "[54]\tvalidation_0-merror:0.270684\n",
      "[55]\tvalidation_0-merror:0.269663\n",
      "[56]\tvalidation_0-merror:0.268423\n",
      "[57]\tvalidation_0-merror:0.262513\n",
      "[58]\tvalidation_0-merror:0.257406\n",
      "[59]\tvalidation_0-merror:0.257333\n",
      "[60]\tvalidation_0-merror:0.256895\n",
      "[61]\tvalidation_0-merror:0.257333\n",
      "[62]\tvalidation_0-merror:0.235444\n",
      "[63]\tvalidation_0-merror:0.23756\n",
      "[64]\tvalidation_0-merror:0.234642\n",
      "[65]\tvalidation_0-merror:0.23435\n",
      "[66]\tvalidation_0-merror:0.234204\n",
      "[67]\tvalidation_0-merror:0.23311\n",
      "[68]\tvalidation_0-merror:0.232526\n",
      "[69]\tvalidation_0-merror:0.234496\n",
      "[70]\tvalidation_0-merror:0.23435\n",
      "[71]\tvalidation_0-merror:0.234496\n",
      "[72]\tvalidation_0-merror:0.23362\n",
      "[73]\tvalidation_0-merror:0.233693\n",
      "[74]\tvalidation_0-merror:0.23238\n",
      "[75]\tvalidation_0-merror:0.23165\n",
      "[76]\tvalidation_0-merror:0.233183\n",
      "[77]\tvalidation_0-merror:0.233183\n",
      "[78]\tvalidation_0-merror:0.232964\n",
      "[79]\tvalidation_0-merror:0.233256\n",
      "[80]\tvalidation_0-merror:0.233256\n",
      "[81]\tvalidation_0-merror:0.23311\n",
      "[82]\tvalidation_0-merror:0.233256\n",
      "[83]\tvalidation_0-merror:0.233037\n",
      "[84]\tvalidation_0-merror:0.232891\n",
      "[85]\tvalidation_0-merror:0.23311\n",
      "[86]\tvalidation_0-merror:0.233037\n",
      "[87]\tvalidation_0-merror:0.233183\n",
      "[88]\tvalidation_0-merror:0.232453\n",
      "[89]\tvalidation_0-merror:0.232599\n",
      "[90]\tvalidation_0-merror:0.232015\n",
      "[91]\tvalidation_0-merror:0.232161\n",
      "[92]\tvalidation_0-merror:0.232453\n",
      "[93]\tvalidation_0-merror:0.232234\n",
      "[94]\tvalidation_0-merror:0.232453\n",
      "[95]\tvalidation_0-merror:0.231942\n",
      "[96]\tvalidation_0-merror:0.231869\n",
      "[97]\tvalidation_0-merror:0.230848\n",
      "[98]\tvalidation_0-merror:0.230775\n",
      "[99]\tvalidation_0-merror:0.230848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, num_class=4, objective='multi:softprob',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "              seed=None, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(objective = 'multi:softmax', num_class=4)\n",
    "model.fit(X=X.values, y=Y.values, eval_set=[(Xtest.values,Ytest.values)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tentative de classification en utilisant un réseau de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "encoded_band = pd.read_pickle('encoded_band.csv')\n",
    "encoded_influencer = pd.read_pickle('encoded_influencer.csv')\n",
    "\n",
    "submission = pd.read_pickle('submission_stacked.csv')[['score', 'band_id', 'influencer_id']]\n",
    "one_hot_score = pd.get_dummies(submission['score'],prefix='score')\n",
    "submission = pd.concat([submission,one_hot_score], axis = 1, sort = False).drop('score', axis = 1)\n",
    "\n",
    "Data = submission.merge(encoded_band, on = ['band_id'], how = 'left')\n",
    "Data = Data.merge(encoded_influencer, on = ['influencer_id'], how = 'left')\n",
    "\n",
    "\n",
    "X=Data.drop(['band_id','influencer_id','score_0.0', 'score_0.25', 'score_0.5', 'score_1.0'], axis = 1)\n",
    "Y=Data[['score_0.0', 'score_0.25', 'score_0.5','score_1.0']]\n",
    "#Y=Data['score']\n",
    "#X=Data.drop(['band_id','influencer_id','score'], axis = 1)\n",
    "             \n",
    "Xtest=X.iloc[70000:]\n",
    "Ytest=Y.iloc[70000:]\n",
    "\n",
    "X=X.iloc[:70000]\n",
    "Y=Y.iloc[:70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_shape = X.shape[1]\n",
    "size_L1 = 341\n",
    "size_L2 = 200\n",
    "size_L3 = 100\n",
    "size_L4 = 50\n",
    "output_shape = 4\n",
    "\n",
    "learning_rate = 0.1\n",
    "momentum = 0.05 \n",
    "epoch = 50 \n",
    "decay_rate=learning_rate/epoch\n",
    "sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
    "\n",
    "\n",
    "Model_reco = build_model_recomendation(input_shape, output_shape, size_L1, size_L2, size_L3, size_L4)\n",
    "Model_reco.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 70000 samples\n",
      "Epoch 1/50\n",
      "70000/70000 [==============================] - ETA: 8s - loss: 6.6084 - accuracy: 0.59 - ETA: 4s - loss: 6.0174 - accuracy: 0.62 - ETA: 4s - loss: 5.8310 - accuracy: 0.63 - ETA: 5s - loss: 5.9567 - accuracy: 0.63 - ETA: 4s - loss: 5.9273 - accuracy: 0.63 - ETA: 4s - loss: 5.8195 - accuracy: 0.63 - ETA: 4s - loss: 5.8656 - accuracy: 0.63 - ETA: 4s - loss: 5.8950 - accuracy: 0.63 - ETA: 4s - loss: 5.8675 - accuracy: 0.63 - ETA: 4s - loss: 5.8855 - accuracy: 0.63 - ETA: 4s - loss: 5.9057 - accuracy: 0.63 - ETA: 4s - loss: 5.8841 - accuracy: 0.63 - ETA: 4s - loss: 5.9028 - accuracy: 0.63 - ETA: 4s - loss: 5.9028 - accuracy: 0.63 - ETA: 4s - loss: 5.8527 - accuracy: 0.63 - ETA: 4s - loss: 5.8296 - accuracy: 0.63 - ETA: 4s - loss: 5.8305 - accuracy: 0.63 - ETA: 4s - loss: 5.8453 - accuracy: 0.63 - ETA: 3s - loss: 5.8336 - accuracy: 0.63 - ETA: 3s - loss: 5.8343 - accuracy: 0.63 - ETA: 3s - loss: 5.8433 - accuracy: 0.63 - ETA: 3s - loss: 5.8230 - accuracy: 0.63 - ETA: 3s - loss: 5.8349 - accuracy: 0.63 - ETA: 3s - loss: 5.8430 - accuracy: 0.63 - ETA: 3s - loss: 5.8262 - accuracy: 0.63 - ETA: 3s - loss: 5.8226 - accuracy: 0.63 - ETA: 3s - loss: 5.8312 - accuracy: 0.63 - ETA: 3s - loss: 5.8328 - accuracy: 0.63 - ETA: 3s - loss: 5.8231 - accuracy: 0.63 - ETA: 3s - loss: 5.8315 - accuracy: 0.63 - ETA: 3s - loss: 5.8269 - accuracy: 0.63 - ETA: 3s - loss: 5.8303 - accuracy: 0.63 - ETA: 3s - loss: 5.8273 - accuracy: 0.63 - ETA: 3s - loss: 5.8112 - accuracy: 0.63 - ETA: 3s - loss: 5.8335 - accuracy: 0.63 - ETA: 3s - loss: 5.8276 - accuracy: 0.63 - ETA: 3s - loss: 5.8269 - accuracy: 0.63 - ETA: 3s - loss: 5.8257 - accuracy: 0.63 - ETA: 3s - loss: 5.8205 - accuracy: 0.63 - ETA: 3s - loss: 5.8212 - accuracy: 0.63 - ETA: 2s - loss: 5.8378 - accuracy: 0.63 - ETA: 2s - loss: 5.8410 - accuracy: 0.63 - ETA: 2s - loss: 5.8419 - accuracy: 0.63 - ETA: 2s - loss: 5.8426 - accuracy: 0.63 - ETA: 2s - loss: 5.8422 - accuracy: 0.63 - ETA: 2s - loss: 5.8442 - accuracy: 0.63 - ETA: 2s - loss: 5.8438 - accuracy: 0.63 - ETA: 2s - loss: 5.8399 - accuracy: 0.63 - ETA: 2s - loss: 5.8335 - accuracy: 0.63 - ETA: 2s - loss: 5.8326 - accuracy: 0.63 - ETA: 2s - loss: 5.8213 - accuracy: 0.63 - ETA: 2s - loss: 5.8170 - accuracy: 0.63 - ETA: 2s - loss: 5.8205 - accuracy: 0.63 - ETA: 2s - loss: 5.8180 - accuracy: 0.63 - ETA: 2s - loss: 5.8190 - accuracy: 0.63 - ETA: 2s - loss: 5.8203 - accuracy: 0.63 - ETA: 2s - loss: 5.8279 - accuracy: 0.63 - ETA: 2s - loss: 5.8300 - accuracy: 0.63 - ETA: 2s - loss: 5.8314 - accuracy: 0.63 - ETA: 2s - loss: 5.8275 - accuracy: 0.63 - ETA: 1s - loss: 5.8335 - accuracy: 0.63 - ETA: 1s - loss: 5.8340 - accuracy: 0.63 - ETA: 1s - loss: 5.8371 - accuracy: 0.63 - ETA: 1s - loss: 5.8422 - accuracy: 0.63 - ETA: 1s - loss: 5.8444 - accuracy: 0.63 - ETA: 1s - loss: 5.8444 - accuracy: 0.63 - ETA: 1s - loss: 5.8471 - accuracy: 0.63 - ETA: 1s - loss: 5.8517 - accuracy: 0.63 - ETA: 1s - loss: 5.8484 - accuracy: 0.63 - ETA: 1s - loss: 5.8464 - accuracy: 0.63 - ETA: 1s - loss: 5.8448 - accuracy: 0.63 - ETA: 1s - loss: 5.8480 - accuracy: 0.63 - ETA: 1s - loss: 5.8424 - accuracy: 0.63 - ETA: 1s - loss: 5.8358 - accuracy: 0.63 - ETA: 1s - loss: 5.8272 - accuracy: 0.63 - ETA: 1s - loss: 5.8298 - accuracy: 0.63 - ETA: 1s - loss: 5.8306 - accuracy: 0.63 - ETA: 1s - loss: 5.8317 - accuracy: 0.63 - ETA: 0s - loss: 5.8385 - accuracy: 0.63 - ETA: 0s - loss: 5.8430 - accuracy: 0.63 - ETA: 0s - loss: 5.8425 - accuracy: 0.63 - ETA: 0s - loss: 5.8467 - accuracy: 0.63 - ETA: 0s - loss: 5.8442 - accuracy: 0.63 - ETA: 0s - loss: 5.8523 - accuracy: 0.63 - ETA: 0s - loss: 5.8469 - accuracy: 0.63 - ETA: 0s - loss: 5.8485 - accuracy: 0.63 - ETA: 0s - loss: 5.8483 - accuracy: 0.63 - ETA: 0s - loss: 5.8522 - accuracy: 0.63 - ETA: 0s - loss: 5.8532 - accuracy: 0.63 - ETA: 0s - loss: 5.8548 - accuracy: 0.63 - ETA: 0s - loss: 5.8560 - accuracy: 0.63 - ETA: 0s - loss: 5.8574 - accuracy: 0.63 - ETA: 0s - loss: 5.8609 - accuracy: 0.63 - ETA: 0s - loss: 5.8603 - accuracy: 0.63 - ETA: 0s - loss: 5.8576 - accuracy: 0.63 - ETA: 0s - loss: 5.8546 - accuracy: 0.63 - ETA: 0s - loss: 5.8571 - accuracy: 0.63 - ETA: 0s - loss: 5.8539 - accuracy: 0.63 - 5s 73us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 2/50\n",
      "70000/70000 [==============================] - ETA: 13s - loss: 6.1249 - accuracy: 0.620 - ETA: 6s - loss: 5.7421 - accuracy: 0.643 - ETA: 5s - loss: 5.7918 - accuracy: 0.64 - ETA: 5s - loss: 5.7659 - accuracy: 0.64 - ETA: 5s - loss: 5.7112 - accuracy: 0.64 - ETA: 5s - loss: 5.6849 - accuracy: 0.64 - ETA: 4s - loss: 5.7109 - accuracy: 0.64 - ETA: 4s - loss: 5.7330 - accuracy: 0.64 - ETA: 4s - loss: 5.8692 - accuracy: 0.63 - ETA: 4s - loss: 5.9116 - accuracy: 0.63 - ETA: 4s - loss: 5.9593 - accuracy: 0.63 - ETA: 4s - loss: 5.9335 - accuracy: 0.63 - ETA: 4s - loss: 5.9875 - accuracy: 0.62 - ETA: 4s - loss: 5.9486 - accuracy: 0.63 - ETA: 4s - loss: 5.9795 - accuracy: 0.62 - ETA: 4s - loss: 5.9740 - accuracy: 0.62 - ETA: 4s - loss: 5.9276 - accuracy: 0.63 - ETA: 4s - loss: 5.9422 - accuracy: 0.63 - ETA: 4s - loss: 5.9133 - accuracy: 0.63 - ETA: 4s - loss: 5.8997 - accuracy: 0.63 - ETA: 4s - loss: 5.9085 - accuracy: 0.63 - ETA: 4s - loss: 5.8929 - accuracy: 0.63 - ETA: 4s - loss: 5.8862 - accuracy: 0.63 - ETA: 4s - loss: 5.8906 - accuracy: 0.63 - ETA: 4s - loss: 5.8908 - accuracy: 0.63 - ETA: 3s - loss: 5.8799 - accuracy: 0.63 - ETA: 3s - loss: 5.9138 - accuracy: 0.63 - ETA: 3s - loss: 5.9097 - accuracy: 0.63 - ETA: 3s - loss: 5.9086 - accuracy: 0.63 - ETA: 3s - loss: 5.8914 - accuracy: 0.63 - ETA: 3s - loss: 5.8720 - accuracy: 0.63 - ETA: 3s - loss: 5.8758 - accuracy: 0.63 - ETA: 3s - loss: 5.8643 - accuracy: 0.63 - ETA: 3s - loss: 5.8562 - accuracy: 0.63 - ETA: 3s - loss: 5.8587 - accuracy: 0.63 - ETA: 3s - loss: 5.8649 - accuracy: 0.63 - ETA: 3s - loss: 5.8562 - accuracy: 0.63 - ETA: 3s - loss: 5.8630 - accuracy: 0.63 - ETA: 3s - loss: 5.8581 - accuracy: 0.63 - ETA: 3s - loss: 5.8568 - accuracy: 0.63 - ETA: 3s - loss: 5.8528 - accuracy: 0.63 - ETA: 3s - loss: 5.8532 - accuracy: 0.63 - ETA: 3s - loss: 5.8672 - accuracy: 0.63 - ETA: 2s - loss: 5.8628 - accuracy: 0.63 - ETA: 2s - loss: 5.8531 - accuracy: 0.63 - ETA: 2s - loss: 5.8534 - accuracy: 0.63 - ETA: 2s - loss: 5.8478 - accuracy: 0.63 - ETA: 2s - loss: 5.8470 - accuracy: 0.63 - ETA: 2s - loss: 5.8430 - accuracy: 0.63 - ETA: 2s - loss: 5.8416 - accuracy: 0.63 - ETA: 2s - loss: 5.8340 - accuracy: 0.63 - ETA: 2s - loss: 5.8423 - accuracy: 0.63 - ETA: 2s - loss: 5.8451 - accuracy: 0.63 - ETA: 2s - loss: 5.8500 - accuracy: 0.63 - ETA: 2s - loss: 5.8479 - accuracy: 0.63 - ETA: 2s - loss: 5.8454 - accuracy: 0.63 - ETA: 2s - loss: 5.8452 - accuracy: 0.63 - ETA: 2s - loss: 5.8460 - accuracy: 0.63 - ETA: 2s - loss: 5.8490 - accuracy: 0.63 - ETA: 2s - loss: 5.8504 - accuracy: 0.63 - ETA: 2s - loss: 5.8564 - accuracy: 0.63 - ETA: 2s - loss: 5.8554 - accuracy: 0.63 - ETA: 1s - loss: 5.8582 - accuracy: 0.63 - ETA: 1s - loss: 5.8637 - accuracy: 0.63 - ETA: 1s - loss: 5.8602 - accuracy: 0.63 - ETA: 1s - loss: 5.8626 - accuracy: 0.63 - ETA: 1s - loss: 5.8663 - accuracy: 0.63 - ETA: 1s - loss: 5.8714 - accuracy: 0.63 - ETA: 1s - loss: 5.8631 - accuracy: 0.63 - ETA: 1s - loss: 5.8629 - accuracy: 0.63 - ETA: 1s - loss: 5.8601 - accuracy: 0.63 - ETA: 1s - loss: 5.8528 - accuracy: 0.63 - ETA: 1s - loss: 5.8456 - accuracy: 0.63 - ETA: 1s - loss: 5.8482 - accuracy: 0.63 - ETA: 1s - loss: 5.8468 - accuracy: 0.63 - ETA: 1s - loss: 5.8508 - accuracy: 0.63 - ETA: 1s - loss: 5.8483 - accuracy: 0.63 - ETA: 1s - loss: 5.8453 - accuracy: 0.63 - ETA: 1s - loss: 5.8530 - accuracy: 0.63 - ETA: 1s - loss: 5.8553 - accuracy: 0.63 - ETA: 1s - loss: 5.8604 - accuracy: 0.63 - ETA: 0s - loss: 5.8567 - accuracy: 0.63 - ETA: 0s - loss: 5.8486 - accuracy: 0.63 - ETA: 0s - loss: 5.8472 - accuracy: 0.63 - ETA: 0s - loss: 5.8510 - accuracy: 0.63 - ETA: 0s - loss: 5.8523 - accuracy: 0.63 - ETA: 0s - loss: 5.8520 - accuracy: 0.63 - ETA: 0s - loss: 5.8493 - accuracy: 0.63 - ETA: 0s - loss: 5.8578 - accuracy: 0.63 - ETA: 0s - loss: 5.8594 - accuracy: 0.63 - ETA: 0s - loss: 5.8584 - accuracy: 0.63 - ETA: 0s - loss: 5.8536 - accuracy: 0.63 - ETA: 0s - loss: 5.8558 - accuracy: 0.63 - ETA: 0s - loss: 5.8535 - accuracy: 0.63 - ETA: 0s - loss: 5.8550 - accuracy: 0.63 - ETA: 0s - loss: 5.8510 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8564 - accuracy: 0.63 - ETA: 0s - loss: 5.8558 - accuracy: 0.63 - ETA: 0s - loss: 5.8556 - accuracy: 0.63 - 5s 74us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 11s - loss: 7.4143 - accuracy: 0.540 - ETA: 5s - loss: 6.0532 - accuracy: 0.624 - ETA: 5s - loss: 5.8831 - accuracy: 0.63 - ETA: 4s - loss: 5.7891 - accuracy: 0.64 - ETA: 4s - loss: 5.9169 - accuracy: 0.63 - ETA: 4s - loss: 5.9637 - accuracy: 0.63 - ETA: 4s - loss: 6.0031 - accuracy: 0.62 - ETA: 4s - loss: 5.9181 - accuracy: 0.63 - ETA: 4s - loss: 5.8298 - accuracy: 0.63 - ETA: 4s - loss: 5.8298 - accuracy: 0.63 - ETA: 4s - loss: 5.8423 - accuracy: 0.63 - ETA: 4s - loss: 5.8630 - accuracy: 0.63 - ETA: 4s - loss: 5.8766 - accuracy: 0.63 - ETA: 4s - loss: 5.8591 - accuracy: 0.63 - ETA: 4s - loss: 5.8557 - accuracy: 0.63 - ETA: 4s - loss: 5.8883 - accuracy: 0.63 - ETA: 4s - loss: 5.8397 - accuracy: 0.63 - ETA: 4s - loss: 5.8714 - accuracy: 0.63 - ETA: 4s - loss: 5.8382 - accuracy: 0.63 - ETA: 4s - loss: 5.8399 - accuracy: 0.63 - ETA: 4s - loss: 5.8514 - accuracy: 0.63 - ETA: 3s - loss: 5.8647 - accuracy: 0.63 - ETA: 3s - loss: 5.8599 - accuracy: 0.63 - ETA: 3s - loss: 5.8681 - accuracy: 0.63 - ETA: 3s - loss: 5.8720 - accuracy: 0.63 - ETA: 3s - loss: 5.8911 - accuracy: 0.63 - ETA: 3s - loss: 5.9031 - accuracy: 0.63 - ETA: 3s - loss: 5.9086 - accuracy: 0.63 - ETA: 3s - loss: 5.8902 - accuracy: 0.63 - ETA: 3s - loss: 5.9021 - accuracy: 0.63 - ETA: 3s - loss: 5.8772 - accuracy: 0.63 - ETA: 3s - loss: 5.8700 - accuracy: 0.63 - ETA: 3s - loss: 5.8776 - accuracy: 0.63 - ETA: 3s - loss: 5.8868 - accuracy: 0.63 - ETA: 3s - loss: 5.8766 - accuracy: 0.63 - ETA: 3s - loss: 5.8841 - accuracy: 0.63 - ETA: 3s - loss: 5.9028 - accuracy: 0.63 - ETA: 3s - loss: 5.8966 - accuracy: 0.63 - ETA: 3s - loss: 5.8995 - accuracy: 0.63 - ETA: 3s - loss: 5.9064 - accuracy: 0.63 - ETA: 2s - loss: 5.8939 - accuracy: 0.63 - ETA: 2s - loss: 5.8975 - accuracy: 0.63 - ETA: 2s - loss: 5.8929 - accuracy: 0.63 - ETA: 2s - loss: 5.8926 - accuracy: 0.63 - ETA: 2s - loss: 5.8929 - accuracy: 0.63 - ETA: 2s - loss: 5.8910 - accuracy: 0.63 - ETA: 2s - loss: 5.9071 - accuracy: 0.63 - ETA: 2s - loss: 5.9009 - accuracy: 0.63 - ETA: 2s - loss: 5.9081 - accuracy: 0.63 - ETA: 2s - loss: 5.9070 - accuracy: 0.63 - ETA: 2s - loss: 5.9012 - accuracy: 0.63 - ETA: 2s - loss: 5.8986 - accuracy: 0.63 - ETA: 2s - loss: 5.8973 - accuracy: 0.63 - ETA: 2s - loss: 5.8975 - accuracy: 0.63 - ETA: 2s - loss: 5.8952 - accuracy: 0.63 - ETA: 2s - loss: 5.8954 - accuracy: 0.63 - ETA: 2s - loss: 5.8991 - accuracy: 0.63 - ETA: 2s - loss: 5.8988 - accuracy: 0.63 - ETA: 1s - loss: 5.8898 - accuracy: 0.63 - ETA: 1s - loss: 5.8945 - accuracy: 0.63 - ETA: 1s - loss: 5.8831 - accuracy: 0.63 - ETA: 1s - loss: 5.8771 - accuracy: 0.63 - ETA: 1s - loss: 5.8738 - accuracy: 0.63 - ETA: 1s - loss: 5.8694 - accuracy: 0.63 - ETA: 1s - loss: 5.8712 - accuracy: 0.63 - ETA: 1s - loss: 5.8789 - accuracy: 0.63 - ETA: 1s - loss: 5.8771 - accuracy: 0.63 - ETA: 1s - loss: 5.8797 - accuracy: 0.63 - ETA: 1s - loss: 5.8774 - accuracy: 0.63 - ETA: 1s - loss: 5.8786 - accuracy: 0.63 - ETA: 1s - loss: 5.8754 - accuracy: 0.63 - ETA: 1s - loss: 5.8696 - accuracy: 0.63 - ETA: 1s - loss: 5.8697 - accuracy: 0.63 - ETA: 1s - loss: 5.8675 - accuracy: 0.63 - ETA: 1s - loss: 5.8638 - accuracy: 0.63 - ETA: 1s - loss: 5.8668 - accuracy: 0.63 - ETA: 1s - loss: 5.8673 - accuracy: 0.63 - ETA: 0s - loss: 5.8596 - accuracy: 0.63 - ETA: 0s - loss: 5.8565 - accuracy: 0.63 - ETA: 0s - loss: 5.8514 - accuracy: 0.63 - ETA: 0s - loss: 5.8511 - accuracy: 0.63 - ETA: 0s - loss: 5.8508 - accuracy: 0.63 - ETA: 0s - loss: 5.8462 - accuracy: 0.63 - ETA: 0s - loss: 5.8438 - accuracy: 0.63 - ETA: 0s - loss: 5.8416 - accuracy: 0.63 - ETA: 0s - loss: 5.8466 - accuracy: 0.63 - ETA: 0s - loss: 5.8525 - accuracy: 0.63 - ETA: 0s - loss: 5.8477 - accuracy: 0.63 - ETA: 0s - loss: 5.8497 - accuracy: 0.63 - ETA: 0s - loss: 5.8539 - accuracy: 0.63 - ETA: 0s - loss: 5.8538 - accuracy: 0.63 - ETA: 0s - loss: 5.8512 - accuracy: 0.63 - ETA: 0s - loss: 5.8537 - accuracy: 0.63 - ETA: 0s - loss: 5.8499 - accuracy: 0.63 - ETA: 0s - loss: 5.8487 - accuracy: 0.63 - ETA: 0s - loss: 5.8480 - accuracy: 0.63 - ETA: 0s - loss: 5.8512 - accuracy: 0.63 - ETA: 0s - loss: 5.8530 - accuracy: 0.63 - 5s 73us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 4/50\n",
      "70000/70000 [==============================] - ETA: 5s - loss: 6.1249 - accuracy: 0.62 - ETA: 5s - loss: 6.0241 - accuracy: 0.62 - ETA: 4s - loss: 5.7521 - accuracy: 0.64 - ETA: 4s - loss: 5.8294 - accuracy: 0.63 - ETA: 4s - loss: 5.8227 - accuracy: 0.63 - ETA: 4s - loss: 5.7502 - accuracy: 0.64 - ETA: 5s - loss: 5.7688 - accuracy: 0.64 - ETA: 5s - loss: 5.8223 - accuracy: 0.63 - ETA: 5s - loss: 5.8435 - accuracy: 0.63 - ETA: 5s - loss: 5.8342 - accuracy: 0.63 - ETA: 5s - loss: 5.8769 - accuracy: 0.63 - ETA: 5s - loss: 5.8456 - accuracy: 0.63 - ETA: 5s - loss: 5.8624 - accuracy: 0.63 - ETA: 5s - loss: 5.8859 - accuracy: 0.63 - ETA: 5s - loss: 5.8875 - accuracy: 0.63 - ETA: 5s - loss: 5.8865 - accuracy: 0.63 - ETA: 5s - loss: 5.8604 - accuracy: 0.63 - ETA: 4s - loss: 5.8391 - accuracy: 0.63 - ETA: 4s - loss: 5.8645 - accuracy: 0.63 - ETA: 4s - loss: 5.8733 - accuracy: 0.63 - ETA: 4s - loss: 5.8800 - accuracy: 0.63 - ETA: 4s - loss: 5.8992 - accuracy: 0.63 - ETA: 4s - loss: 5.8695 - accuracy: 0.63 - ETA: 4s - loss: 5.8728 - accuracy: 0.63 - ETA: 4s - loss: 5.8655 - accuracy: 0.63 - ETA: 4s - loss: 5.8556 - accuracy: 0.63 - ETA: 4s - loss: 5.8634 - accuracy: 0.63 - ETA: 4s - loss: 5.8484 - accuracy: 0.63 - ETA: 4s - loss: 5.8542 - accuracy: 0.63 - ETA: 4s - loss: 5.8660 - accuracy: 0.63 - ETA: 4s - loss: 5.8859 - accuracy: 0.63 - ETA: 3s - loss: 5.8679 - accuracy: 0.63 - ETA: 3s - loss: 5.8670 - accuracy: 0.63 - ETA: 3s - loss: 5.8652 - accuracy: 0.63 - ETA: 3s - loss: 5.8760 - accuracy: 0.63 - ETA: 3s - loss: 5.8701 - accuracy: 0.63 - ETA: 3s - loss: 5.8635 - accuracy: 0.63 - ETA: 3s - loss: 5.8687 - accuracy: 0.63 - ETA: 3s - loss: 5.8662 - accuracy: 0.63 - ETA: 3s - loss: 5.8710 - accuracy: 0.63 - ETA: 3s - loss: 5.8708 - accuracy: 0.63 - ETA: 3s - loss: 5.8641 - accuracy: 0.63 - ETA: 3s - loss: 5.8532 - accuracy: 0.63 - ETA: 3s - loss: 5.8522 - accuracy: 0.63 - ETA: 3s - loss: 5.8450 - accuracy: 0.63 - ETA: 3s - loss: 5.8480 - accuracy: 0.63 - ETA: 2s - loss: 5.8492 - accuracy: 0.63 - ETA: 2s - loss: 5.8507 - accuracy: 0.63 - ETA: 2s - loss: 5.8562 - accuracy: 0.63 - ETA: 2s - loss: 5.8654 - accuracy: 0.63 - ETA: 2s - loss: 5.8615 - accuracy: 0.63 - ETA: 2s - loss: 5.8659 - accuracy: 0.63 - ETA: 2s - loss: 5.8726 - accuracy: 0.63 - ETA: 2s - loss: 5.8726 - accuracy: 0.63 - ETA: 2s - loss: 5.8676 - accuracy: 0.63 - ETA: 2s - loss: 5.8668 - accuracy: 0.63 - ETA: 2s - loss: 5.8816 - accuracy: 0.63 - ETA: 2s - loss: 5.8829 - accuracy: 0.63 - ETA: 2s - loss: 5.8798 - accuracy: 0.63 - ETA: 2s - loss: 5.8807 - accuracy: 0.63 - ETA: 2s - loss: 5.8801 - accuracy: 0.63 - ETA: 2s - loss: 5.8868 - accuracy: 0.63 - ETA: 2s - loss: 5.8841 - accuracy: 0.63 - ETA: 2s - loss: 5.8793 - accuracy: 0.63 - ETA: 2s - loss: 5.8829 - accuracy: 0.63 - ETA: 2s - loss: 5.8818 - accuracy: 0.63 - ETA: 1s - loss: 5.8833 - accuracy: 0.63 - ETA: 1s - loss: 5.8773 - accuracy: 0.63 - ETA: 1s - loss: 5.8707 - accuracy: 0.63 - ETA: 1s - loss: 5.8668 - accuracy: 0.63 - ETA: 1s - loss: 5.8638 - accuracy: 0.63 - ETA: 1s - loss: 5.8663 - accuracy: 0.63 - ETA: 1s - loss: 5.8617 - accuracy: 0.63 - ETA: 1s - loss: 5.8553 - accuracy: 0.63 - ETA: 1s - loss: 5.8501 - accuracy: 0.63 - ETA: 1s - loss: 5.8529 - accuracy: 0.63 - ETA: 1s - loss: 5.8400 - accuracy: 0.63 - ETA: 1s - loss: 5.8423 - accuracy: 0.63 - ETA: 1s - loss: 5.8480 - accuracy: 0.63 - ETA: 1s - loss: 5.8459 - accuracy: 0.63 - ETA: 1s - loss: 5.8491 - accuracy: 0.63 - ETA: 1s - loss: 5.8425 - accuracy: 0.63 - ETA: 1s - loss: 5.8392 - accuracy: 0.63 - ETA: 1s - loss: 5.8366 - accuracy: 0.63 - ETA: 0s - loss: 5.8406 - accuracy: 0.63 - ETA: 0s - loss: 5.8440 - accuracy: 0.63 - ETA: 0s - loss: 5.8452 - accuracy: 0.63 - ETA: 0s - loss: 5.8479 - accuracy: 0.63 - ETA: 0s - loss: 5.8508 - accuracy: 0.63 - ETA: 0s - loss: 5.8529 - accuracy: 0.63 - ETA: 0s - loss: 5.8505 - accuracy: 0.63 - ETA: 0s - loss: 5.8486 - accuracy: 0.63 - ETA: 0s - loss: 5.8520 - accuracy: 0.63 - ETA: 0s - loss: 5.8474 - accuracy: 0.63 - ETA: 0s - loss: 5.8516 - accuracy: 0.63 - ETA: 0s - loss: 5.8519 - accuracy: 0.63 - ETA: 0s - loss: 5.8529 - accuracy: 0.63 - ETA: 0s - loss: 5.8524 - accuracy: 0.63 - ETA: 0s - loss: 5.8534 - accuracy: 0.63 - ETA: 0s - loss: 5.8591 - accuracy: 0.63 - ETA: 0s - loss: 5.8628 - accuracy: 0.63 - ETA: 0s - loss: 5.8656 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - 5s 77us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 4s - loss: 4.3519 - accuracy: 0.73 - ETA: 5s - loss: 5.3391 - accuracy: 0.66 - ETA: 5s - loss: 5.4264 - accuracy: 0.66 - ETA: 5s - loss: 5.6340 - accuracy: 0.65 - ETA: 5s - loss: 5.6360 - accuracy: 0.65 - ETA: 5s - loss: 5.7067 - accuracy: 0.64 - ETA: 5s - loss: 5.6986 - accuracy: 0.64 - ETA: 4s - loss: 5.6900 - accuracy: 0.64 - ETA: 5s - loss: 5.7175 - accuracy: 0.64 - ETA: 5s - loss: 5.7104 - accuracy: 0.64 - ETA: 4s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 5.8707 - accuracy: 0.63 - ETA: 4s - loss: 5.8822 - accuracy: 0.63 - ETA: 4s - loss: 5.9134 - accuracy: 0.63 - ETA: 4s - loss: 5.9174 - accuracy: 0.63 - ETA: 4s - loss: 5.8831 - accuracy: 0.63 - ETA: 4s - loss: 5.9012 - accuracy: 0.63 - ETA: 4s - loss: 5.8791 - accuracy: 0.63 - ETA: 4s - loss: 5.8780 - accuracy: 0.63 - ETA: 4s - loss: 5.8733 - accuracy: 0.63 - ETA: 4s - loss: 5.8635 - accuracy: 0.63 - ETA: 4s - loss: 5.8581 - accuracy: 0.63 - ETA: 4s - loss: 5.8486 - accuracy: 0.63 - ETA: 4s - loss: 5.8503 - accuracy: 0.63 - ETA: 4s - loss: 5.8397 - accuracy: 0.63 - ETA: 3s - loss: 5.8417 - accuracy: 0.63 - ETA: 3s - loss: 5.8428 - accuracy: 0.63 - ETA: 3s - loss: 5.8297 - accuracy: 0.63 - ETA: 3s - loss: 5.8359 - accuracy: 0.63 - ETA: 3s - loss: 5.8340 - accuracy: 0.63 - ETA: 3s - loss: 5.8453 - accuracy: 0.63 - ETA: 3s - loss: 5.8617 - accuracy: 0.63 - ETA: 3s - loss: 5.8670 - accuracy: 0.63 - ETA: 3s - loss: 5.8793 - accuracy: 0.63 - ETA: 3s - loss: 5.8636 - accuracy: 0.63 - ETA: 3s - loss: 5.8695 - accuracy: 0.63 - ETA: 3s - loss: 5.8623 - accuracy: 0.63 - ETA: 3s - loss: 5.8564 - accuracy: 0.63 - ETA: 3s - loss: 5.8401 - accuracy: 0.63 - ETA: 3s - loss: 5.8281 - accuracy: 0.63 - ETA: 3s - loss: 5.8350 - accuracy: 0.63 - ETA: 3s - loss: 5.8364 - accuracy: 0.63 - ETA: 3s - loss: 5.8345 - accuracy: 0.63 - ETA: 2s - loss: 5.8231 - accuracy: 0.63 - ETA: 2s - loss: 5.8242 - accuracy: 0.63 - ETA: 2s - loss: 5.8197 - accuracy: 0.63 - ETA: 2s - loss: 5.8218 - accuracy: 0.63 - ETA: 2s - loss: 5.8231 - accuracy: 0.63 - ETA: 2s - loss: 5.8126 - accuracy: 0.63 - ETA: 2s - loss: 5.8142 - accuracy: 0.63 - ETA: 2s - loss: 5.8176 - accuracy: 0.63 - ETA: 2s - loss: 5.8266 - accuracy: 0.63 - ETA: 2s - loss: 5.8297 - accuracy: 0.63 - ETA: 2s - loss: 5.8323 - accuracy: 0.63 - ETA: 2s - loss: 5.8203 - accuracy: 0.63 - ETA: 2s - loss: 5.8175 - accuracy: 0.63 - ETA: 2s - loss: 5.8204 - accuracy: 0.63 - ETA: 2s - loss: 5.8269 - accuracy: 0.63 - ETA: 2s - loss: 5.8323 - accuracy: 0.63 - ETA: 2s - loss: 5.8283 - accuracy: 0.63 - ETA: 2s - loss: 5.8299 - accuracy: 0.63 - ETA: 2s - loss: 5.8289 - accuracy: 0.63 - ETA: 2s - loss: 5.8314 - accuracy: 0.63 - ETA: 1s - loss: 5.8233 - accuracy: 0.63 - ETA: 1s - loss: 5.8326 - accuracy: 0.63 - ETA: 1s - loss: 5.8365 - accuracy: 0.63 - ETA: 1s - loss: 5.8331 - accuracy: 0.63 - ETA: 1s - loss: 5.8385 - accuracy: 0.63 - ETA: 1s - loss: 5.8406 - accuracy: 0.63 - ETA: 1s - loss: 5.8368 - accuracy: 0.63 - ETA: 1s - loss: 5.8397 - accuracy: 0.63 - ETA: 1s - loss: 5.8383 - accuracy: 0.63 - ETA: 1s - loss: 5.8390 - accuracy: 0.63 - ETA: 1s - loss: 5.8354 - accuracy: 0.63 - ETA: 1s - loss: 5.8350 - accuracy: 0.63 - ETA: 1s - loss: 5.8349 - accuracy: 0.63 - ETA: 1s - loss: 5.8385 - accuracy: 0.63 - ETA: 1s - loss: 5.8442 - accuracy: 0.63 - ETA: 1s - loss: 5.8458 - accuracy: 0.63 - ETA: 1s - loss: 5.8459 - accuracy: 0.63 - ETA: 1s - loss: 5.8489 - accuracy: 0.63 - ETA: 1s - loss: 5.8460 - accuracy: 0.63 - ETA: 1s - loss: 5.8491 - accuracy: 0.63 - ETA: 0s - loss: 5.8516 - accuracy: 0.63 - ETA: 0s - loss: 5.8490 - accuracy: 0.63 - ETA: 0s - loss: 5.8487 - accuracy: 0.63 - ETA: 0s - loss: 5.8516 - accuracy: 0.63 - ETA: 0s - loss: 5.8494 - accuracy: 0.63 - ETA: 0s - loss: 5.8530 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8634 - accuracy: 0.63 - ETA: 0s - loss: 5.8620 - accuracy: 0.63 - ETA: 0s - loss: 5.8596 - accuracy: 0.63 - ETA: 0s - loss: 5.8610 - accuracy: 0.63 - ETA: 0s - loss: 5.8514 - accuracy: 0.63 - ETA: 0s - loss: 5.8525 - accuracy: 0.63 - ETA: 0s - loss: 5.8538 - accuracy: 0.63 - ETA: 0s - loss: 5.8582 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - 5s 75us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 6/50\n",
      "70000/70000 [==============================] - ETA: 8s - loss: 5.4802 - accuracy: 0.66 - ETA: 4s - loss: 5.7488 - accuracy: 0.64 - ETA: 4s - loss: 5.7646 - accuracy: 0.64 - ETA: 4s - loss: 5.7622 - accuracy: 0.64 - ETA: 4s - loss: 5.7649 - accuracy: 0.64 - ETA: 4s - loss: 5.6880 - accuracy: 0.64 - ETA: 4s - loss: 5.6834 - accuracy: 0.64 - ETA: 4s - loss: 5.6951 - accuracy: 0.64 - ETA: 4s - loss: 5.6933 - accuracy: 0.64 - ETA: 4s - loss: 5.7288 - accuracy: 0.64 - ETA: 4s - loss: 5.7062 - accuracy: 0.64 - ETA: 4s - loss: 5.7268 - accuracy: 0.64 - ETA: 4s - loss: 5.7434 - accuracy: 0.64 - ETA: 4s - loss: 5.7527 - accuracy: 0.64 - ETA: 4s - loss: 5.7718 - accuracy: 0.64 - ETA: 4s - loss: 5.7540 - accuracy: 0.64 - ETA: 4s - loss: 5.7692 - accuracy: 0.64 - ETA: 3s - loss: 5.7650 - accuracy: 0.64 - ETA: 3s - loss: 5.7536 - accuracy: 0.64 - ETA: 3s - loss: 5.7631 - accuracy: 0.64 - ETA: 3s - loss: 5.7896 - accuracy: 0.64 - ETA: 3s - loss: 5.8118 - accuracy: 0.63 - ETA: 3s - loss: 5.8094 - accuracy: 0.63 - ETA: 3s - loss: 5.8168 - accuracy: 0.63 - ETA: 3s - loss: 5.8237 - accuracy: 0.63 - ETA: 3s - loss: 5.8337 - accuracy: 0.63 - ETA: 3s - loss: 5.8351 - accuracy: 0.63 - ETA: 3s - loss: 5.8416 - accuracy: 0.63 - ETA: 3s - loss: 5.8485 - accuracy: 0.63 - ETA: 3s - loss: 5.8395 - accuracy: 0.63 - ETA: 3s - loss: 5.8461 - accuracy: 0.63 - ETA: 3s - loss: 5.8397 - accuracy: 0.63 - ETA: 3s - loss: 5.8387 - accuracy: 0.63 - ETA: 3s - loss: 5.8314 - accuracy: 0.63 - ETA: 3s - loss: 5.8387 - accuracy: 0.63 - ETA: 3s - loss: 5.8324 - accuracy: 0.63 - ETA: 3s - loss: 5.8299 - accuracy: 0.63 - ETA: 3s - loss: 5.8305 - accuracy: 0.63 - ETA: 3s - loss: 5.8431 - accuracy: 0.63 - ETA: 3s - loss: 5.8455 - accuracy: 0.63 - ETA: 3s - loss: 5.8496 - accuracy: 0.63 - ETA: 3s - loss: 5.8547 - accuracy: 0.63 - ETA: 3s - loss: 5.8535 - accuracy: 0.63 - ETA: 3s - loss: 5.8528 - accuracy: 0.63 - ETA: 3s - loss: 5.8464 - accuracy: 0.63 - ETA: 2s - loss: 5.8499 - accuracy: 0.63 - ETA: 2s - loss: 5.8506 - accuracy: 0.63 - ETA: 2s - loss: 5.8429 - accuracy: 0.63 - ETA: 2s - loss: 5.8391 - accuracy: 0.63 - ETA: 2s - loss: 5.8414 - accuracy: 0.63 - ETA: 2s - loss: 5.8341 - accuracy: 0.63 - ETA: 2s - loss: 5.8285 - accuracy: 0.63 - ETA: 2s - loss: 5.8283 - accuracy: 0.63 - ETA: 2s - loss: 5.8176 - accuracy: 0.63 - ETA: 2s - loss: 5.8186 - accuracy: 0.63 - ETA: 2s - loss: 5.8258 - accuracy: 0.63 - ETA: 2s - loss: 5.8178 - accuracy: 0.63 - ETA: 2s - loss: 5.8306 - accuracy: 0.63 - ETA: 1s - loss: 5.8247 - accuracy: 0.63 - ETA: 1s - loss: 5.8309 - accuracy: 0.63 - ETA: 1s - loss: 5.8332 - accuracy: 0.63 - ETA: 1s - loss: 5.8369 - accuracy: 0.63 - ETA: 1s - loss: 5.8383 - accuracy: 0.63 - ETA: 1s - loss: 5.8482 - accuracy: 0.63 - ETA: 1s - loss: 5.8457 - accuracy: 0.63 - ETA: 1s - loss: 5.8406 - accuracy: 0.63 - ETA: 1s - loss: 5.8380 - accuracy: 0.63 - ETA: 1s - loss: 5.8377 - accuracy: 0.63 - ETA: 1s - loss: 5.8427 - accuracy: 0.63 - ETA: 1s - loss: 5.8387 - accuracy: 0.63 - ETA: 1s - loss: 5.8399 - accuracy: 0.63 - ETA: 1s - loss: 5.8472 - accuracy: 0.63 - ETA: 1s - loss: 5.8487 - accuracy: 0.63 - ETA: 1s - loss: 5.8449 - accuracy: 0.63 - ETA: 0s - loss: 5.8479 - accuracy: 0.63 - ETA: 0s - loss: 5.8459 - accuracy: 0.63 - ETA: 0s - loss: 5.8542 - accuracy: 0.63 - ETA: 0s - loss: 5.8531 - accuracy: 0.63 - ETA: 0s - loss: 5.8565 - accuracy: 0.63 - ETA: 0s - loss: 5.8581 - accuracy: 0.63 - ETA: 0s - loss: 5.8569 - accuracy: 0.63 - ETA: 0s - loss: 5.8594 - accuracy: 0.63 - ETA: 0s - loss: 5.8614 - accuracy: 0.63 - ETA: 0s - loss: 5.8597 - accuracy: 0.63 - ETA: 0s - loss: 5.8572 - accuracy: 0.63 - ETA: 0s - loss: 5.8590 - accuracy: 0.63 - ETA: 0s - loss: 5.8544 - accuracy: 0.63 - ETA: 0s - loss: 5.8557 - accuracy: 0.63 - ETA: 0s - loss: 5.8566 - accuracy: 0.63 - ETA: 0s - loss: 5.8569 - accuracy: 0.63 - ETA: 0s - loss: 5.8571 - accuracy: 0.63 - 5s 68us/sample - loss: 5.8557 - accuracy: 0.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "70000/70000 [==============================] - ETA: 5s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 5.9798 - accuracy: 0.62 - ETA: 4s - loss: 5.9542 - accuracy: 0.63 - ETA: 4s - loss: 5.8682 - accuracy: 0.63 - ETA: 4s - loss: 5.8348 - accuracy: 0.63 - ETA: 4s - loss: 5.9852 - accuracy: 0.62 - ETA: 3s - loss: 5.9607 - accuracy: 0.63 - ETA: 4s - loss: 5.9267 - accuracy: 0.63 - ETA: 3s - loss: 5.8703 - accuracy: 0.63 - ETA: 3s - loss: 5.8852 - accuracy: 0.63 - ETA: 3s - loss: 5.8897 - accuracy: 0.63 - ETA: 3s - loss: 5.8780 - accuracy: 0.63 - ETA: 3s - loss: 5.8542 - accuracy: 0.63 - ETA: 3s - loss: 5.8504 - accuracy: 0.63 - ETA: 3s - loss: 5.8531 - accuracy: 0.63 - ETA: 3s - loss: 5.8670 - accuracy: 0.63 - ETA: 3s - loss: 5.8504 - accuracy: 0.63 - ETA: 3s - loss: 5.8610 - accuracy: 0.63 - ETA: 3s - loss: 5.8836 - accuracy: 0.63 - ETA: 3s - loss: 5.8811 - accuracy: 0.63 - ETA: 3s - loss: 5.8836 - accuracy: 0.63 - ETA: 3s - loss: 5.8748 - accuracy: 0.63 - ETA: 3s - loss: 5.8739 - accuracy: 0.63 - ETA: 3s - loss: 5.8768 - accuracy: 0.63 - ETA: 3s - loss: 5.8799 - accuracy: 0.63 - ETA: 3s - loss: 5.8812 - accuracy: 0.63 - ETA: 3s - loss: 5.8654 - accuracy: 0.63 - ETA: 2s - loss: 5.8565 - accuracy: 0.63 - ETA: 2s - loss: 5.8558 - accuracy: 0.63 - ETA: 2s - loss: 5.8505 - accuracy: 0.63 - ETA: 2s - loss: 5.8342 - accuracy: 0.63 - ETA: 2s - loss: 5.8394 - accuracy: 0.63 - ETA: 2s - loss: 5.8400 - accuracy: 0.63 - ETA: 2s - loss: 5.8314 - accuracy: 0.63 - ETA: 2s - loss: 5.8434 - accuracy: 0.63 - ETA: 2s - loss: 5.8476 - accuracy: 0.63 - ETA: 2s - loss: 5.8432 - accuracy: 0.63 - ETA: 2s - loss: 5.8513 - accuracy: 0.63 - ETA: 2s - loss: 5.8468 - accuracy: 0.63 - ETA: 2s - loss: 5.8530 - accuracy: 0.63 - ETA: 2s - loss: 5.8550 - accuracy: 0.63 - ETA: 2s - loss: 5.8606 - accuracy: 0.63 - ETA: 2s - loss: 5.8518 - accuracy: 0.63 - ETA: 2s - loss: 5.8600 - accuracy: 0.63 - ETA: 2s - loss: 5.8519 - accuracy: 0.63 - ETA: 1s - loss: 5.8389 - accuracy: 0.63 - ETA: 1s - loss: 5.8428 - accuracy: 0.63 - ETA: 1s - loss: 5.8450 - accuracy: 0.63 - ETA: 1s - loss: 5.8508 - accuracy: 0.63 - ETA: 1s - loss: 5.8447 - accuracy: 0.63 - ETA: 1s - loss: 5.8469 - accuracy: 0.63 - ETA: 1s - loss: 5.8456 - accuracy: 0.63 - ETA: 1s - loss: 5.8374 - accuracy: 0.63 - ETA: 1s - loss: 5.8396 - accuracy: 0.63 - ETA: 1s - loss: 5.8385 - accuracy: 0.63 - ETA: 1s - loss: 5.8402 - accuracy: 0.63 - ETA: 1s - loss: 5.8383 - accuracy: 0.63 - ETA: 1s - loss: 5.8429 - accuracy: 0.63 - ETA: 1s - loss: 5.8448 - accuracy: 0.63 - ETA: 1s - loss: 5.8423 - accuracy: 0.63 - ETA: 1s - loss: 5.8477 - accuracy: 0.63 - ETA: 1s - loss: 5.8523 - accuracy: 0.63 - ETA: 1s - loss: 5.8508 - accuracy: 0.63 - ETA: 1s - loss: 5.8471 - accuracy: 0.63 - ETA: 0s - loss: 5.8520 - accuracy: 0.63 - ETA: 0s - loss: 5.8543 - accuracy: 0.63 - ETA: 0s - loss: 5.8580 - accuracy: 0.63 - ETA: 0s - loss: 5.8483 - accuracy: 0.63 - ETA: 0s - loss: 5.8459 - accuracy: 0.63 - ETA: 0s - loss: 5.8460 - accuracy: 0.63 - ETA: 0s - loss: 5.8443 - accuracy: 0.63 - ETA: 0s - loss: 5.8428 - accuracy: 0.63 - ETA: 0s - loss: 5.8427 - accuracy: 0.63 - ETA: 0s - loss: 5.8421 - accuracy: 0.63 - ETA: 0s - loss: 5.8431 - accuracy: 0.63 - ETA: 0s - loss: 5.8476 - accuracy: 0.63 - ETA: 0s - loss: 5.8453 - accuracy: 0.63 - ETA: 0s - loss: 5.8473 - accuracy: 0.63 - ETA: 0s - loss: 5.8431 - accuracy: 0.63 - ETA: 0s - loss: 5.8502 - accuracy: 0.63 - ETA: 0s - loss: 5.8521 - accuracy: 0.63 - ETA: 0s - loss: 5.8553 - accuracy: 0.63 - ETA: 0s - loss: 5.8534 - accuracy: 0.63 - ETA: 0s - loss: 5.8537 - accuracy: 0.63 - ETA: 0s - loss: 5.8549 - accuracy: 0.63 - ETA: 0s - loss: 5.8505 - accuracy: 0.63 - ETA: 0s - loss: 5.8550 - accuracy: 0.63 - 5s 76us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 8/50\n",
      "70000/70000 [==============================] - ETA: 4s - loss: 5.8025 - accuracy: 0.64 - ETA: 3s - loss: 6.3300 - accuracy: 0.60 - ETA: 4s - loss: 6.1249 - accuracy: 0.62 - ETA: 4s - loss: 6.0193 - accuracy: 0.62 - ETA: 3s - loss: 5.8661 - accuracy: 0.63 - ETA: 4s - loss: 5.8282 - accuracy: 0.63 - ETA: 4s - loss: 5.8694 - accuracy: 0.63 - ETA: 4s - loss: 5.9109 - accuracy: 0.63 - ETA: 4s - loss: 5.9315 - accuracy: 0.63 - ETA: 4s - loss: 5.9262 - accuracy: 0.63 - ETA: 4s - loss: 5.8733 - accuracy: 0.63 - ETA: 4s - loss: 5.9265 - accuracy: 0.63 - ETA: 3s - loss: 5.9202 - accuracy: 0.63 - ETA: 3s - loss: 5.9829 - accuracy: 0.62 - ETA: 3s - loss: 5.9513 - accuracy: 0.63 - ETA: 3s - loss: 5.9509 - accuracy: 0.63 - ETA: 3s - loss: 5.9601 - accuracy: 0.63 - ETA: 3s - loss: 5.9515 - accuracy: 0.63 - ETA: 3s - loss: 5.9128 - accuracy: 0.63 - ETA: 3s - loss: 5.8851 - accuracy: 0.63 - ETA: 3s - loss: 5.8740 - accuracy: 0.63 - ETA: 3s - loss: 5.8686 - accuracy: 0.63 - ETA: 3s - loss: 5.8904 - accuracy: 0.63 - ETA: 3s - loss: 5.8740 - accuracy: 0.63 - ETA: 3s - loss: 5.8843 - accuracy: 0.63 - ETA: 3s - loss: 5.8846 - accuracy: 0.63 - ETA: 3s - loss: 5.8768 - accuracy: 0.63 - ETA: 2s - loss: 5.8707 - accuracy: 0.63 - ETA: 2s - loss: 5.8855 - accuracy: 0.63 - ETA: 2s - loss: 5.8978 - accuracy: 0.63 - ETA: 2s - loss: 5.8954 - accuracy: 0.63 - ETA: 2s - loss: 5.8859 - accuracy: 0.63 - ETA: 2s - loss: 5.8846 - accuracy: 0.63 - ETA: 2s - loss: 5.8902 - accuracy: 0.63 - ETA: 2s - loss: 5.8942 - accuracy: 0.63 - ETA: 2s - loss: 5.8870 - accuracy: 0.63 - ETA: 2s - loss: 5.8807 - accuracy: 0.63 - ETA: 2s - loss: 5.8896 - accuracy: 0.63 - ETA: 2s - loss: 5.8912 - accuracy: 0.63 - ETA: 2s - loss: 5.9001 - accuracy: 0.63 - ETA: 2s - loss: 5.8889 - accuracy: 0.63 - ETA: 2s - loss: 5.8871 - accuracy: 0.63 - ETA: 2s - loss: 5.8778 - accuracy: 0.63 - ETA: 2s - loss: 5.8741 - accuracy: 0.63 - ETA: 2s - loss: 5.8573 - accuracy: 0.63 - ETA: 2s - loss: 5.8530 - accuracy: 0.63 - ETA: 1s - loss: 5.8568 - accuracy: 0.63 - ETA: 1s - loss: 5.8588 - accuracy: 0.63 - ETA: 1s - loss: 5.8639 - accuracy: 0.63 - ETA: 1s - loss: 5.8606 - accuracy: 0.63 - ETA: 1s - loss: 5.8658 - accuracy: 0.63 - ETA: 1s - loss: 5.8657 - accuracy: 0.63 - ETA: 1s - loss: 5.8711 - accuracy: 0.63 - ETA: 1s - loss: 5.8729 - accuracy: 0.63 - ETA: 1s - loss: 5.8746 - accuracy: 0.63 - ETA: 1s - loss: 5.8796 - accuracy: 0.63 - ETA: 1s - loss: 5.8771 - accuracy: 0.63 - ETA: 1s - loss: 5.8876 - accuracy: 0.63 - ETA: 1s - loss: 5.8857 - accuracy: 0.63 - ETA: 1s - loss: 5.8815 - accuracy: 0.63 - ETA: 1s - loss: 5.8828 - accuracy: 0.63 - ETA: 1s - loss: 5.8845 - accuracy: 0.63 - ETA: 1s - loss: 5.8757 - accuracy: 0.63 - ETA: 1s - loss: 5.8811 - accuracy: 0.63 - ETA: 1s - loss: 5.8792 - accuracy: 0.63 - ETA: 0s - loss: 5.8783 - accuracy: 0.63 - ETA: 0s - loss: 5.8698 - accuracy: 0.63 - ETA: 0s - loss: 5.8704 - accuracy: 0.63 - ETA: 0s - loss: 5.8692 - accuracy: 0.63 - ETA: 0s - loss: 5.8740 - accuracy: 0.63 - ETA: 0s - loss: 5.8717 - accuracy: 0.63 - ETA: 0s - loss: 5.8717 - accuracy: 0.63 - ETA: 0s - loss: 5.8675 - accuracy: 0.63 - ETA: 0s - loss: 5.8632 - accuracy: 0.63 - ETA: 0s - loss: 5.8613 - accuracy: 0.63 - ETA: 0s - loss: 5.8620 - accuracy: 0.63 - ETA: 0s - loss: 5.8635 - accuracy: 0.63 - ETA: 0s - loss: 5.8590 - accuracy: 0.63 - ETA: 0s - loss: 5.8553 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8549 - accuracy: 0.63 - ETA: 0s - loss: 5.8591 - accuracy: 0.63 - ETA: 0s - loss: 5.8603 - accuracy: 0.63 - 4s 63us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 9/50\n",
      "70000/70000 [==============================] - ETA: 4s - loss: 6.1249 - accuracy: 0.62 - ETA: 3s - loss: 5.6413 - accuracy: 0.65 - ETA: 4s - loss: 5.8204 - accuracy: 0.63 - ETA: 4s - loss: 5.9577 - accuracy: 0.63 - ETA: 3s - loss: 5.9950 - accuracy: 0.62 - ETA: 3s - loss: 5.9171 - accuracy: 0.63 - ETA: 3s - loss: 5.8742 - accuracy: 0.63 - ETA: 3s - loss: 5.8639 - accuracy: 0.63 - ETA: 3s - loss: 5.8952 - accuracy: 0.63 - ETA: 3s - loss: 5.8870 - accuracy: 0.63 - ETA: 3s - loss: 5.9052 - accuracy: 0.63 - ETA: 3s - loss: 5.9089 - accuracy: 0.63 - ETA: 3s - loss: 5.9001 - accuracy: 0.63 - ETA: 3s - loss: 5.9325 - accuracy: 0.63 - ETA: 3s - loss: 5.9247 - accuracy: 0.63 - ETA: 3s - loss: 5.8990 - accuracy: 0.63 - ETA: 3s - loss: 5.8875 - accuracy: 0.63 - ETA: 3s - loss: 5.8857 - accuracy: 0.63 - ETA: 3s - loss: 5.9080 - accuracy: 0.63 - ETA: 3s - loss: 5.9189 - accuracy: 0.63 - ETA: 3s - loss: 5.9282 - accuracy: 0.63 - ETA: 3s - loss: 5.9308 - accuracy: 0.63 - ETA: 2s - loss: 5.9282 - accuracy: 0.63 - ETA: 2s - loss: 5.9226 - accuracy: 0.63 - ETA: 2s - loss: 5.9342 - accuracy: 0.63 - ETA: 2s - loss: 5.9303 - accuracy: 0.63 - ETA: 2s - loss: 5.9143 - accuracy: 0.63 - ETA: 2s - loss: 5.9256 - accuracy: 0.63 - ETA: 3s - loss: 5.9204 - accuracy: 0.63 - ETA: 3s - loss: 5.9169 - accuracy: 0.63 - ETA: 2s - loss: 5.9185 - accuracy: 0.63 - ETA: 2s - loss: 5.9134 - accuracy: 0.63 - ETA: 2s - loss: 5.9090 - accuracy: 0.63 - ETA: 2s - loss: 5.8948 - accuracy: 0.63 - ETA: 2s - loss: 5.8875 - accuracy: 0.63 - ETA: 2s - loss: 5.8877 - accuracy: 0.63 - ETA: 2s - loss: 5.8891 - accuracy: 0.63 - ETA: 2s - loss: 5.8864 - accuracy: 0.63 - ETA: 2s - loss: 5.8904 - accuracy: 0.63 - ETA: 2s - loss: 5.8854 - accuracy: 0.63 - ETA: 2s - loss: 5.8881 - accuracy: 0.63 - ETA: 2s - loss: 5.8949 - accuracy: 0.63 - ETA: 2s - loss: 5.8944 - accuracy: 0.63 - ETA: 2s - loss: 5.8944 - accuracy: 0.63 - ETA: 2s - loss: 5.8881 - accuracy: 0.63 - ETA: 2s - loss: 5.8891 - accuracy: 0.63 - ETA: 2s - loss: 5.8907 - accuracy: 0.63 - ETA: 2s - loss: 5.8936 - accuracy: 0.63 - ETA: 2s - loss: 5.8833 - accuracy: 0.63 - ETA: 2s - loss: 5.8897 - accuracy: 0.63 - ETA: 2s - loss: 5.8912 - accuracy: 0.63 - ETA: 2s - loss: 5.8954 - accuracy: 0.63 - ETA: 2s - loss: 5.8917 - accuracy: 0.63 - ETA: 2s - loss: 5.8965 - accuracy: 0.63 - ETA: 2s - loss: 5.8951 - accuracy: 0.63 - ETA: 2s - loss: 5.8942 - accuracy: 0.63 - ETA: 1s - loss: 5.8826 - accuracy: 0.63 - ETA: 1s - loss: 5.8794 - accuracy: 0.63 - ETA: 1s - loss: 5.8735 - accuracy: 0.63 - ETA: 1s - loss: 5.8685 - accuracy: 0.63 - ETA: 1s - loss: 5.8645 - accuracy: 0.63 - ETA: 1s - loss: 5.8710 - accuracy: 0.63 - ETA: 1s - loss: 5.8714 - accuracy: 0.63 - ETA: 1s - loss: 5.8701 - accuracy: 0.63 - ETA: 1s - loss: 5.8661 - accuracy: 0.63 - ETA: 1s - loss: 5.8591 - accuracy: 0.63 - ETA: 1s - loss: 5.8597 - accuracy: 0.63 - ETA: 1s - loss: 5.8617 - accuracy: 0.63 - ETA: 1s - loss: 5.8563 - accuracy: 0.63 - ETA: 1s - loss: 5.8621 - accuracy: 0.63 - ETA: 0s - loss: 5.8680 - accuracy: 0.63 - ETA: 0s - loss: 5.8633 - accuracy: 0.63 - ETA: 0s - loss: 5.8646 - accuracy: 0.63 - ETA: 0s - loss: 5.8658 - accuracy: 0.63 - ETA: 0s - loss: 5.8662 - accuracy: 0.63 - ETA: 0s - loss: 5.8648 - accuracy: 0.63 - ETA: 0s - loss: 5.8633 - accuracy: 0.63 - ETA: 0s - loss: 5.8615 - accuracy: 0.63 - ETA: 0s - loss: 5.8599 - accuracy: 0.63 - ETA: 0s - loss: 5.8621 - accuracy: 0.63 - ETA: 0s - loss: 5.8623 - accuracy: 0.63 - ETA: 0s - loss: 5.8579 - accuracy: 0.63 - ETA: 0s - loss: 5.8556 - accuracy: 0.63 - ETA: 0s - loss: 5.8581 - accuracy: 0.63 - ETA: 0s - loss: 5.8604 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - 5s 70us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 10/50\n",
      "70000/70000 [==============================] - ETA: 4s - loss: 6.2861 - accuracy: 0.61 - ETA: 4s - loss: 5.8992 - accuracy: 0.63 - ETA: 4s - loss: 5.7361 - accuracy: 0.64 - ETA: 4s - loss: 5.7316 - accuracy: 0.64 - ETA: 4s - loss: 5.9442 - accuracy: 0.63 - ETA: 4s - loss: 5.9675 - accuracy: 0.62 - ETA: 3s - loss: 5.9036 - accuracy: 0.63 - ETA: 4s - loss: 5.8760 - accuracy: 0.63 - ETA: 4s - loss: 5.9265 - accuracy: 0.63 - ETA: 4s - loss: 5.8908 - accuracy: 0.63 - ETA: 3s - loss: 5.8752 - accuracy: 0.63 - ETA: 3s - loss: 5.8680 - accuracy: 0.63 - ETA: 3s - loss: 5.8589 - accuracy: 0.63 - ETA: 3s - loss: 5.8324 - accuracy: 0.63 - ETA: 3s - loss: 5.8246 - accuracy: 0.63 - ETA: 3s - loss: 5.8486 - accuracy: 0.63 - ETA: 3s - loss: 5.8622 - accuracy: 0.63 - ETA: 3s - loss: 5.8618 - accuracy: 0.63 - ETA: 3s - loss: 5.8815 - accuracy: 0.63 - ETA: 3s - loss: 5.9093 - accuracy: 0.63 - ETA: 3s - loss: 5.9046 - accuracy: 0.63 - ETA: 3s - loss: 5.9103 - accuracy: 0.63 - ETA: 3s - loss: 5.8922 - accuracy: 0.63 - ETA: 3s - loss: 5.9028 - accuracy: 0.63 - ETA: 3s - loss: 5.8886 - accuracy: 0.63 - ETA: 3s - loss: 5.8782 - accuracy: 0.63 - ETA: 3s - loss: 5.8969 - accuracy: 0.63 - ETA: 2s - loss: 5.8967 - accuracy: 0.63 - ETA: 2s - loss: 5.8750 - accuracy: 0.63 - ETA: 2s - loss: 5.8770 - accuracy: 0.63 - ETA: 2s - loss: 5.8672 - accuracy: 0.63 - ETA: 2s - loss: 5.8699 - accuracy: 0.63 - ETA: 2s - loss: 5.8632 - accuracy: 0.63 - ETA: 2s - loss: 5.8574 - accuracy: 0.63 - ETA: 2s - loss: 5.8497 - accuracy: 0.63 - ETA: 2s - loss: 5.8536 - accuracy: 0.63 - ETA: 2s - loss: 5.8562 - accuracy: 0.63 - ETA: 2s - loss: 5.8542 - accuracy: 0.63 - ETA: 2s - loss: 5.8548 - accuracy: 0.63 - ETA: 2s - loss: 5.8477 - accuracy: 0.63 - ETA: 2s - loss: 5.8561 - accuracy: 0.63 - ETA: 2s - loss: 5.8549 - accuracy: 0.63 - ETA: 2s - loss: 5.8478 - accuracy: 0.63 - ETA: 2s - loss: 5.8497 - accuracy: 0.63 - ETA: 1s - loss: 5.8461 - accuracy: 0.63 - ETA: 1s - loss: 5.8587 - accuracy: 0.63 - ETA: 1s - loss: 5.8604 - accuracy: 0.63 - ETA: 1s - loss: 5.8625 - accuracy: 0.63 - ETA: 1s - loss: 5.8654 - accuracy: 0.63 - ETA: 1s - loss: 5.8646 - accuracy: 0.63 - ETA: 1s - loss: 5.8565 - accuracy: 0.63 - ETA: 1s - loss: 5.8588 - accuracy: 0.63 - ETA: 1s - loss: 5.8657 - accuracy: 0.63 - ETA: 1s - loss: 5.8658 - accuracy: 0.63 - ETA: 1s - loss: 5.8709 - accuracy: 0.63 - ETA: 1s - loss: 5.8681 - accuracy: 0.63 - ETA: 1s - loss: 5.8673 - accuracy: 0.63 - ETA: 1s - loss: 5.8681 - accuracy: 0.63 - ETA: 1s - loss: 5.8666 - accuracy: 0.63 - ETA: 1s - loss: 5.8658 - accuracy: 0.63 - ETA: 1s - loss: 5.8628 - accuracy: 0.63 - ETA: 1s - loss: 5.8619 - accuracy: 0.63 - ETA: 1s - loss: 5.8648 - accuracy: 0.63 - ETA: 0s - loss: 5.8659 - accuracy: 0.63 - ETA: 0s - loss: 5.8572 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8488 - accuracy: 0.63 - ETA: 0s - loss: 5.8431 - accuracy: 0.63 - ETA: 0s - loss: 5.8469 - accuracy: 0.63 - ETA: 0s - loss: 5.8451 - accuracy: 0.63 - ETA: 0s - loss: 5.8459 - accuracy: 0.63 - ETA: 0s - loss: 5.8445 - accuracy: 0.63 - ETA: 0s - loss: 5.8413 - accuracy: 0.63 - ETA: 0s - loss: 5.8454 - accuracy: 0.63 - ETA: 0s - loss: 5.8456 - accuracy: 0.63 - ETA: 0s - loss: 5.8440 - accuracy: 0.63 - ETA: 0s - loss: 5.8449 - accuracy: 0.63 - ETA: 0s - loss: 5.8485 - accuracy: 0.63 - ETA: 0s - loss: 5.8501 - accuracy: 0.63 - ETA: 0s - loss: 5.8517 - accuracy: 0.63 - ETA: 0s - loss: 5.8536 - accuracy: 0.63 - ETA: 0s - loss: 5.8571 - accuracy: 0.63 - 4s 62us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 4s - loss: 4.6742 - accuracy: 0.71 - ETA: 4s - loss: 5.3673 - accuracy: 0.66 - ETA: 4s - loss: 5.6244 - accuracy: 0.65 - ETA: 4s - loss: 5.6234 - accuracy: 0.65 - ETA: 4s - loss: 5.7196 - accuracy: 0.64 - ETA: 4s - loss: 5.7763 - accuracy: 0.64 - ETA: 3s - loss: 5.8180 - accuracy: 0.63 - ETA: 4s - loss: 5.8271 - accuracy: 0.63 - ETA: 3s - loss: 5.8169 - accuracy: 0.63 - ETA: 3s - loss: 5.8195 - accuracy: 0.63 - ETA: 3s - loss: 5.8025 - accuracy: 0.64 - ETA: 3s - loss: 5.7802 - accuracy: 0.64 - ETA: 3s - loss: 5.7884 - accuracy: 0.64 - ETA: 3s - loss: 5.7737 - accuracy: 0.64 - ETA: 3s - loss: 5.7772 - accuracy: 0.64 - ETA: 3s - loss: 5.7963 - accuracy: 0.64 - ETA: 3s - loss: 5.8106 - accuracy: 0.63 - ETA: 3s - loss: 5.8080 - accuracy: 0.63 - ETA: 3s - loss: 5.8314 - accuracy: 0.63 - ETA: 3s - loss: 5.8475 - accuracy: 0.63 - ETA: 3s - loss: 5.8340 - accuracy: 0.63 - ETA: 3s - loss: 5.8395 - accuracy: 0.63 - ETA: 3s - loss: 5.8389 - accuracy: 0.63 - ETA: 3s - loss: 5.8356 - accuracy: 0.63 - ETA: 3s - loss: 5.8373 - accuracy: 0.63 - ETA: 3s - loss: 5.8252 - accuracy: 0.63 - ETA: 2s - loss: 5.8250 - accuracy: 0.63 - ETA: 2s - loss: 5.8465 - accuracy: 0.63 - ETA: 2s - loss: 5.8515 - accuracy: 0.63 - ETA: 2s - loss: 5.8549 - accuracy: 0.63 - ETA: 2s - loss: 5.8537 - accuracy: 0.63 - ETA: 2s - loss: 5.8484 - accuracy: 0.63 - ETA: 2s - loss: 5.8457 - accuracy: 0.63 - ETA: 2s - loss: 5.8466 - accuracy: 0.63 - ETA: 2s - loss: 5.8535 - accuracy: 0.63 - ETA: 2s - loss: 5.8502 - accuracy: 0.63 - ETA: 2s - loss: 5.8381 - accuracy: 0.63 - ETA: 2s - loss: 5.8275 - accuracy: 0.63 - ETA: 2s - loss: 5.8357 - accuracy: 0.63 - ETA: 2s - loss: 5.8339 - accuracy: 0.63 - ETA: 2s - loss: 5.8425 - accuracy: 0.63 - ETA: 2s - loss: 5.8342 - accuracy: 0.63 - ETA: 2s - loss: 5.8450 - accuracy: 0.63 - ETA: 2s - loss: 5.8462 - accuracy: 0.63 - ETA: 1s - loss: 5.8528 - accuracy: 0.63 - ETA: 1s - loss: 5.8589 - accuracy: 0.63 - ETA: 1s - loss: 5.8616 - accuracy: 0.63 - ETA: 1s - loss: 5.8679 - accuracy: 0.63 - ETA: 1s - loss: 5.8668 - accuracy: 0.63 - ETA: 1s - loss: 5.8593 - accuracy: 0.63 - ETA: 1s - loss: 5.8574 - accuracy: 0.63 - ETA: 1s - loss: 5.8445 - accuracy: 0.63 - ETA: 1s - loss: 5.8436 - accuracy: 0.63 - ETA: 1s - loss: 5.8524 - accuracy: 0.63 - ETA: 1s - loss: 5.8519 - accuracy: 0.63 - ETA: 1s - loss: 5.8523 - accuracy: 0.63 - ETA: 1s - loss: 5.8590 - accuracy: 0.63 - ETA: 1s - loss: 5.8604 - accuracy: 0.63 - ETA: 1s - loss: 5.8621 - accuracy: 0.63 - ETA: 1s - loss: 5.8563 - accuracy: 0.63 - ETA: 1s - loss: 5.8556 - accuracy: 0.63 - ETA: 1s - loss: 5.8530 - accuracy: 0.63 - ETA: 1s - loss: 5.8503 - accuracy: 0.63 - ETA: 1s - loss: 5.8445 - accuracy: 0.63 - ETA: 1s - loss: 5.8518 - accuracy: 0.63 - ETA: 1s - loss: 5.8552 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8605 - accuracy: 0.63 - ETA: 0s - loss: 5.8595 - accuracy: 0.63 - ETA: 0s - loss: 5.8523 - accuracy: 0.63 - ETA: 0s - loss: 5.8521 - accuracy: 0.63 - ETA: 0s - loss: 5.8548 - accuracy: 0.63 - ETA: 0s - loss: 5.8578 - accuracy: 0.63 - ETA: 0s - loss: 5.8631 - accuracy: 0.63 - ETA: 0s - loss: 5.8636 - accuracy: 0.63 - ETA: 0s - loss: 5.8693 - accuracy: 0.63 - ETA: 0s - loss: 5.8642 - accuracy: 0.63 - ETA: 0s - loss: 5.8665 - accuracy: 0.63 - ETA: 0s - loss: 5.8657 - accuracy: 0.63 - ETA: 0s - loss: 5.8621 - accuracy: 0.63 - ETA: 0s - loss: 5.8608 - accuracy: 0.63 - ETA: 0s - loss: 5.8575 - accuracy: 0.63 - ETA: 0s - loss: 5.8590 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8530 - accuracy: 0.63 - ETA: 0s - loss: 5.8546 - accuracy: 0.63 - 5s 65us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 12/50\n",
      "70000/70000 [==============================] - ETA: 5s - loss: 5.9637 - accuracy: 0.63 - ETA: 4s - loss: 5.3996 - accuracy: 0.66 - ETA: 3s - loss: 5.5141 - accuracy: 0.65 - ETA: 4s - loss: 5.6055 - accuracy: 0.65 - ETA: 3s - loss: 5.6369 - accuracy: 0.65 - ETA: 3s - loss: 5.6521 - accuracy: 0.64 - ETA: 3s - loss: 5.6596 - accuracy: 0.64 - ETA: 3s - loss: 5.7505 - accuracy: 0.64 - ETA: 3s - loss: 5.7026 - accuracy: 0.64 - ETA: 3s - loss: 5.7401 - accuracy: 0.64 - ETA: 3s - loss: 5.7916 - accuracy: 0.64 - ETA: 3s - loss: 5.7876 - accuracy: 0.64 - ETA: 3s - loss: 5.7326 - accuracy: 0.64 - ETA: 3s - loss: 5.8067 - accuracy: 0.63 - ETA: 3s - loss: 5.8181 - accuracy: 0.63 - ETA: 3s - loss: 5.8292 - accuracy: 0.63 - ETA: 3s - loss: 5.8105 - accuracy: 0.63 - ETA: 3s - loss: 5.8079 - accuracy: 0.63 - ETA: 3s - loss: 5.8035 - accuracy: 0.63 - ETA: 3s - loss: 5.7996 - accuracy: 0.64 - ETA: 3s - loss: 5.7980 - accuracy: 0.64 - ETA: 3s - loss: 5.8077 - accuracy: 0.63 - ETA: 3s - loss: 5.7934 - accuracy: 0.64 - ETA: 2s - loss: 5.8159 - accuracy: 0.63 - ETA: 2s - loss: 5.8116 - accuracy: 0.63 - ETA: 2s - loss: 5.8032 - accuracy: 0.64 - ETA: 2s - loss: 5.8046 - accuracy: 0.63 - ETA: 2s - loss: 5.8147 - accuracy: 0.63 - ETA: 2s - loss: 5.8273 - accuracy: 0.63 - ETA: 2s - loss: 5.8371 - accuracy: 0.63 - ETA: 2s - loss: 5.8208 - accuracy: 0.63 - ETA: 2s - loss: 5.8313 - accuracy: 0.63 - ETA: 2s - loss: 5.8304 - accuracy: 0.63 - ETA: 2s - loss: 5.8301 - accuracy: 0.63 - ETA: 2s - loss: 5.8395 - accuracy: 0.63 - ETA: 2s - loss: 5.8416 - accuracy: 0.63 - ETA: 2s - loss: 5.8461 - accuracy: 0.63 - ETA: 2s - loss: 5.8341 - accuracy: 0.63 - ETA: 2s - loss: 5.8313 - accuracy: 0.63 - ETA: 2s - loss: 5.8492 - accuracy: 0.63 - ETA: 2s - loss: 5.8480 - accuracy: 0.63 - ETA: 2s - loss: 5.8527 - accuracy: 0.63 - ETA: 1s - loss: 5.8455 - accuracy: 0.63 - ETA: 1s - loss: 5.8517 - accuracy: 0.63 - ETA: 1s - loss: 5.8464 - accuracy: 0.63 - ETA: 1s - loss: 5.8406 - accuracy: 0.63 - ETA: 1s - loss: 5.8433 - accuracy: 0.63 - ETA: 1s - loss: 5.8494 - accuracy: 0.63 - ETA: 1s - loss: 5.8526 - accuracy: 0.63 - ETA: 1s - loss: 5.8509 - accuracy: 0.63 - ETA: 1s - loss: 5.8539 - accuracy: 0.63 - ETA: 1s - loss: 5.8465 - accuracy: 0.63 - ETA: 1s - loss: 5.8442 - accuracy: 0.63 - ETA: 1s - loss: 5.8417 - accuracy: 0.63 - ETA: 1s - loss: 5.8498 - accuracy: 0.63 - ETA: 1s - loss: 5.8529 - accuracy: 0.63 - ETA: 1s - loss: 5.8507 - accuracy: 0.63 - ETA: 1s - loss: 5.8540 - accuracy: 0.63 - ETA: 1s - loss: 5.8538 - accuracy: 0.63 - ETA: 1s - loss: 5.8554 - accuracy: 0.63 - ETA: 1s - loss: 5.8536 - accuracy: 0.63 - ETA: 0s - loss: 5.8483 - accuracy: 0.63 - ETA: 0s - loss: 5.8490 - accuracy: 0.63 - ETA: 0s - loss: 5.8513 - accuracy: 0.63 - ETA: 0s - loss: 5.8497 - accuracy: 0.63 - ETA: 0s - loss: 5.8549 - accuracy: 0.63 - ETA: 0s - loss: 5.8505 - accuracy: 0.63 - ETA: 0s - loss: 5.8563 - accuracy: 0.63 - ETA: 0s - loss: 5.8544 - accuracy: 0.63 - ETA: 0s - loss: 5.8444 - accuracy: 0.63 - ETA: 0s - loss: 5.8482 - accuracy: 0.63 - ETA: 0s - loss: 5.8471 - accuracy: 0.63 - ETA: 0s - loss: 5.8545 - accuracy: 0.63 - ETA: 0s - loss: 5.8576 - accuracy: 0.63 - ETA: 0s - loss: 5.8548 - accuracy: 0.63 - ETA: 0s - loss: 5.8585 - accuracy: 0.63 - ETA: 0s - loss: 5.8598 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8609 - accuracy: 0.63 - ETA: 0s - loss: 5.8552 - accuracy: 0.63 - 4s 60us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 13/50\n",
      "70000/70000 [==============================] - ETA: 6s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 5.6413 - accuracy: 0.65 - ETA: 4s - loss: 5.9891 - accuracy: 0.62 - ETA: 4s - loss: 6.0500 - accuracy: 0.62 - ETA: 3s - loss: 6.0160 - accuracy: 0.62 - ETA: 3s - loss: 5.9812 - accuracy: 0.62 - ETA: 4s - loss: 5.9424 - accuracy: 0.63 - ETA: 4s - loss: 5.9269 - accuracy: 0.63 - ETA: 4s - loss: 5.8781 - accuracy: 0.63 - ETA: 4s - loss: 5.8547 - accuracy: 0.63 - ETA: 4s - loss: 5.8500 - accuracy: 0.63 - ETA: 4s - loss: 5.8288 - accuracy: 0.63 - ETA: 4s - loss: 5.8162 - accuracy: 0.63 - ETA: 4s - loss: 5.8072 - accuracy: 0.63 - ETA: 4s - loss: 5.7968 - accuracy: 0.64 - ETA: 4s - loss: 5.8321 - accuracy: 0.63 - ETA: 3s - loss: 5.8403 - accuracy: 0.63 - ETA: 3s - loss: 5.8390 - accuracy: 0.63 - ETA: 3s - loss: 5.8412 - accuracy: 0.63 - ETA: 3s - loss: 5.8391 - accuracy: 0.63 - ETA: 3s - loss: 5.8302 - accuracy: 0.63 - ETA: 3s - loss: 5.8334 - accuracy: 0.63 - ETA: 3s - loss: 5.8204 - accuracy: 0.63 - ETA: 3s - loss: 5.8368 - accuracy: 0.63 - ETA: 3s - loss: 5.8414 - accuracy: 0.63 - ETA: 3s - loss: 5.8320 - accuracy: 0.63 - ETA: 3s - loss: 5.8394 - accuracy: 0.63 - ETA: 3s - loss: 5.8498 - accuracy: 0.63 - ETA: 3s - loss: 5.8453 - accuracy: 0.63 - ETA: 3s - loss: 5.8537 - accuracy: 0.63 - ETA: 3s - loss: 5.8538 - accuracy: 0.63 - ETA: 3s - loss: 5.8708 - accuracy: 0.63 - ETA: 3s - loss: 5.8567 - accuracy: 0.63 - ETA: 2s - loss: 5.8501 - accuracy: 0.63 - ETA: 2s - loss: 5.8517 - accuracy: 0.63 - ETA: 2s - loss: 5.8463 - accuracy: 0.63 - ETA: 2s - loss: 5.8529 - accuracy: 0.63 - ETA: 2s - loss: 5.8439 - accuracy: 0.63 - ETA: 2s - loss: 5.8411 - accuracy: 0.63 - ETA: 2s - loss: 5.8417 - accuracy: 0.63 - ETA: 2s - loss: 5.8376 - accuracy: 0.63 - ETA: 2s - loss: 5.8391 - accuracy: 0.63 - ETA: 2s - loss: 5.8401 - accuracy: 0.63 - ETA: 2s - loss: 5.8377 - accuracy: 0.63 - ETA: 2s - loss: 5.8460 - accuracy: 0.63 - ETA: 2s - loss: 5.8365 - accuracy: 0.63 - ETA: 2s - loss: 5.8486 - accuracy: 0.63 - ETA: 2s - loss: 5.8509 - accuracy: 0.63 - ETA: 2s - loss: 5.8420 - accuracy: 0.63 - ETA: 1s - loss: 5.8339 - accuracy: 0.63 - ETA: 1s - loss: 5.8321 - accuracy: 0.63 - ETA: 1s - loss: 5.8361 - accuracy: 0.63 - ETA: 1s - loss: 5.8338 - accuracy: 0.63 - ETA: 1s - loss: 5.8435 - accuracy: 0.63 - ETA: 1s - loss: 5.8445 - accuracy: 0.63 - ETA: 1s - loss: 5.8437 - accuracy: 0.63 - ETA: 1s - loss: 5.8519 - accuracy: 0.63 - ETA: 1s - loss: 5.8610 - accuracy: 0.63 - ETA: 1s - loss: 5.8593 - accuracy: 0.63 - ETA: 1s - loss: 5.8701 - accuracy: 0.63 - ETA: 1s - loss: 5.8792 - accuracy: 0.63 - ETA: 1s - loss: 5.8802 - accuracy: 0.63 - ETA: 1s - loss: 5.8820 - accuracy: 0.63 - ETA: 1s - loss: 5.8808 - accuracy: 0.63 - ETA: 1s - loss: 5.8792 - accuracy: 0.63 - ETA: 1s - loss: 5.8777 - accuracy: 0.63 - ETA: 0s - loss: 5.8708 - accuracy: 0.63 - ETA: 0s - loss: 5.8725 - accuracy: 0.63 - ETA: 0s - loss: 5.8757 - accuracy: 0.63 - ETA: 0s - loss: 5.8817 - accuracy: 0.63 - ETA: 0s - loss: 5.8810 - accuracy: 0.63 - ETA: 0s - loss: 5.8769 - accuracy: 0.63 - ETA: 0s - loss: 5.8712 - accuracy: 0.63 - ETA: 0s - loss: 5.8663 - accuracy: 0.63 - ETA: 0s - loss: 5.8668 - accuracy: 0.63 - ETA: 0s - loss: 5.8580 - accuracy: 0.63 - ETA: 0s - loss: 5.8637 - accuracy: 0.63 - ETA: 0s - loss: 5.8561 - accuracy: 0.63 - ETA: 0s - loss: 5.8549 - accuracy: 0.63 - ETA: 0s - loss: 5.8521 - accuracy: 0.63 - ETA: 0s - loss: 5.8536 - accuracy: 0.63 - ETA: 0s - loss: 5.8552 - accuracy: 0.63 - ETA: 0s - loss: 5.8481 - accuracy: 0.63 - ETA: 0s - loss: 5.8462 - accuracy: 0.63 - ETA: 0s - loss: 5.8533 - accuracy: 0.63 - 5s 66us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 14/50\n",
      "70000/70000 [==============================] - ETA: 6s - loss: 5.9637 - accuracy: 0.63 - ETA: 5s - loss: 6.1249 - accuracy: 0.62 - ETA: 4s - loss: 6.0644 - accuracy: 0.62 - ETA: 4s - loss: 6.0711 - accuracy: 0.62 - ETA: 4s - loss: 6.1249 - accuracy: 0.62 - ETA: 4s - loss: 6.0000 - accuracy: 0.62 - ETA: 4s - loss: 5.9704 - accuracy: 0.62 - ETA: 4s - loss: 5.9004 - accuracy: 0.63 - ETA: 4s - loss: 5.8957 - accuracy: 0.63 - ETA: 4s - loss: 5.8965 - accuracy: 0.63 - ETA: 4s - loss: 5.8448 - accuracy: 0.63 - ETA: 3s - loss: 5.8721 - accuracy: 0.63 - ETA: 3s - loss: 5.9133 - accuracy: 0.63 - ETA: 3s - loss: 5.9234 - accuracy: 0.63 - ETA: 3s - loss: 5.8989 - accuracy: 0.63 - ETA: 3s - loss: 5.8838 - accuracy: 0.63 - ETA: 3s - loss: 5.8769 - accuracy: 0.63 - ETA: 3s - loss: 5.8714 - accuracy: 0.63 - ETA: 3s - loss: 5.8749 - accuracy: 0.63 - ETA: 3s - loss: 5.8774 - accuracy: 0.63 - ETA: 3s - loss: 5.8592 - accuracy: 0.63 - ETA: 3s - loss: 5.8566 - accuracy: 0.63 - ETA: 3s - loss: 5.8755 - accuracy: 0.63 - ETA: 3s - loss: 5.8565 - accuracy: 0.63 - ETA: 3s - loss: 5.8428 - accuracy: 0.63 - ETA: 3s - loss: 5.8332 - accuracy: 0.63 - ETA: 3s - loss: 5.8540 - accuracy: 0.63 - ETA: 3s - loss: 5.8657 - accuracy: 0.63 - ETA: 2s - loss: 5.8558 - accuracy: 0.63 - ETA: 2s - loss: 5.8423 - accuracy: 0.63 - ETA: 2s - loss: 5.8305 - accuracy: 0.63 - ETA: 2s - loss: 5.8420 - accuracy: 0.63 - ETA: 2s - loss: 5.8414 - accuracy: 0.63 - ETA: 2s - loss: 5.8458 - accuracy: 0.63 - ETA: 2s - loss: 5.8524 - accuracy: 0.63 - ETA: 2s - loss: 5.8492 - accuracy: 0.63 - ETA: 2s - loss: 5.8519 - accuracy: 0.63 - ETA: 2s - loss: 5.8538 - accuracy: 0.63 - ETA: 2s - loss: 5.8576 - accuracy: 0.63 - ETA: 2s - loss: 5.8372 - accuracy: 0.63 - ETA: 2s - loss: 5.8324 - accuracy: 0.63 - ETA: 2s - loss: 5.8370 - accuracy: 0.63 - ETA: 2s - loss: 5.8309 - accuracy: 0.63 - ETA: 2s - loss: 5.8317 - accuracy: 0.63 - ETA: 2s - loss: 5.8350 - accuracy: 0.63 - ETA: 2s - loss: 5.8503 - accuracy: 0.63 - ETA: 2s - loss: 5.8466 - accuracy: 0.63 - ETA: 1s - loss: 5.8518 - accuracy: 0.63 - ETA: 1s - loss: 5.8492 - accuracy: 0.63 - ETA: 1s - loss: 5.8529 - accuracy: 0.63 - ETA: 1s - loss: 5.8604 - accuracy: 0.63 - ETA: 1s - loss: 5.8581 - accuracy: 0.63 - ETA: 2s - loss: 5.8546 - accuracy: 0.63 - ETA: 2s - loss: 5.8534 - accuracy: 0.63 - ETA: 2s - loss: 5.8525 - accuracy: 0.63 - ETA: 2s - loss: 5.8517 - accuracy: 0.63 - ETA: 2s - loss: 5.8512 - accuracy: 0.63 - ETA: 2s - loss: 5.8508 - accuracy: 0.63 - ETA: 2s - loss: 5.8515 - accuracy: 0.63 - ETA: 2s - loss: 5.8503 - accuracy: 0.63 - ETA: 1s - loss: 5.8522 - accuracy: 0.63 - ETA: 1s - loss: 5.8497 - accuracy: 0.63 - ETA: 1s - loss: 5.8483 - accuracy: 0.63 - ETA: 1s - loss: 5.8505 - accuracy: 0.63 - ETA: 1s - loss: 5.8459 - accuracy: 0.63 - ETA: 1s - loss: 5.8428 - accuracy: 0.63 - ETA: 1s - loss: 5.8401 - accuracy: 0.63 - ETA: 1s - loss: 5.8355 - accuracy: 0.63 - ETA: 1s - loss: 5.8383 - accuracy: 0.63 - ETA: 1s - loss: 5.8393 - accuracy: 0.63 - ETA: 1s - loss: 5.8470 - accuracy: 0.63 - ETA: 1s - loss: 5.8539 - accuracy: 0.63 - ETA: 1s - loss: 5.8495 - accuracy: 0.63 - ETA: 1s - loss: 5.8540 - accuracy: 0.63 - ETA: 1s - loss: 5.8492 - accuracy: 0.63 - ETA: 0s - loss: 5.8494 - accuracy: 0.63 - ETA: 0s - loss: 5.8519 - accuracy: 0.63 - ETA: 0s - loss: 5.8502 - accuracy: 0.63 - ETA: 0s - loss: 5.8494 - accuracy: 0.63 - ETA: 0s - loss: 5.8494 - accuracy: 0.63 - ETA: 0s - loss: 5.8548 - accuracy: 0.63 - ETA: 0s - loss: 5.8618 - accuracy: 0.63 - ETA: 0s - loss: 5.8600 - accuracy: 0.63 - ETA: 0s - loss: 5.8557 - accuracy: 0.63 - ETA: 0s - loss: 5.8597 - accuracy: 0.63 - ETA: 0s - loss: 5.8594 - accuracy: 0.63 - ETA: 0s - loss: 5.8553 - accuracy: 0.63 - ETA: 0s - loss: 5.8541 - accuracy: 0.63 - ETA: 0s - loss: 5.8518 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - ETA: 0s - loss: 5.8569 - accuracy: 0.63 - ETA: 0s - loss: 5.8544 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - 6s 82us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 6s - loss: 6.6084 - accuracy: 0.59 - ETA: 5s - loss: 5.7795 - accuracy: 0.64 - ETA: 5s - loss: 5.8486 - accuracy: 0.63 - ETA: 5s - loss: 5.6780 - accuracy: 0.64 - ETA: 4s - loss: 5.7414 - accuracy: 0.64 - ETA: 4s - loss: 5.6980 - accuracy: 0.64 - ETA: 4s - loss: 5.7201 - accuracy: 0.64 - ETA: 4s - loss: 5.7234 - accuracy: 0.64 - ETA: 4s - loss: 5.7595 - accuracy: 0.64 - ETA: 4s - loss: 5.7708 - accuracy: 0.64 - ETA: 4s - loss: 5.7689 - accuracy: 0.64 - ETA: 4s - loss: 5.7842 - accuracy: 0.64 - ETA: 4s - loss: 5.7688 - accuracy: 0.64 - ETA: 4s - loss: 5.7785 - accuracy: 0.64 - ETA: 4s - loss: 5.7757 - accuracy: 0.64 - ETA: 4s - loss: 5.7644 - accuracy: 0.64 - ETA: 4s - loss: 5.7998 - accuracy: 0.64 - ETA: 4s - loss: 5.8191 - accuracy: 0.63 - ETA: 4s - loss: 5.8134 - accuracy: 0.63 - ETA: 4s - loss: 5.8394 - accuracy: 0.63 - ETA: 3s - loss: 5.8493 - accuracy: 0.63 - ETA: 3s - loss: 5.8555 - accuracy: 0.63 - ETA: 3s - loss: 5.8453 - accuracy: 0.63 - ETA: 3s - loss: 5.8597 - accuracy: 0.63 - ETA: 3s - loss: 5.8708 - accuracy: 0.63 - ETA: 3s - loss: 5.8618 - accuracy: 0.63 - ETA: 3s - loss: 5.8501 - accuracy: 0.63 - ETA: 3s - loss: 5.8635 - accuracy: 0.63 - ETA: 3s - loss: 5.8630 - accuracy: 0.63 - ETA: 3s - loss: 5.8647 - accuracy: 0.63 - ETA: 3s - loss: 5.8497 - accuracy: 0.63 - ETA: 3s - loss: 5.8642 - accuracy: 0.63 - ETA: 3s - loss: 5.8675 - accuracy: 0.63 - ETA: 3s - loss: 5.8795 - accuracy: 0.63 - ETA: 3s - loss: 5.8764 - accuracy: 0.63 - ETA: 3s - loss: 5.8822 - accuracy: 0.63 - ETA: 3s - loss: 5.8943 - accuracy: 0.63 - ETA: 3s - loss: 5.8852 - accuracy: 0.63 - ETA: 2s - loss: 5.8840 - accuracy: 0.63 - ETA: 2s - loss: 5.8853 - accuracy: 0.63 - ETA: 2s - loss: 5.8837 - accuracy: 0.63 - ETA: 2s - loss: 5.8842 - accuracy: 0.63 - ETA: 2s - loss: 5.8857 - accuracy: 0.63 - ETA: 2s - loss: 5.8836 - accuracy: 0.63 - ETA: 2s - loss: 5.8910 - accuracy: 0.63 - ETA: 2s - loss: 5.8804 - accuracy: 0.63 - ETA: 2s - loss: 5.8822 - accuracy: 0.63 - ETA: 2s - loss: 5.8727 - accuracy: 0.63 - ETA: 2s - loss: 5.8685 - accuracy: 0.63 - ETA: 2s - loss: 5.8724 - accuracy: 0.63 - ETA: 2s - loss: 5.8753 - accuracy: 0.63 - ETA: 2s - loss: 5.8720 - accuracy: 0.63 - ETA: 2s - loss: 5.8823 - accuracy: 0.63 - ETA: 2s - loss: 5.8817 - accuracy: 0.63 - ETA: 2s - loss: 5.8849 - accuracy: 0.63 - ETA: 2s - loss: 5.8851 - accuracy: 0.63 - ETA: 2s - loss: 5.8839 - accuracy: 0.63 - ETA: 1s - loss: 5.8800 - accuracy: 0.63 - ETA: 1s - loss: 5.8700 - accuracy: 0.63 - ETA: 1s - loss: 5.8665 - accuracy: 0.63 - ETA: 1s - loss: 5.8658 - accuracy: 0.63 - ETA: 1s - loss: 5.8669 - accuracy: 0.63 - ETA: 1s - loss: 5.8647 - accuracy: 0.63 - ETA: 1s - loss: 5.8637 - accuracy: 0.63 - ETA: 1s - loss: 5.8691 - accuracy: 0.63 - ETA: 1s - loss: 5.8656 - accuracy: 0.63 - ETA: 1s - loss: 5.8644 - accuracy: 0.63 - ETA: 1s - loss: 5.8646 - accuracy: 0.63 - ETA: 1s - loss: 5.8585 - accuracy: 0.63 - ETA: 1s - loss: 5.8611 - accuracy: 0.63 - ETA: 1s - loss: 5.8614 - accuracy: 0.63 - ETA: 1s - loss: 5.8538 - accuracy: 0.63 - ETA: 1s - loss: 5.8598 - accuracy: 0.63 - ETA: 1s - loss: 5.8577 - accuracy: 0.63 - ETA: 1s - loss: 5.8586 - accuracy: 0.63 - ETA: 1s - loss: 5.8589 - accuracy: 0.63 - ETA: 1s - loss: 5.8605 - accuracy: 0.63 - ETA: 0s - loss: 5.8608 - accuracy: 0.63 - ETA: 0s - loss: 5.8568 - accuracy: 0.63 - ETA: 0s - loss: 5.8586 - accuracy: 0.63 - ETA: 0s - loss: 5.8521 - accuracy: 0.63 - ETA: 0s - loss: 5.8496 - accuracy: 0.63 - ETA: 0s - loss: 5.8508 - accuracy: 0.63 - ETA: 0s - loss: 5.8471 - accuracy: 0.63 - ETA: 0s - loss: 5.8450 - accuracy: 0.63 - ETA: 0s - loss: 5.8401 - accuracy: 0.63 - ETA: 0s - loss: 5.8397 - accuracy: 0.63 - ETA: 0s - loss: 5.8387 - accuracy: 0.63 - ETA: 0s - loss: 5.8378 - accuracy: 0.63 - ETA: 0s - loss: 5.8411 - accuracy: 0.63 - ETA: 0s - loss: 5.8445 - accuracy: 0.63 - ETA: 0s - loss: 5.8455 - accuracy: 0.63 - ETA: 0s - loss: 5.8451 - accuracy: 0.63 - ETA: 0s - loss: 5.8486 - accuracy: 0.63 - ETA: 0s - loss: 5.8518 - accuracy: 0.63 - ETA: 0s - loss: 5.8526 - accuracy: 0.63 - 5s 72us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 16/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 4.5131 - accuracy: 0.72 - ETA: 4s - loss: 5.7846 - accuracy: 0.64 - ETA: 5s - loss: 5.9637 - accuracy: 0.63 - ETA: 5s - loss: 5.7879 - accuracy: 0.64 - ETA: 5s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 5.7345 - accuracy: 0.64 - ETA: 4s - loss: 5.7478 - accuracy: 0.64 - ETA: 4s - loss: 5.7058 - accuracy: 0.64 - ETA: 4s - loss: 5.7400 - accuracy: 0.64 - ETA: 4s - loss: 5.6653 - accuracy: 0.64 - ETA: 4s - loss: 5.6831 - accuracy: 0.64 - ETA: 4s - loss: 5.7065 - accuracy: 0.64 - ETA: 4s - loss: 5.6648 - accuracy: 0.64 - ETA: 4s - loss: 5.6914 - accuracy: 0.64 - ETA: 4s - loss: 5.7096 - accuracy: 0.64 - ETA: 4s - loss: 5.7226 - accuracy: 0.64 - ETA: 4s - loss: 5.7466 - accuracy: 0.64 - ETA: 4s - loss: 5.7500 - accuracy: 0.64 - ETA: 4s - loss: 5.7402 - accuracy: 0.64 - ETA: 4s - loss: 5.7443 - accuracy: 0.64 - ETA: 4s - loss: 5.7289 - accuracy: 0.64 - ETA: 4s - loss: 5.7525 - accuracy: 0.64 - ETA: 3s - loss: 5.7384 - accuracy: 0.64 - ETA: 3s - loss: 5.7164 - accuracy: 0.64 - ETA: 3s - loss: 5.7286 - accuracy: 0.64 - ETA: 3s - loss: 5.7241 - accuracy: 0.64 - ETA: 3s - loss: 5.7372 - accuracy: 0.64 - ETA: 3s - loss: 5.7406 - accuracy: 0.64 - ETA: 3s - loss: 5.7567 - accuracy: 0.64 - ETA: 3s - loss: 5.7517 - accuracy: 0.64 - ETA: 3s - loss: 5.7576 - accuracy: 0.64 - ETA: 3s - loss: 5.7762 - accuracy: 0.64 - ETA: 3s - loss: 5.7911 - accuracy: 0.64 - ETA: 3s - loss: 5.8019 - accuracy: 0.64 - ETA: 3s - loss: 5.8019 - accuracy: 0.64 - ETA: 3s - loss: 5.8275 - accuracy: 0.63 - ETA: 3s - loss: 5.8363 - accuracy: 0.63 - ETA: 3s - loss: 5.8326 - accuracy: 0.63 - ETA: 2s - loss: 5.8200 - accuracy: 0.63 - ETA: 2s - loss: 5.8207 - accuracy: 0.63 - ETA: 2s - loss: 5.8207 - accuracy: 0.63 - ETA: 2s - loss: 5.8198 - accuracy: 0.63 - ETA: 2s - loss: 5.8266 - accuracy: 0.63 - ETA: 2s - loss: 5.8381 - accuracy: 0.63 - ETA: 2s - loss: 5.8407 - accuracy: 0.63 - ETA: 2s - loss: 5.8414 - accuracy: 0.63 - ETA: 2s - loss: 5.8462 - accuracy: 0.63 - ETA: 2s - loss: 5.8438 - accuracy: 0.63 - ETA: 2s - loss: 5.8457 - accuracy: 0.63 - ETA: 2s - loss: 5.8506 - accuracy: 0.63 - ETA: 2s - loss: 5.8658 - accuracy: 0.63 - ETA: 2s - loss: 5.8666 - accuracy: 0.63 - ETA: 2s - loss: 5.8587 - accuracy: 0.63 - ETA: 2s - loss: 5.8609 - accuracy: 0.63 - ETA: 2s - loss: 5.8577 - accuracy: 0.63 - ETA: 2s - loss: 5.8557 - accuracy: 0.63 - ETA: 2s - loss: 5.8482 - accuracy: 0.63 - ETA: 2s - loss: 5.8417 - accuracy: 0.63 - ETA: 1s - loss: 5.8406 - accuracy: 0.63 - ETA: 1s - loss: 5.8352 - accuracy: 0.63 - ETA: 1s - loss: 5.8321 - accuracy: 0.63 - ETA: 1s - loss: 5.8254 - accuracy: 0.63 - ETA: 1s - loss: 5.8166 - accuracy: 0.63 - ETA: 1s - loss: 5.8227 - accuracy: 0.63 - ETA: 1s - loss: 5.8237 - accuracy: 0.63 - ETA: 1s - loss: 5.8323 - accuracy: 0.63 - ETA: 1s - loss: 5.8355 - accuracy: 0.63 - ETA: 1s - loss: 5.8413 - accuracy: 0.63 - ETA: 1s - loss: 5.8464 - accuracy: 0.63 - ETA: 1s - loss: 5.8535 - accuracy: 0.63 - ETA: 1s - loss: 5.8546 - accuracy: 0.63 - ETA: 1s - loss: 5.8538 - accuracy: 0.63 - ETA: 1s - loss: 5.8507 - accuracy: 0.63 - ETA: 1s - loss: 5.8528 - accuracy: 0.63 - ETA: 1s - loss: 5.8480 - accuracy: 0.63 - ETA: 1s - loss: 5.8407 - accuracy: 0.63 - ETA: 1s - loss: 5.8448 - accuracy: 0.63 - ETA: 0s - loss: 5.8423 - accuracy: 0.63 - ETA: 0s - loss: 5.8440 - accuracy: 0.63 - ETA: 0s - loss: 5.8466 - accuracy: 0.63 - ETA: 0s - loss: 5.8504 - accuracy: 0.63 - ETA: 0s - loss: 5.8517 - accuracy: 0.63 - ETA: 0s - loss: 5.8493 - accuracy: 0.63 - ETA: 0s - loss: 5.8468 - accuracy: 0.63 - ETA: 0s - loss: 5.8444 - accuracy: 0.63 - ETA: 0s - loss: 5.8439 - accuracy: 0.63 - ETA: 0s - loss: 5.8438 - accuracy: 0.63 - ETA: 0s - loss: 5.8474 - accuracy: 0.63 - ETA: 0s - loss: 5.8496 - accuracy: 0.63 - ETA: 0s - loss: 5.8501 - accuracy: 0.63 - ETA: 0s - loss: 5.8531 - accuracy: 0.63 - ETA: 0s - loss: 5.8542 - accuracy: 0.63 - ETA: 0s - loss: 5.8586 - accuracy: 0.63 - ETA: 0s - loss: 5.8599 - accuracy: 0.63 - ETA: 0s - loss: 5.8603 - accuracy: 0.63 - ETA: 0s - loss: 5.8551 - accuracy: 0.63 - ETA: 0s - loss: 5.8580 - accuracy: 0.63 - 5s 73us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 10s - loss: 6.9308 - accuracy: 0.570 - ETA: 5s - loss: 6.3666 - accuracy: 0.605 - ETA: 5s - loss: 6.2323 - accuracy: 0.61 - ETA: 5s - loss: 5.9930 - accuracy: 0.62 - ETA: 5s - loss: 5.9359 - accuracy: 0.63 - ETA: 4s - loss: 5.9861 - accuracy: 0.62 - ETA: 4s - loss: 6.0199 - accuracy: 0.62 - ETA: 4s - loss: 6.0153 - accuracy: 0.62 - ETA: 4s - loss: 6.0316 - accuracy: 0.62 - ETA: 4s - loss: 6.0216 - accuracy: 0.62 - ETA: 4s - loss: 5.9977 - accuracy: 0.62 - ETA: 4s - loss: 5.9800 - accuracy: 0.62 - ETA: 4s - loss: 5.9806 - accuracy: 0.62 - ETA: 4s - loss: 5.9949 - accuracy: 0.62 - ETA: 4s - loss: 5.9734 - accuracy: 0.62 - ETA: 4s - loss: 5.9846 - accuracy: 0.62 - ETA: 4s - loss: 5.9694 - accuracy: 0.62 - ETA: 4s - loss: 6.0094 - accuracy: 0.62 - ETA: 4s - loss: 5.9931 - accuracy: 0.62 - ETA: 4s - loss: 6.0015 - accuracy: 0.62 - ETA: 4s - loss: 5.9846 - accuracy: 0.62 - ETA: 4s - loss: 5.9793 - accuracy: 0.62 - ETA: 4s - loss: 5.9890 - accuracy: 0.62 - ETA: 4s - loss: 5.9897 - accuracy: 0.62 - ETA: 4s - loss: 5.9608 - accuracy: 0.63 - ETA: 4s - loss: 5.9536 - accuracy: 0.63 - ETA: 3s - loss: 5.9398 - accuracy: 0.63 - ETA: 3s - loss: 5.9296 - accuracy: 0.63 - ETA: 3s - loss: 5.9275 - accuracy: 0.63 - ETA: 3s - loss: 5.9216 - accuracy: 0.63 - ETA: 3s - loss: 5.9092 - accuracy: 0.63 - ETA: 3s - loss: 5.9050 - accuracy: 0.63 - ETA: 3s - loss: 5.9033 - accuracy: 0.63 - ETA: 3s - loss: 5.9013 - accuracy: 0.63 - ETA: 3s - loss: 5.8865 - accuracy: 0.63 - ETA: 3s - loss: 5.8765 - accuracy: 0.63 - ETA: 3s - loss: 5.8767 - accuracy: 0.63 - ETA: 3s - loss: 5.8691 - accuracy: 0.63 - ETA: 3s - loss: 5.8607 - accuracy: 0.63 - ETA: 3s - loss: 5.8531 - accuracy: 0.63 - ETA: 3s - loss: 5.8512 - accuracy: 0.63 - ETA: 3s - loss: 5.8461 - accuracy: 0.63 - ETA: 3s - loss: 5.8527 - accuracy: 0.63 - ETA: 3s - loss: 5.8586 - accuracy: 0.63 - ETA: 3s - loss: 5.8662 - accuracy: 0.63 - ETA: 2s - loss: 5.8681 - accuracy: 0.63 - ETA: 2s - loss: 5.8687 - accuracy: 0.63 - ETA: 2s - loss: 5.8643 - accuracy: 0.63 - ETA: 2s - loss: 5.8640 - accuracy: 0.63 - ETA: 2s - loss: 5.8677 - accuracy: 0.63 - ETA: 2s - loss: 5.8649 - accuracy: 0.63 - ETA: 2s - loss: 5.8644 - accuracy: 0.63 - ETA: 2s - loss: 5.8643 - accuracy: 0.63 - ETA: 2s - loss: 5.8669 - accuracy: 0.63 - ETA: 2s - loss: 5.8691 - accuracy: 0.63 - ETA: 2s - loss: 5.8666 - accuracy: 0.63 - ETA: 2s - loss: 5.8672 - accuracy: 0.63 - ETA: 2s - loss: 5.8660 - accuracy: 0.63 - ETA: 2s - loss: 5.8673 - accuracy: 0.63 - ETA: 2s - loss: 5.8623 - accuracy: 0.63 - ETA: 2s - loss: 5.8655 - accuracy: 0.63 - ETA: 2s - loss: 5.8641 - accuracy: 0.63 - ETA: 2s - loss: 5.8693 - accuracy: 0.63 - ETA: 1s - loss: 5.8600 - accuracy: 0.63 - ETA: 1s - loss: 5.8658 - accuracy: 0.63 - ETA: 1s - loss: 5.8643 - accuracy: 0.63 - ETA: 1s - loss: 5.8553 - accuracy: 0.63 - ETA: 1s - loss: 5.8559 - accuracy: 0.63 - ETA: 1s - loss: 5.8521 - accuracy: 0.63 - ETA: 1s - loss: 5.8537 - accuracy: 0.63 - ETA: 1s - loss: 5.8483 - accuracy: 0.63 - ETA: 1s - loss: 5.8504 - accuracy: 0.63 - ETA: 1s - loss: 5.8517 - accuracy: 0.63 - ETA: 1s - loss: 5.8580 - accuracy: 0.63 - ETA: 1s - loss: 5.8607 - accuracy: 0.63 - ETA: 1s - loss: 5.8532 - accuracy: 0.63 - ETA: 1s - loss: 5.8546 - accuracy: 0.63 - ETA: 1s - loss: 5.8563 - accuracy: 0.63 - ETA: 1s - loss: 5.8613 - accuracy: 0.63 - ETA: 1s - loss: 5.8570 - accuracy: 0.63 - ETA: 1s - loss: 5.8591 - accuracy: 0.63 - ETA: 1s - loss: 5.8614 - accuracy: 0.63 - ETA: 0s - loss: 5.8613 - accuracy: 0.63 - ETA: 0s - loss: 5.8587 - accuracy: 0.63 - ETA: 0s - loss: 5.8577 - accuracy: 0.63 - ETA: 0s - loss: 5.8530 - accuracy: 0.63 - ETA: 0s - loss: 5.8535 - accuracy: 0.63 - ETA: 0s - loss: 5.8579 - accuracy: 0.63 - ETA: 0s - loss: 5.8646 - accuracy: 0.63 - ETA: 0s - loss: 5.8659 - accuracy: 0.63 - ETA: 0s - loss: 5.8609 - accuracy: 0.63 - ETA: 0s - loss: 5.8650 - accuracy: 0.63 - ETA: 0s - loss: 5.8586 - accuracy: 0.63 - ETA: 0s - loss: 5.8557 - accuracy: 0.63 - ETA: 0s - loss: 5.8576 - accuracy: 0.63 - ETA: 0s - loss: 5.8529 - accuracy: 0.63 - ETA: 0s - loss: 5.8550 - accuracy: 0.63 - ETA: 0s - loss: 5.8557 - accuracy: 0.63 - ETA: 0s - loss: 5.8580 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - ETA: 0s - loss: 5.8556 - accuracy: 0.63 - 5s 75us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 18/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 5.3190 - accuracy: 0.67 - ETA: 5s - loss: 5.6212 - accuracy: 0.65 - ETA: 5s - loss: 5.8126 - accuracy: 0.63 - ETA: 4s - loss: 5.8227 - accuracy: 0.63 - ETA: 4s - loss: 5.7773 - accuracy: 0.64 - ETA: 4s - loss: 5.7743 - accuracy: 0.64 - ETA: 4s - loss: 5.8162 - accuracy: 0.63 - ETA: 4s - loss: 5.8260 - accuracy: 0.63 - ETA: 4s - loss: 5.8493 - accuracy: 0.63 - ETA: 4s - loss: 5.8749 - accuracy: 0.63 - ETA: 4s - loss: 5.8519 - accuracy: 0.63 - ETA: 4s - loss: 5.8929 - accuracy: 0.63 - ETA: 4s - loss: 5.8867 - accuracy: 0.63 - ETA: 4s - loss: 5.9205 - accuracy: 0.63 - ETA: 4s - loss: 5.9371 - accuracy: 0.63 - ETA: 4s - loss: 5.9388 - accuracy: 0.63 - ETA: 4s - loss: 5.9375 - accuracy: 0.63 - ETA: 4s - loss: 5.9377 - accuracy: 0.63 - ETA: 4s - loss: 5.9476 - accuracy: 0.63 - ETA: 4s - loss: 5.9216 - accuracy: 0.63 - ETA: 4s - loss: 5.9226 - accuracy: 0.63 - ETA: 4s - loss: 5.9050 - accuracy: 0.63 - ETA: 4s - loss: 5.9045 - accuracy: 0.63 - ETA: 3s - loss: 5.8963 - accuracy: 0.63 - ETA: 3s - loss: 5.8981 - accuracy: 0.63 - ETA: 3s - loss: 5.8827 - accuracy: 0.63 - ETA: 3s - loss: 5.8853 - accuracy: 0.63 - ETA: 3s - loss: 5.8827 - accuracy: 0.63 - ETA: 3s - loss: 5.8847 - accuracy: 0.63 - ETA: 3s - loss: 5.8866 - accuracy: 0.63 - ETA: 3s - loss: 5.8899 - accuracy: 0.63 - ETA: 3s - loss: 5.8798 - accuracy: 0.63 - ETA: 3s - loss: 5.8835 - accuracy: 0.63 - ETA: 3s - loss: 5.8739 - accuracy: 0.63 - ETA: 3s - loss: 5.8801 - accuracy: 0.63 - ETA: 3s - loss: 5.8825 - accuracy: 0.63 - ETA: 3s - loss: 5.8853 - accuracy: 0.63 - ETA: 3s - loss: 5.8807 - accuracy: 0.63 - ETA: 3s - loss: 5.8837 - accuracy: 0.63 - ETA: 3s - loss: 5.8817 - accuracy: 0.63 - ETA: 3s - loss: 5.8735 - accuracy: 0.63 - ETA: 3s - loss: 5.8702 - accuracy: 0.63 - ETA: 2s - loss: 5.8847 - accuracy: 0.63 - ETA: 2s - loss: 5.8765 - accuracy: 0.63 - ETA: 2s - loss: 5.8790 - accuracy: 0.63 - ETA: 2s - loss: 5.8736 - accuracy: 0.63 - ETA: 2s - loss: 5.8821 - accuracy: 0.63 - ETA: 2s - loss: 5.8860 - accuracy: 0.63 - ETA: 2s - loss: 5.8850 - accuracy: 0.63 - ETA: 2s - loss: 5.8901 - accuracy: 0.63 - ETA: 2s - loss: 5.8813 - accuracy: 0.63 - ETA: 2s - loss: 5.8864 - accuracy: 0.63 - ETA: 2s - loss: 5.8792 - accuracy: 0.63 - ETA: 2s - loss: 5.8782 - accuracy: 0.63 - ETA: 2s - loss: 5.8764 - accuracy: 0.63 - ETA: 2s - loss: 5.8817 - accuracy: 0.63 - ETA: 2s - loss: 5.8916 - accuracy: 0.63 - ETA: 2s - loss: 5.8934 - accuracy: 0.63 - ETA: 2s - loss: 5.9027 - accuracy: 0.63 - ETA: 2s - loss: 5.9102 - accuracy: 0.63 - ETA: 2s - loss: 5.9103 - accuracy: 0.63 - ETA: 1s - loss: 5.9113 - accuracy: 0.63 - ETA: 1s - loss: 5.9078 - accuracy: 0.63 - ETA: 1s - loss: 5.9091 - accuracy: 0.63 - ETA: 1s - loss: 5.9108 - accuracy: 0.63 - ETA: 1s - loss: 5.9030 - accuracy: 0.63 - ETA: 1s - loss: 5.8988 - accuracy: 0.63 - ETA: 1s - loss: 5.8993 - accuracy: 0.63 - ETA: 1s - loss: 5.8968 - accuracy: 0.63 - ETA: 1s - loss: 5.8906 - accuracy: 0.63 - ETA: 1s - loss: 5.8831 - accuracy: 0.63 - ETA: 1s - loss: 5.8895 - accuracy: 0.63 - ETA: 1s - loss: 5.8922 - accuracy: 0.63 - ETA: 1s - loss: 5.8836 - accuracy: 0.63 - ETA: 1s - loss: 5.8817 - accuracy: 0.63 - ETA: 1s - loss: 5.8859 - accuracy: 0.63 - ETA: 1s - loss: 5.8905 - accuracy: 0.63 - ETA: 1s - loss: 5.8923 - accuracy: 0.63 - ETA: 1s - loss: 5.8961 - accuracy: 0.63 - ETA: 0s - loss: 5.8923 - accuracy: 0.63 - ETA: 0s - loss: 5.8818 - accuracy: 0.63 - ETA: 0s - loss: 5.8823 - accuracy: 0.63 - ETA: 0s - loss: 5.8798 - accuracy: 0.63 - ETA: 0s - loss: 5.8791 - accuracy: 0.63 - ETA: 0s - loss: 5.8717 - accuracy: 0.63 - ETA: 0s - loss: 5.8660 - accuracy: 0.63 - ETA: 0s - loss: 5.8727 - accuracy: 0.63 - ETA: 0s - loss: 5.8696 - accuracy: 0.63 - ETA: 0s - loss: 5.8718 - accuracy: 0.63 - ETA: 0s - loss: 5.8702 - accuracy: 0.63 - ETA: 0s - loss: 5.8691 - accuracy: 0.63 - ETA: 0s - loss: 5.8651 - accuracy: 0.63 - ETA: 0s - loss: 5.8614 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8563 - accuracy: 0.63 - ETA: 0s - loss: 5.8566 - accuracy: 0.63 - ETA: 0s - loss: 5.8574 - accuracy: 0.63 - 5s 72us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 19/50\n",
      "70000/70000 [==============================] - ETA: 6s - loss: 6.1249 - accuracy: 0.62 - ETA: 4s - loss: 6.1070 - accuracy: 0.62 - ETA: 4s - loss: 6.1249 - accuracy: 0.62 - ETA: 4s - loss: 5.9959 - accuracy: 0.62 - ETA: 4s - loss: 6.0077 - accuracy: 0.62 - ETA: 4s - loss: 5.9205 - accuracy: 0.63 - ETA: 4s - loss: 5.8387 - accuracy: 0.63 - ETA: 4s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 5.8358 - accuracy: 0.63 - ETA: 4s - loss: 5.8209 - accuracy: 0.63 - ETA: 4s - loss: 5.7962 - accuracy: 0.64 - ETA: 4s - loss: 5.7779 - accuracy: 0.64 - ETA: 4s - loss: 5.7748 - accuracy: 0.64 - ETA: 4s - loss: 5.7850 - accuracy: 0.64 - ETA: 4s - loss: 5.7892 - accuracy: 0.64 - ETA: 3s - loss: 5.8011 - accuracy: 0.64 - ETA: 3s - loss: 5.8025 - accuracy: 0.64 - ETA: 3s - loss: 5.8037 - accuracy: 0.63 - ETA: 3s - loss: 5.8174 - accuracy: 0.63 - ETA: 3s - loss: 5.8145 - accuracy: 0.63 - ETA: 3s - loss: 5.8015 - accuracy: 0.64 - ETA: 3s - loss: 5.8015 - accuracy: 0.64 - ETA: 3s - loss: 5.8016 - accuracy: 0.64 - ETA: 3s - loss: 5.7826 - accuracy: 0.64 - ETA: 3s - loss: 5.7817 - accuracy: 0.64 - ETA: 3s - loss: 5.8050 - accuracy: 0.63 - ETA: 3s - loss: 5.8033 - accuracy: 0.64 - ETA: 3s - loss: 5.7987 - accuracy: 0.64 - ETA: 3s - loss: 5.7987 - accuracy: 0.64 - ETA: 3s - loss: 5.7923 - accuracy: 0.64 - ETA: 3s - loss: 5.7863 - accuracy: 0.64 - ETA: 3s - loss: 5.8073 - accuracy: 0.63 - ETA: 3s - loss: 5.8204 - accuracy: 0.63 - ETA: 3s - loss: 5.8179 - accuracy: 0.63 - ETA: 3s - loss: 5.8187 - accuracy: 0.63 - ETA: 3s - loss: 5.8285 - accuracy: 0.63 - ETA: 2s - loss: 5.8254 - accuracy: 0.63 - ETA: 2s - loss: 5.8259 - accuracy: 0.63 - ETA: 2s - loss: 5.8396 - accuracy: 0.63 - ETA: 2s - loss: 5.8500 - accuracy: 0.63 - ETA: 2s - loss: 5.8513 - accuracy: 0.63 - ETA: 2s - loss: 5.8451 - accuracy: 0.63 - ETA: 2s - loss: 5.8431 - accuracy: 0.63 - ETA: 2s - loss: 5.8445 - accuracy: 0.63 - ETA: 2s - loss: 5.8450 - accuracy: 0.63 - ETA: 2s - loss: 5.8477 - accuracy: 0.63 - ETA: 2s - loss: 5.8476 - accuracy: 0.63 - ETA: 2s - loss: 5.8476 - accuracy: 0.63 - ETA: 2s - loss: 5.8527 - accuracy: 0.63 - ETA: 2s - loss: 5.8521 - accuracy: 0.63 - ETA: 2s - loss: 5.8548 - accuracy: 0.63 - ETA: 2s - loss: 5.8572 - accuracy: 0.63 - ETA: 2s - loss: 5.8571 - accuracy: 0.63 - ETA: 2s - loss: 5.8595 - accuracy: 0.63 - ETA: 2s - loss: 5.8537 - accuracy: 0.63 - ETA: 2s - loss: 5.8521 - accuracy: 0.63 - ETA: 1s - loss: 5.8528 - accuracy: 0.63 - ETA: 1s - loss: 5.8515 - accuracy: 0.63 - ETA: 1s - loss: 5.8543 - accuracy: 0.63 - ETA: 1s - loss: 5.8650 - accuracy: 0.63 - ETA: 1s - loss: 5.8646 - accuracy: 0.63 - ETA: 1s - loss: 5.8589 - accuracy: 0.63 - ETA: 1s - loss: 5.8591 - accuracy: 0.63 - ETA: 1s - loss: 5.8551 - accuracy: 0.63 - ETA: 1s - loss: 5.8606 - accuracy: 0.63 - ETA: 1s - loss: 5.8561 - accuracy: 0.63 - ETA: 1s - loss: 5.8527 - accuracy: 0.63 - ETA: 1s - loss: 5.8527 - accuracy: 0.63 - ETA: 1s - loss: 5.8560 - accuracy: 0.63 - ETA: 1s - loss: 5.8496 - accuracy: 0.63 - ETA: 1s - loss: 5.8523 - accuracy: 0.63 - ETA: 1s - loss: 5.8509 - accuracy: 0.63 - ETA: 1s - loss: 5.8521 - accuracy: 0.63 - ETA: 1s - loss: 5.8473 - accuracy: 0.63 - ETA: 0s - loss: 5.8472 - accuracy: 0.63 - ETA: 0s - loss: 5.8432 - accuracy: 0.63 - ETA: 0s - loss: 5.8504 - accuracy: 0.63 - ETA: 0s - loss: 5.8441 - accuracy: 0.63 - ETA: 0s - loss: 5.8460 - accuracy: 0.63 - ETA: 0s - loss: 5.8471 - accuracy: 0.63 - ETA: 0s - loss: 5.8465 - accuracy: 0.63 - ETA: 0s - loss: 5.8478 - accuracy: 0.63 - ETA: 0s - loss: 5.8535 - accuracy: 0.63 - ETA: 0s - loss: 5.8511 - accuracy: 0.63 - ETA: 0s - loss: 5.8506 - accuracy: 0.63 - ETA: 0s - loss: 5.8504 - accuracy: 0.63 - ETA: 0s - loss: 5.8505 - accuracy: 0.63 - ETA: 0s - loss: 5.8475 - accuracy: 0.63 - ETA: 0s - loss: 5.8518 - accuracy: 0.63 - ETA: 0s - loss: 5.8554 - accuracy: 0.63 - ETA: 0s - loss: 5.8546 - accuracy: 0.63 - ETA: 0s - loss: 5.8500 - accuracy: 0.63 - ETA: 0s - loss: 5.8506 - accuracy: 0.63 - ETA: 0s - loss: 5.8541 - accuracy: 0.63 - 5s 70us/sample - loss: 5.8557 - accuracy: 0.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "70000/70000 [==============================] - ETA: 6s - loss: 5.1578 - accuracy: 0.68 - ETA: 4s - loss: 5.7667 - accuracy: 0.64 - ETA: 4s - loss: 5.8594 - accuracy: 0.63 - ETA: 4s - loss: 5.9637 - accuracy: 0.63 - ETA: 4s - loss: 5.8961 - accuracy: 0.63 - ETA: 4s - loss: 5.8873 - accuracy: 0.63 - ETA: 4s - loss: 5.8491 - accuracy: 0.63 - ETA: 4s - loss: 5.8174 - accuracy: 0.63 - ETA: 4s - loss: 5.7791 - accuracy: 0.64 - ETA: 4s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 5.8087 - accuracy: 0.63 - ETA: 4s - loss: 5.8081 - accuracy: 0.63 - ETA: 4s - loss: 5.7689 - accuracy: 0.64 - ETA: 4s - loss: 5.7993 - accuracy: 0.64 - ETA: 4s - loss: 5.7664 - accuracy: 0.64 - ETA: 4s - loss: 5.7507 - accuracy: 0.64 - ETA: 3s - loss: 5.7501 - accuracy: 0.64 - ETA: 3s - loss: 5.7496 - accuracy: 0.64 - ETA: 3s - loss: 5.7573 - accuracy: 0.64 - ETA: 3s - loss: 5.7521 - accuracy: 0.64 - ETA: 3s - loss: 5.7599 - accuracy: 0.64 - ETA: 3s - loss: 5.7458 - accuracy: 0.64 - ETA: 3s - loss: 5.7636 - accuracy: 0.64 - ETA: 3s - loss: 5.7488 - accuracy: 0.64 - ETA: 3s - loss: 5.7755 - accuracy: 0.64 - ETA: 3s - loss: 5.8017 - accuracy: 0.64 - ETA: 3s - loss: 5.7889 - accuracy: 0.64 - ETA: 3s - loss: 5.8102 - accuracy: 0.63 - ETA: 3s - loss: 5.7996 - accuracy: 0.64 - ETA: 3s - loss: 5.7982 - accuracy: 0.64 - ETA: 3s - loss: 5.7928 - accuracy: 0.64 - ETA: 3s - loss: 5.7925 - accuracy: 0.64 - ETA: 3s - loss: 5.7941 - accuracy: 0.64 - ETA: 2s - loss: 5.7919 - accuracy: 0.64 - ETA: 2s - loss: 5.7776 - accuracy: 0.64 - ETA: 2s - loss: 5.7872 - accuracy: 0.64 - ETA: 2s - loss: 5.7882 - accuracy: 0.64 - ETA: 2s - loss: 5.7925 - accuracy: 0.64 - ETA: 2s - loss: 5.7949 - accuracy: 0.64 - ETA: 2s - loss: 5.7978 - accuracy: 0.64 - ETA: 2s - loss: 5.8010 - accuracy: 0.64 - ETA: 2s - loss: 5.8055 - accuracy: 0.63 - ETA: 2s - loss: 5.8119 - accuracy: 0.63 - ETA: 2s - loss: 5.8107 - accuracy: 0.63 - ETA: 2s - loss: 5.8152 - accuracy: 0.63 - ETA: 2s - loss: 5.8208 - accuracy: 0.63 - ETA: 2s - loss: 5.8240 - accuracy: 0.63 - ETA: 2s - loss: 5.8275 - accuracy: 0.63 - ETA: 2s - loss: 5.8232 - accuracy: 0.63 - ETA: 2s - loss: 5.8211 - accuracy: 0.63 - ETA: 2s - loss: 5.8204 - accuracy: 0.63 - ETA: 2s - loss: 5.8281 - accuracy: 0.63 - ETA: 1s - loss: 5.8149 - accuracy: 0.63 - ETA: 1s - loss: 5.8205 - accuracy: 0.63 - ETA: 1s - loss: 5.8086 - accuracy: 0.63 - ETA: 1s - loss: 5.8104 - accuracy: 0.63 - ETA: 1s - loss: 5.8188 - accuracy: 0.63 - ETA: 1s - loss: 5.8239 - accuracy: 0.63 - ETA: 1s - loss: 5.8264 - accuracy: 0.63 - ETA: 1s - loss: 5.8348 - accuracy: 0.63 - ETA: 1s - loss: 5.8304 - accuracy: 0.63 - ETA: 1s - loss: 5.8297 - accuracy: 0.63 - ETA: 1s - loss: 5.8335 - accuracy: 0.63 - ETA: 1s - loss: 5.8324 - accuracy: 0.63 - ETA: 1s - loss: 5.8335 - accuracy: 0.63 - ETA: 1s - loss: 5.8323 - accuracy: 0.63 - ETA: 1s - loss: 5.8256 - accuracy: 0.63 - ETA: 1s - loss: 5.8296 - accuracy: 0.63 - ETA: 1s - loss: 5.8307 - accuracy: 0.63 - ETA: 1s - loss: 5.8315 - accuracy: 0.63 - ETA: 1s - loss: 5.8282 - accuracy: 0.63 - ETA: 0s - loss: 5.8319 - accuracy: 0.63 - ETA: 0s - loss: 5.8409 - accuracy: 0.63 - ETA: 0s - loss: 5.8412 - accuracy: 0.63 - ETA: 0s - loss: 5.8490 - accuracy: 0.63 - ETA: 0s - loss: 5.8500 - accuracy: 0.63 - ETA: 0s - loss: 5.8521 - accuracy: 0.63 - ETA: 0s - loss: 5.8481 - accuracy: 0.63 - ETA: 0s - loss: 5.8460 - accuracy: 0.63 - ETA: 0s - loss: 5.8513 - accuracy: 0.63 - ETA: 0s - loss: 5.8502 - accuracy: 0.63 - ETA: 0s - loss: 5.8517 - accuracy: 0.63 - ETA: 0s - loss: 5.8522 - accuracy: 0.63 - ETA: 0s - loss: 5.8502 - accuracy: 0.63 - ETA: 0s - loss: 5.8519 - accuracy: 0.63 - ETA: 0s - loss: 5.8567 - accuracy: 0.63 - ETA: 0s - loss: 5.8569 - accuracy: 0.63 - ETA: 0s - loss: 5.8569 - accuracy: 0.63 - ETA: 0s - loss: 5.8543 - accuracy: 0.63 - ETA: 0s - loss: 5.8588 - accuracy: 0.63 - ETA: 0s - loss: 5.8596 - accuracy: 0.63 - 5s 69us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 21/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 6.7696 - accuracy: 0.58 - ETA: 4s - loss: 5.7488 - accuracy: 0.64 - ETA: 4s - loss: 5.7741 - accuracy: 0.64 - ETA: 4s - loss: 5.7421 - accuracy: 0.64 - ETA: 4s - loss: 5.7975 - accuracy: 0.64 - ETA: 4s - loss: 5.8630 - accuracy: 0.63 - ETA: 4s - loss: 5.8965 - accuracy: 0.63 - ETA: 4s - loss: 5.9608 - accuracy: 0.63 - ETA: 4s - loss: 5.9816 - accuracy: 0.62 - ETA: 4s - loss: 5.9614 - accuracy: 0.63 - ETA: 4s - loss: 5.9214 - accuracy: 0.63 - ETA: 4s - loss: 5.9526 - accuracy: 0.63 - ETA: 4s - loss: 5.9162 - accuracy: 0.63 - ETA: 4s - loss: 5.9293 - accuracy: 0.63 - ETA: 3s - loss: 5.9100 - accuracy: 0.63 - ETA: 3s - loss: 5.9163 - accuracy: 0.63 - ETA: 3s - loss: 5.8990 - accuracy: 0.63 - ETA: 3s - loss: 5.8777 - accuracy: 0.63 - ETA: 3s - loss: 5.8808 - accuracy: 0.63 - ETA: 3s - loss: 5.8702 - accuracy: 0.63 - ETA: 3s - loss: 5.9025 - accuracy: 0.63 - ETA: 3s - loss: 5.9054 - accuracy: 0.63 - ETA: 3s - loss: 5.9264 - accuracy: 0.63 - ETA: 3s - loss: 5.9261 - accuracy: 0.63 - ETA: 3s - loss: 5.9240 - accuracy: 0.63 - ETA: 3s - loss: 5.9086 - accuracy: 0.63 - ETA: 3s - loss: 5.8886 - accuracy: 0.63 - ETA: 3s - loss: 5.8656 - accuracy: 0.63 - ETA: 3s - loss: 5.8655 - accuracy: 0.63 - ETA: 3s - loss: 5.8558 - accuracy: 0.63 - ETA: 3s - loss: 5.8409 - accuracy: 0.63 - ETA: 3s - loss: 5.8365 - accuracy: 0.63 - ETA: 3s - loss: 5.8302 - accuracy: 0.63 - ETA: 2s - loss: 5.8294 - accuracy: 0.63 - ETA: 2s - loss: 5.8255 - accuracy: 0.63 - ETA: 2s - loss: 5.8250 - accuracy: 0.63 - ETA: 2s - loss: 5.8186 - accuracy: 0.63 - ETA: 2s - loss: 5.8299 - accuracy: 0.63 - ETA: 2s - loss: 5.8248 - accuracy: 0.63 - ETA: 2s - loss: 5.8248 - accuracy: 0.63 - ETA: 2s - loss: 5.8294 - accuracy: 0.63 - ETA: 2s - loss: 5.8388 - accuracy: 0.63 - ETA: 2s - loss: 5.8325 - accuracy: 0.63 - ETA: 2s - loss: 5.8279 - accuracy: 0.63 - ETA: 2s - loss: 5.8278 - accuracy: 0.63 - ETA: 2s - loss: 5.8324 - accuracy: 0.63 - ETA: 2s - loss: 5.8375 - accuracy: 0.63 - ETA: 2s - loss: 5.8398 - accuracy: 0.63 - ETA: 2s - loss: 5.8451 - accuracy: 0.63 - ETA: 2s - loss: 5.8513 - accuracy: 0.63 - ETA: 2s - loss: 5.8536 - accuracy: 0.63 - ETA: 2s - loss: 5.8490 - accuracy: 0.63 - ETA: 1s - loss: 5.8466 - accuracy: 0.63 - ETA: 1s - loss: 5.8403 - accuracy: 0.63 - ETA: 1s - loss: 5.8426 - accuracy: 0.63 - ETA: 1s - loss: 5.8456 - accuracy: 0.63 - ETA: 1s - loss: 5.8405 - accuracy: 0.63 - ETA: 1s - loss: 5.8385 - accuracy: 0.63 - ETA: 1s - loss: 5.8310 - accuracy: 0.63 - ETA: 1s - loss: 5.8271 - accuracy: 0.63 - ETA: 1s - loss: 5.8229 - accuracy: 0.63 - ETA: 1s - loss: 5.8202 - accuracy: 0.63 - ETA: 1s - loss: 5.8182 - accuracy: 0.63 - ETA: 1s - loss: 5.8219 - accuracy: 0.63 - ETA: 1s - loss: 5.8233 - accuracy: 0.63 - ETA: 1s - loss: 5.8214 - accuracy: 0.63 - ETA: 1s - loss: 5.8227 - accuracy: 0.63 - ETA: 1s - loss: 5.8202 - accuracy: 0.63 - ETA: 1s - loss: 5.8178 - accuracy: 0.63 - ETA: 1s - loss: 5.8196 - accuracy: 0.63 - ETA: 1s - loss: 5.8147 - accuracy: 0.63 - ETA: 1s - loss: 5.8127 - accuracy: 0.63 - ETA: 0s - loss: 5.8186 - accuracy: 0.63 - ETA: 0s - loss: 5.8227 - accuracy: 0.63 - ETA: 0s - loss: 5.8171 - accuracy: 0.63 - ETA: 0s - loss: 5.8253 - accuracy: 0.63 - ETA: 0s - loss: 5.8286 - accuracy: 0.63 - ETA: 0s - loss: 5.8320 - accuracy: 0.63 - ETA: 0s - loss: 5.8316 - accuracy: 0.63 - ETA: 0s - loss: 5.8341 - accuracy: 0.63 - ETA: 0s - loss: 5.8351 - accuracy: 0.63 - ETA: 0s - loss: 5.8398 - accuracy: 0.63 - ETA: 0s - loss: 5.8377 - accuracy: 0.63 - ETA: 0s - loss: 5.8416 - accuracy: 0.63 - ETA: 0s - loss: 5.8431 - accuracy: 0.63 - ETA: 0s - loss: 5.8453 - accuracy: 0.63 - ETA: 0s - loss: 5.8494 - accuracy: 0.63 - ETA: 0s - loss: 5.8530 - accuracy: 0.63 - ETA: 0s - loss: 5.8547 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - ETA: 0s - loss: 5.8538 - accuracy: 0.63 - 5s 68us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 22/50\n",
      "70000/70000 [==============================] - ETA: 5s - loss: 6.4472 - accuracy: 0.60 - ETA: 5s - loss: 5.6010 - accuracy: 0.65 - ETA: 5s - loss: 5.7918 - accuracy: 0.64 - ETA: 4s - loss: 5.8305 - accuracy: 0.63 - ETA: 4s - loss: 5.8493 - accuracy: 0.63 - ETA: 4s - loss: 5.8480 - accuracy: 0.63 - ETA: 4s - loss: 5.9911 - accuracy: 0.62 - ETA: 4s - loss: 6.0135 - accuracy: 0.62 - ETA: 4s - loss: 6.0079 - accuracy: 0.62 - ETA: 4s - loss: 5.9798 - accuracy: 0.62 - ETA: 4s - loss: 5.9678 - accuracy: 0.62 - ETA: 4s - loss: 5.9846 - accuracy: 0.62 - ETA: 4s - loss: 5.9843 - accuracy: 0.62 - ETA: 4s - loss: 5.9890 - accuracy: 0.62 - ETA: 4s - loss: 5.9446 - accuracy: 0.63 - ETA: 3s - loss: 5.9323 - accuracy: 0.63 - ETA: 3s - loss: 5.9471 - accuracy: 0.63 - ETA: 3s - loss: 5.9382 - accuracy: 0.63 - ETA: 3s - loss: 5.9214 - accuracy: 0.63 - ETA: 3s - loss: 5.9237 - accuracy: 0.63 - ETA: 3s - loss: 5.9144 - accuracy: 0.63 - ETA: 3s - loss: 5.9070 - accuracy: 0.63 - ETA: 3s - loss: 5.8850 - accuracy: 0.63 - ETA: 3s - loss: 5.9048 - accuracy: 0.63 - ETA: 3s - loss: 5.8857 - accuracy: 0.63 - ETA: 3s - loss: 5.8753 - accuracy: 0.63 - ETA: 3s - loss: 5.8859 - accuracy: 0.63 - ETA: 3s - loss: 5.8636 - accuracy: 0.63 - ETA: 3s - loss: 5.8621 - accuracy: 0.63 - ETA: 3s - loss: 5.8614 - accuracy: 0.63 - ETA: 3s - loss: 5.8624 - accuracy: 0.63 - ETA: 3s - loss: 5.8458 - accuracy: 0.63 - ETA: 3s - loss: 5.8457 - accuracy: 0.63 - ETA: 2s - loss: 5.8456 - accuracy: 0.63 - ETA: 2s - loss: 5.8335 - accuracy: 0.63 - ETA: 2s - loss: 5.8320 - accuracy: 0.63 - ETA: 2s - loss: 5.8382 - accuracy: 0.63 - ETA: 2s - loss: 5.8340 - accuracy: 0.63 - ETA: 2s - loss: 5.8419 - accuracy: 0.63 - ETA: 2s - loss: 5.8515 - accuracy: 0.63 - ETA: 2s - loss: 5.8503 - accuracy: 0.63 - ETA: 2s - loss: 5.8562 - accuracy: 0.63 - ETA: 2s - loss: 5.8620 - accuracy: 0.63 - ETA: 2s - loss: 5.8650 - accuracy: 0.63 - ETA: 2s - loss: 5.8687 - accuracy: 0.63 - ETA: 2s - loss: 5.8667 - accuracy: 0.63 - ETA: 2s - loss: 5.8761 - accuracy: 0.63 - ETA: 2s - loss: 5.8767 - accuracy: 0.63 - ETA: 2s - loss: 5.8669 - accuracy: 0.63 - ETA: 2s - loss: 5.8685 - accuracy: 0.63 - ETA: 2s - loss: 5.8709 - accuracy: 0.63 - ETA: 2s - loss: 5.8671 - accuracy: 0.63 - ETA: 1s - loss: 5.8606 - accuracy: 0.63 - ETA: 1s - loss: 5.8572 - accuracy: 0.63 - ETA: 1s - loss: 5.8573 - accuracy: 0.63 - ETA: 1s - loss: 5.8559 - accuracy: 0.63 - ETA: 1s - loss: 5.8562 - accuracy: 0.63 - ETA: 1s - loss: 5.8565 - accuracy: 0.63 - ETA: 1s - loss: 5.8538 - accuracy: 0.63 - ETA: 1s - loss: 5.8549 - accuracy: 0.63 - ETA: 1s - loss: 5.8503 - accuracy: 0.63 - ETA: 1s - loss: 5.8457 - accuracy: 0.63 - ETA: 1s - loss: 5.8514 - accuracy: 0.63 - ETA: 1s - loss: 5.8469 - accuracy: 0.63 - ETA: 1s - loss: 5.8498 - accuracy: 0.63 - ETA: 1s - loss: 5.8484 - accuracy: 0.63 - ETA: 1s - loss: 5.8505 - accuracy: 0.63 - ETA: 1s - loss: 5.8510 - accuracy: 0.63 - ETA: 1s - loss: 5.8580 - accuracy: 0.63 - ETA: 1s - loss: 5.8576 - accuracy: 0.63 - ETA: 1s - loss: 5.8526 - accuracy: 0.63 - ETA: 1s - loss: 5.8563 - accuracy: 0.63 - ETA: 1s - loss: 5.8581 - accuracy: 0.63 - ETA: 1s - loss: 5.8578 - accuracy: 0.63 - ETA: 0s - loss: 5.8592 - accuracy: 0.63 - ETA: 0s - loss: 5.8608 - accuracy: 0.63 - ETA: 0s - loss: 5.8594 - accuracy: 0.63 - ETA: 0s - loss: 5.8595 - accuracy: 0.63 - ETA: 0s - loss: 5.8595 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - ETA: 0s - loss: 5.8556 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8542 - accuracy: 0.63 - ETA: 0s - loss: 5.8564 - accuracy: 0.63 - ETA: 0s - loss: 5.8590 - accuracy: 0.63 - ETA: 0s - loss: 5.8641 - accuracy: 0.63 - ETA: 0s - loss: 5.8624 - accuracy: 0.63 - ETA: 0s - loss: 5.8583 - accuracy: 0.63 - ETA: 0s - loss: 5.8596 - accuracy: 0.63 - ETA: 0s - loss: 5.8620 - accuracy: 0.63 - ETA: 0s - loss: 5.8620 - accuracy: 0.63 - ETA: 0s - loss: 5.8606 - accuracy: 0.63 - ETA: 0s - loss: 5.8546 - accuracy: 0.63 - ETA: 0s - loss: 5.8557 - accuracy: 0.63 - 5s 71us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 23/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 7.5755 - accuracy: 0.53 - ETA: 5s - loss: 6.0443 - accuracy: 0.62 - ETA: 5s - loss: 5.9315 - accuracy: 0.63 - ETA: 5s - loss: 5.7181 - accuracy: 0.64 - ETA: 5s - loss: 5.8859 - accuracy: 0.63 - ETA: 4s - loss: 5.9158 - accuracy: 0.63 - ETA: 4s - loss: 5.9315 - accuracy: 0.63 - ETA: 4s - loss: 5.8907 - accuracy: 0.63 - ETA: 4s - loss: 5.8517 - accuracy: 0.63 - ETA: 4s - loss: 5.8855 - accuracy: 0.63 - ETA: 4s - loss: 5.8504 - accuracy: 0.63 - ETA: 4s - loss: 5.8549 - accuracy: 0.63 - ETA: 4s - loss: 5.8473 - accuracy: 0.63 - ETA: 4s - loss: 5.8765 - accuracy: 0.63 - ETA: 4s - loss: 5.8588 - accuracy: 0.63 - ETA: 4s - loss: 5.8638 - accuracy: 0.63 - ETA: 4s - loss: 5.8571 - accuracy: 0.63 - ETA: 3s - loss: 5.8712 - accuracy: 0.63 - ETA: 4s - loss: 5.8704 - accuracy: 0.63 - ETA: 4s - loss: 5.8668 - accuracy: 0.63 - ETA: 4s - loss: 5.8732 - accuracy: 0.63 - ETA: 3s - loss: 5.8689 - accuracy: 0.63 - ETA: 3s - loss: 5.8881 - accuracy: 0.63 - ETA: 3s - loss: 5.8807 - accuracy: 0.63 - ETA: 3s - loss: 5.8794 - accuracy: 0.63 - ETA: 3s - loss: 5.8675 - accuracy: 0.63 - ETA: 3s - loss: 5.8690 - accuracy: 0.63 - ETA: 3s - loss: 5.8766 - accuracy: 0.63 - ETA: 3s - loss: 5.8612 - accuracy: 0.63 - ETA: 3s - loss: 5.8628 - accuracy: 0.63 - ETA: 3s - loss: 5.8526 - accuracy: 0.63 - ETA: 3s - loss: 5.8490 - accuracy: 0.63 - ETA: 3s - loss: 5.8688 - accuracy: 0.63 - ETA: 3s - loss: 5.8637 - accuracy: 0.63 - ETA: 3s - loss: 5.8771 - accuracy: 0.63 - ETA: 3s - loss: 5.8655 - accuracy: 0.63 - ETA: 3s - loss: 5.8687 - accuracy: 0.63 - ETA: 3s - loss: 5.8740 - accuracy: 0.63 - ETA: 2s - loss: 5.8728 - accuracy: 0.63 - ETA: 2s - loss: 5.8731 - accuracy: 0.63 - ETA: 2s - loss: 5.8745 - accuracy: 0.63 - ETA: 2s - loss: 5.8749 - accuracy: 0.63 - ETA: 2s - loss: 5.8723 - accuracy: 0.63 - ETA: 2s - loss: 5.8783 - accuracy: 0.63 - ETA: 2s - loss: 5.8725 - accuracy: 0.63 - ETA: 2s - loss: 5.8670 - accuracy: 0.63 - ETA: 2s - loss: 5.8699 - accuracy: 0.63 - ETA: 2s - loss: 5.8727 - accuracy: 0.63 - ETA: 2s - loss: 5.8743 - accuracy: 0.63 - ETA: 2s - loss: 5.8773 - accuracy: 0.63 - ETA: 2s - loss: 5.8659 - accuracy: 0.63 - ETA: 2s - loss: 5.8633 - accuracy: 0.63 - ETA: 2s - loss: 5.8562 - accuracy: 0.63 - ETA: 2s - loss: 5.8535 - accuracy: 0.63 - ETA: 2s - loss: 5.8607 - accuracy: 0.63 - ETA: 2s - loss: 5.8668 - accuracy: 0.63 - ETA: 2s - loss: 5.8713 - accuracy: 0.63 - ETA: 1s - loss: 5.8688 - accuracy: 0.63 - ETA: 1s - loss: 5.8672 - accuracy: 0.63 - ETA: 1s - loss: 5.8653 - accuracy: 0.63 - ETA: 1s - loss: 5.8689 - accuracy: 0.63 - ETA: 1s - loss: 5.8680 - accuracy: 0.63 - ETA: 1s - loss: 5.8685 - accuracy: 0.63 - ETA: 1s - loss: 5.8592 - accuracy: 0.63 - ETA: 1s - loss: 5.8616 - accuracy: 0.63 - ETA: 1s - loss: 5.8597 - accuracy: 0.63 - ETA: 1s - loss: 5.8538 - accuracy: 0.63 - ETA: 1s - loss: 5.8617 - accuracy: 0.63 - ETA: 1s - loss: 5.8573 - accuracy: 0.63 - ETA: 1s - loss: 5.8556 - accuracy: 0.63 - ETA: 1s - loss: 5.8561 - accuracy: 0.63 - ETA: 1s - loss: 5.8590 - accuracy: 0.63 - ETA: 1s - loss: 5.8617 - accuracy: 0.63 - ETA: 1s - loss: 5.8561 - accuracy: 0.63 - ETA: 1s - loss: 5.8594 - accuracy: 0.63 - ETA: 0s - loss: 5.8556 - accuracy: 0.63 - ETA: 0s - loss: 5.8585 - accuracy: 0.63 - ETA: 0s - loss: 5.8600 - accuracy: 0.63 - ETA: 0s - loss: 5.8600 - accuracy: 0.63 - ETA: 0s - loss: 5.8604 - accuracy: 0.63 - ETA: 0s - loss: 5.8639 - accuracy: 0.63 - ETA: 0s - loss: 5.8620 - accuracy: 0.63 - ETA: 0s - loss: 5.8629 - accuracy: 0.63 - ETA: 0s - loss: 5.8639 - accuracy: 0.63 - ETA: 0s - loss: 5.8680 - accuracy: 0.63 - ETA: 0s - loss: 5.8679 - accuracy: 0.63 - ETA: 0s - loss: 5.8655 - accuracy: 0.63 - ETA: 0s - loss: 5.8602 - accuracy: 0.63 - ETA: 0s - loss: 5.8619 - accuracy: 0.63 - ETA: 0s - loss: 5.8616 - accuracy: 0.63 - ETA: 0s - loss: 5.8628 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8537 - accuracy: 0.63 - ETA: 0s - loss: 5.8552 - accuracy: 0.63 - 5s 71us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 9s - loss: 7.2531 - accuracy: 0.55 - ETA: 5s - loss: 6.1965 - accuracy: 0.61 - ETA: 5s - loss: 5.9133 - accuracy: 0.63 - ETA: 4s - loss: 5.9234 - accuracy: 0.63 - ETA: 4s - loss: 5.8579 - accuracy: 0.63 - ETA: 4s - loss: 5.7501 - accuracy: 0.64 - ETA: 4s - loss: 5.8395 - accuracy: 0.63 - ETA: 4s - loss: 5.8227 - accuracy: 0.63 - ETA: 4s - loss: 5.8076 - accuracy: 0.63 - ETA: 4s - loss: 5.8092 - accuracy: 0.63 - ETA: 4s - loss: 5.7846 - accuracy: 0.64 - ETA: 3s - loss: 5.7609 - accuracy: 0.64 - ETA: 3s - loss: 5.7404 - accuracy: 0.64 - ETA: 3s - loss: 5.7399 - accuracy: 0.64 - ETA: 3s - loss: 5.7677 - accuracy: 0.64 - ETA: 3s - loss: 5.8228 - accuracy: 0.63 - ETA: 3s - loss: 5.8304 - accuracy: 0.63 - ETA: 3s - loss: 5.8206 - accuracy: 0.63 - ETA: 3s - loss: 5.8275 - accuracy: 0.63 - ETA: 3s - loss: 5.8223 - accuracy: 0.63 - ETA: 3s - loss: 5.8121 - accuracy: 0.63 - ETA: 3s - loss: 5.8176 - accuracy: 0.63 - ETA: 3s - loss: 5.8275 - accuracy: 0.63 - ETA: 3s - loss: 5.8470 - accuracy: 0.63 - ETA: 3s - loss: 5.8433 - accuracy: 0.63 - ETA: 3s - loss: 5.8426 - accuracy: 0.63 - ETA: 3s - loss: 5.8527 - accuracy: 0.63 - ETA: 3s - loss: 5.8468 - accuracy: 0.63 - ETA: 3s - loss: 5.8481 - accuracy: 0.63 - ETA: 3s - loss: 5.8362 - accuracy: 0.63 - ETA: 3s - loss: 5.8449 - accuracy: 0.63 - ETA: 3s - loss: 5.8606 - accuracy: 0.63 - ETA: 3s - loss: 5.8692 - accuracy: 0.63 - ETA: 3s - loss: 5.8607 - accuracy: 0.63 - ETA: 3s - loss: 5.8664 - accuracy: 0.63 - ETA: 3s - loss: 5.8747 - accuracy: 0.63 - ETA: 2s - loss: 5.8761 - accuracy: 0.63 - ETA: 2s - loss: 5.8722 - accuracy: 0.63 - ETA: 2s - loss: 5.8680 - accuracy: 0.63 - ETA: 2s - loss: 5.8711 - accuracy: 0.63 - ETA: 2s - loss: 5.8757 - accuracy: 0.63 - ETA: 2s - loss: 5.8759 - accuracy: 0.63 - ETA: 2s - loss: 5.8745 - accuracy: 0.63 - ETA: 2s - loss: 5.8674 - accuracy: 0.63 - ETA: 2s - loss: 5.8704 - accuracy: 0.63 - ETA: 2s - loss: 5.8683 - accuracy: 0.63 - ETA: 2s - loss: 5.8755 - accuracy: 0.63 - ETA: 2s - loss: 5.8784 - accuracy: 0.63 - ETA: 2s - loss: 5.8712 - accuracy: 0.63 - ETA: 2s - loss: 5.8676 - accuracy: 0.63 - ETA: 2s - loss: 5.8569 - accuracy: 0.63 - ETA: 2s - loss: 5.8518 - accuracy: 0.63 - ETA: 2s - loss: 5.8545 - accuracy: 0.63 - ETA: 2s - loss: 5.8503 - accuracy: 0.63 - ETA: 2s - loss: 5.8458 - accuracy: 0.63 - ETA: 1s - loss: 5.8454 - accuracy: 0.63 - ETA: 1s - loss: 5.8439 - accuracy: 0.63 - ETA: 1s - loss: 5.8421 - accuracy: 0.63 - ETA: 1s - loss: 5.8436 - accuracy: 0.63 - ETA: 1s - loss: 5.8444 - accuracy: 0.63 - ETA: 1s - loss: 5.8472 - accuracy: 0.63 - ETA: 1s - loss: 5.8484 - accuracy: 0.63 - ETA: 1s - loss: 5.8490 - accuracy: 0.63 - ETA: 1s - loss: 5.8498 - accuracy: 0.63 - ETA: 1s - loss: 5.8516 - accuracy: 0.63 - ETA: 1s - loss: 5.8615 - accuracy: 0.63 - ETA: 1s - loss: 5.8575 - accuracy: 0.63 - ETA: 1s - loss: 5.8652 - accuracy: 0.63 - ETA: 1s - loss: 5.8651 - accuracy: 0.63 - ETA: 1s - loss: 5.8736 - accuracy: 0.63 - ETA: 1s - loss: 5.8642 - accuracy: 0.63 - ETA: 1s - loss: 5.8654 - accuracy: 0.63 - ETA: 1s - loss: 5.8654 - accuracy: 0.63 - ETA: 0s - loss: 5.8626 - accuracy: 0.63 - ETA: 0s - loss: 5.8578 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8659 - accuracy: 0.63 - ETA: 0s - loss: 5.8610 - accuracy: 0.63 - ETA: 0s - loss: 5.8630 - accuracy: 0.63 - ETA: 0s - loss: 5.8646 - accuracy: 0.63 - ETA: 0s - loss: 5.8679 - accuracy: 0.63 - ETA: 0s - loss: 5.8654 - accuracy: 0.63 - ETA: 0s - loss: 5.8628 - accuracy: 0.63 - ETA: 0s - loss: 5.8602 - accuracy: 0.63 - ETA: 0s - loss: 5.8639 - accuracy: 0.63 - ETA: 0s - loss: 5.8661 - accuracy: 0.63 - ETA: 0s - loss: 5.8641 - accuracy: 0.63 - ETA: 0s - loss: 5.8649 - accuracy: 0.63 - ETA: 0s - loss: 5.8635 - accuracy: 0.63 - ETA: 0s - loss: 5.8627 - accuracy: 0.63 - ETA: 0s - loss: 5.8645 - accuracy: 0.63 - ETA: 0s - loss: 5.8578 - accuracy: 0.63 - 5s 70us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 25/50\n",
      "70000/70000 [==============================] - ETA: 5s - loss: 7.0920 - accuracy: 0.56 - ETA: 5s - loss: 6.1450 - accuracy: 0.61 - ETA: 5s - loss: 5.9959 - accuracy: 0.62 - ETA: 4s - loss: 6.0688 - accuracy: 0.62 - ETA: 4s - loss: 6.0521 - accuracy: 0.62 - ETA: 4s - loss: 6.0298 - accuracy: 0.62 - ETA: 4s - loss: 6.0220 - accuracy: 0.62 - ETA: 4s - loss: 6.0018 - accuracy: 0.62 - ETA: 4s - loss: 5.9954 - accuracy: 0.62 - ETA: 4s - loss: 5.9447 - accuracy: 0.63 - ETA: 4s - loss: 5.9891 - accuracy: 0.62 - ETA: 4s - loss: 5.9851 - accuracy: 0.62 - ETA: 4s - loss: 5.9655 - accuracy: 0.62 - ETA: 4s - loss: 5.9012 - accuracy: 0.63 - ETA: 4s - loss: 5.8885 - accuracy: 0.63 - ETA: 4s - loss: 5.9009 - accuracy: 0.63 - ETA: 4s - loss: 5.8764 - accuracy: 0.63 - ETA: 4s - loss: 5.8894 - accuracy: 0.63 - ETA: 3s - loss: 5.8890 - accuracy: 0.63 - ETA: 3s - loss: 5.8769 - accuracy: 0.63 - ETA: 3s - loss: 5.8863 - accuracy: 0.63 - ETA: 3s - loss: 5.8692 - accuracy: 0.63 - ETA: 3s - loss: 5.8846 - accuracy: 0.63 - ETA: 3s - loss: 5.8929 - accuracy: 0.63 - ETA: 3s - loss: 5.8840 - accuracy: 0.63 - ETA: 3s - loss: 5.8908 - accuracy: 0.63 - ETA: 3s - loss: 5.8972 - accuracy: 0.63 - ETA: 3s - loss: 5.9052 - accuracy: 0.63 - ETA: 3s - loss: 5.8901 - accuracy: 0.63 - ETA: 3s - loss: 5.9010 - accuracy: 0.63 - ETA: 3s - loss: 5.9033 - accuracy: 0.63 - ETA: 3s - loss: 5.9051 - accuracy: 0.63 - ETA: 3s - loss: 5.9034 - accuracy: 0.63 - ETA: 3s - loss: 5.9065 - accuracy: 0.63 - ETA: 3s - loss: 5.8953 - accuracy: 0.63 - ETA: 3s - loss: 5.8944 - accuracy: 0.63 - ETA: 3s - loss: 5.8913 - accuracy: 0.63 - ETA: 3s - loss: 5.8769 - accuracy: 0.63 - ETA: 3s - loss: 5.8618 - accuracy: 0.63 - ETA: 2s - loss: 5.8553 - accuracy: 0.63 - ETA: 2s - loss: 5.8619 - accuracy: 0.63 - ETA: 2s - loss: 5.8584 - accuracy: 0.63 - ETA: 2s - loss: 5.8566 - accuracy: 0.63 - ETA: 2s - loss: 5.8544 - accuracy: 0.63 - ETA: 2s - loss: 5.8688 - accuracy: 0.63 - ETA: 2s - loss: 5.8693 - accuracy: 0.63 - ETA: 2s - loss: 5.8725 - accuracy: 0.63 - ETA: 2s - loss: 5.8713 - accuracy: 0.63 - ETA: 2s - loss: 5.8705 - accuracy: 0.63 - ETA: 2s - loss: 5.8602 - accuracy: 0.63 - ETA: 2s - loss: 5.8640 - accuracy: 0.63 - ETA: 2s - loss: 5.8548 - accuracy: 0.63 - ETA: 2s - loss: 5.8558 - accuracy: 0.63 - ETA: 2s - loss: 5.8501 - accuracy: 0.63 - ETA: 2s - loss: 5.8368 - accuracy: 0.63 - ETA: 2s - loss: 5.8357 - accuracy: 0.63 - ETA: 2s - loss: 5.8379 - accuracy: 0.63 - ETA: 2s - loss: 5.8384 - accuracy: 0.63 - ETA: 2s - loss: 5.8465 - accuracy: 0.63 - ETA: 1s - loss: 5.8447 - accuracy: 0.63 - ETA: 1s - loss: 5.8358 - accuracy: 0.63 - ETA: 1s - loss: 5.8352 - accuracy: 0.63 - ETA: 1s - loss: 5.8375 - accuracy: 0.63 - ETA: 1s - loss: 5.8348 - accuracy: 0.63 - ETA: 1s - loss: 5.8346 - accuracy: 0.63 - ETA: 1s - loss: 5.8364 - accuracy: 0.63 - ETA: 1s - loss: 5.8369 - accuracy: 0.63 - ETA: 1s - loss: 5.8373 - accuracy: 0.63 - ETA: 1s - loss: 5.8351 - accuracy: 0.63 - ETA: 1s - loss: 5.8356 - accuracy: 0.63 - ETA: 1s - loss: 5.8374 - accuracy: 0.63 - ETA: 1s - loss: 5.8347 - accuracy: 0.63 - ETA: 1s - loss: 5.8366 - accuracy: 0.63 - ETA: 1s - loss: 5.8337 - accuracy: 0.63 - ETA: 1s - loss: 5.8312 - accuracy: 0.63 - ETA: 1s - loss: 5.8352 - accuracy: 0.63 - ETA: 1s - loss: 5.8327 - accuracy: 0.63 - ETA: 0s - loss: 5.8329 - accuracy: 0.63 - ETA: 0s - loss: 5.8330 - accuracy: 0.63 - ETA: 0s - loss: 5.8293 - accuracy: 0.63 - ETA: 0s - loss: 5.8251 - accuracy: 0.63 - ETA: 0s - loss: 5.8327 - accuracy: 0.63 - ETA: 0s - loss: 5.8380 - accuracy: 0.63 - ETA: 0s - loss: 5.8397 - accuracy: 0.63 - ETA: 0s - loss: 5.8409 - accuracy: 0.63 - ETA: 0s - loss: 5.8425 - accuracy: 0.63 - ETA: 0s - loss: 5.8417 - accuracy: 0.63 - ETA: 0s - loss: 5.8425 - accuracy: 0.63 - ETA: 0s - loss: 5.8417 - accuracy: 0.63 - ETA: 0s - loss: 5.8410 - accuracy: 0.63 - ETA: 0s - loss: 5.8421 - accuracy: 0.63 - ETA: 0s - loss: 5.8443 - accuracy: 0.63 - ETA: 0s - loss: 5.8455 - accuracy: 0.63 - ETA: 0s - loss: 5.8492 - accuracy: 0.63 - ETA: 0s - loss: 5.8544 - accuracy: 0.63 - ETA: 0s - loss: 5.8579 - accuracy: 0.63 - 5s 72us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 26/50\n",
      "70000/70000 [==============================] - ETA: 10s - loss: 4.0295 - accuracy: 0.750 - ETA: 5s - loss: 6.1652 - accuracy: 0.617 - ETA: 5s - loss: 6.0040 - accuracy: 0.62 - ETA: 5s - loss: 5.8305 - accuracy: 0.63 - ETA: 4s - loss: 5.8337 - accuracy: 0.63 - ETA: 4s - loss: 5.9348 - accuracy: 0.63 - ETA: 4s - loss: 5.9157 - accuracy: 0.63 - ETA: 4s - loss: 5.9995 - accuracy: 0.62 - ETA: 4s - loss: 5.9975 - accuracy: 0.62 - ETA: 4s - loss: 5.9752 - accuracy: 0.62 - ETA: 4s - loss: 5.9534 - accuracy: 0.63 - ETA: 4s - loss: 5.9431 - accuracy: 0.63 - ETA: 4s - loss: 5.9534 - accuracy: 0.63 - ETA: 4s - loss: 5.9206 - accuracy: 0.63 - ETA: 4s - loss: 5.9040 - accuracy: 0.63 - ETA: 4s - loss: 5.9137 - accuracy: 0.63 - ETA: 4s - loss: 5.9165 - accuracy: 0.63 - ETA: 4s - loss: 5.9091 - accuracy: 0.63 - ETA: 3s - loss: 5.8889 - accuracy: 0.63 - ETA: 3s - loss: 5.8776 - accuracy: 0.63 - ETA: 3s - loss: 5.8826 - accuracy: 0.63 - ETA: 3s - loss: 5.8746 - accuracy: 0.63 - ETA: 3s - loss: 5.8547 - accuracy: 0.63 - ETA: 3s - loss: 5.8433 - accuracy: 0.63 - ETA: 3s - loss: 5.8458 - accuracy: 0.63 - ETA: 3s - loss: 5.8382 - accuracy: 0.63 - ETA: 3s - loss: 5.8296 - accuracy: 0.63 - ETA: 3s - loss: 5.8264 - accuracy: 0.63 - ETA: 3s - loss: 5.8204 - accuracy: 0.63 - ETA: 3s - loss: 5.8199 - accuracy: 0.63 - ETA: 3s - loss: 5.8312 - accuracy: 0.63 - ETA: 3s - loss: 5.8202 - accuracy: 0.63 - ETA: 3s - loss: 5.8170 - accuracy: 0.63 - ETA: 3s - loss: 5.8369 - accuracy: 0.63 - ETA: 3s - loss: 5.8322 - accuracy: 0.63 - ETA: 2s - loss: 5.8391 - accuracy: 0.63 - ETA: 2s - loss: 5.8386 - accuracy: 0.63 - ETA: 2s - loss: 5.8478 - accuracy: 0.63 - ETA: 2s - loss: 5.8438 - accuracy: 0.63 - ETA: 2s - loss: 5.8229 - accuracy: 0.63 - ETA: 2s - loss: 5.8282 - accuracy: 0.63 - ETA: 2s - loss: 5.8260 - accuracy: 0.63 - ETA: 2s - loss: 5.8294 - accuracy: 0.63 - ETA: 2s - loss: 5.8321 - accuracy: 0.63 - ETA: 2s - loss: 5.8423 - accuracy: 0.63 - ETA: 2s - loss: 5.8363 - accuracy: 0.63 - ETA: 2s - loss: 5.8338 - accuracy: 0.63 - ETA: 2s - loss: 5.8482 - accuracy: 0.63 - ETA: 2s - loss: 5.8533 - accuracy: 0.63 - ETA: 2s - loss: 5.8599 - accuracy: 0.63 - ETA: 2s - loss: 5.8631 - accuracy: 0.63 - ETA: 2s - loss: 5.8648 - accuracy: 0.63 - ETA: 2s - loss: 5.8627 - accuracy: 0.63 - ETA: 2s - loss: 5.8732 - accuracy: 0.63 - ETA: 1s - loss: 5.8711 - accuracy: 0.63 - ETA: 1s - loss: 5.8744 - accuracy: 0.63 - ETA: 1s - loss: 5.8812 - accuracy: 0.63 - ETA: 1s - loss: 5.8816 - accuracy: 0.63 - ETA: 1s - loss: 5.8899 - accuracy: 0.63 - ETA: 1s - loss: 5.8835 - accuracy: 0.63 - ETA: 1s - loss: 5.8796 - accuracy: 0.63 - ETA: 1s - loss: 5.8746 - accuracy: 0.63 - ETA: 1s - loss: 5.8734 - accuracy: 0.63 - ETA: 1s - loss: 5.8755 - accuracy: 0.63 - ETA: 1s - loss: 5.8760 - accuracy: 0.63 - ETA: 1s - loss: 5.8728 - accuracy: 0.63 - ETA: 1s - loss: 5.8765 - accuracy: 0.63 - ETA: 1s - loss: 5.8731 - accuracy: 0.63 - ETA: 1s - loss: 5.8748 - accuracy: 0.63 - ETA: 1s - loss: 5.8796 - accuracy: 0.63 - ETA: 1s - loss: 5.8841 - accuracy: 0.63 - ETA: 1s - loss: 5.8824 - accuracy: 0.63 - ETA: 0s - loss: 5.8840 - accuracy: 0.63 - ETA: 0s - loss: 5.8810 - accuracy: 0.63 - ETA: 0s - loss: 5.8785 - accuracy: 0.63 - ETA: 0s - loss: 5.8765 - accuracy: 0.63 - ETA: 0s - loss: 5.8741 - accuracy: 0.63 - ETA: 0s - loss: 5.8716 - accuracy: 0.63 - ETA: 0s - loss: 5.8694 - accuracy: 0.63 - ETA: 0s - loss: 5.8631 - accuracy: 0.63 - ETA: 0s - loss: 5.8624 - accuracy: 0.63 - ETA: 0s - loss: 5.8681 - accuracy: 0.63 - ETA: 0s - loss: 5.8671 - accuracy: 0.63 - ETA: 0s - loss: 5.8643 - accuracy: 0.63 - ETA: 0s - loss: 5.8638 - accuracy: 0.63 - ETA: 0s - loss: 5.8655 - accuracy: 0.63 - ETA: 0s - loss: 5.8652 - accuracy: 0.63 - ETA: 0s - loss: 5.8658 - accuracy: 0.63 - ETA: 0s - loss: 5.8653 - accuracy: 0.63 - ETA: 0s - loss: 5.8664 - accuracy: 0.63 - ETA: 0s - loss: 5.8602 - accuracy: 0.63 - 5s 69us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 27/50\n",
      "70000/70000 [==============================] - ETA: 5s - loss: 5.4802 - accuracy: 0.66 - ETA: 5s - loss: 6.1479 - accuracy: 0.61 - ETA: 5s - loss: 6.0819 - accuracy: 0.62 - ETA: 4s - loss: 6.1319 - accuracy: 0.61 - ETA: 4s - loss: 6.0521 - accuracy: 0.62 - ETA: 5s - loss: 6.0129 - accuracy: 0.62 - ETA: 5s - loss: 5.9674 - accuracy: 0.62 - ETA: 5s - loss: 5.8702 - accuracy: 0.63 - ETA: 5s - loss: 5.8192 - accuracy: 0.63 - ETA: 4s - loss: 5.7586 - accuracy: 0.64 - ETA: 4s - loss: 5.7306 - accuracy: 0.64 - ETA: 4s - loss: 5.7587 - accuracy: 0.64 - ETA: 4s - loss: 5.7543 - accuracy: 0.64 - ETA: 4s - loss: 5.7476 - accuracy: 0.64 - ETA: 4s - loss: 5.7451 - accuracy: 0.64 - ETA: 4s - loss: 5.7729 - accuracy: 0.64 - ETA: 4s - loss: 5.7803 - accuracy: 0.64 - ETA: 4s - loss: 5.7606 - accuracy: 0.64 - ETA: 4s - loss: 5.7619 - accuracy: 0.64 - ETA: 4s - loss: 5.7666 - accuracy: 0.64 - ETA: 4s - loss: 5.7747 - accuracy: 0.64 - ETA: 4s - loss: 5.7866 - accuracy: 0.64 - ETA: 4s - loss: 5.7693 - accuracy: 0.64 - ETA: 3s - loss: 5.7670 - accuracy: 0.64 - ETA: 3s - loss: 5.7723 - accuracy: 0.64 - ETA: 3s - loss: 5.7719 - accuracy: 0.64 - ETA: 3s - loss: 5.7731 - accuracy: 0.64 - ETA: 3s - loss: 5.7872 - accuracy: 0.64 - ETA: 3s - loss: 5.7978 - accuracy: 0.64 - ETA: 3s - loss: 5.7995 - accuracy: 0.64 - ETA: 3s - loss: 5.8097 - accuracy: 0.63 - ETA: 3s - loss: 5.8284 - accuracy: 0.63 - ETA: 3s - loss: 5.8235 - accuracy: 0.63 - ETA: 3s - loss: 5.8274 - accuracy: 0.63 - ETA: 3s - loss: 5.8293 - accuracy: 0.63 - ETA: 3s - loss: 5.8291 - accuracy: 0.63 - ETA: 3s - loss: 5.8314 - accuracy: 0.63 - ETA: 3s - loss: 5.8469 - accuracy: 0.63 - ETA: 2s - loss: 5.8555 - accuracy: 0.63 - ETA: 2s - loss: 5.8503 - accuracy: 0.63 - ETA: 2s - loss: 5.8286 - accuracy: 0.63 - ETA: 2s - loss: 5.8200 - accuracy: 0.63 - ETA: 2s - loss: 5.8159 - accuracy: 0.63 - ETA: 2s - loss: 5.8204 - accuracy: 0.63 - ETA: 2s - loss: 5.8231 - accuracy: 0.63 - ETA: 2s - loss: 5.8266 - accuracy: 0.63 - ETA: 2s - loss: 5.8348 - accuracy: 0.63 - ETA: 2s - loss: 5.8284 - accuracy: 0.63 - ETA: 2s - loss: 5.8247 - accuracy: 0.63 - ETA: 2s - loss: 5.8201 - accuracy: 0.63 - ETA: 2s - loss: 5.8247 - accuracy: 0.63 - ETA: 2s - loss: 5.8263 - accuracy: 0.63 - ETA: 2s - loss: 5.8297 - accuracy: 0.63 - ETA: 2s - loss: 5.8333 - accuracy: 0.63 - ETA: 2s - loss: 5.8245 - accuracy: 0.63 - ETA: 2s - loss: 5.8198 - accuracy: 0.63 - ETA: 2s - loss: 5.8261 - accuracy: 0.63 - ETA: 2s - loss: 5.8253 - accuracy: 0.63 - ETA: 1s - loss: 5.8284 - accuracy: 0.63 - ETA: 1s - loss: 5.8258 - accuracy: 0.63 - ETA: 1s - loss: 5.8276 - accuracy: 0.63 - ETA: 1s - loss: 5.8236 - accuracy: 0.63 - ETA: 1s - loss: 5.8247 - accuracy: 0.63 - ETA: 1s - loss: 5.8278 - accuracy: 0.63 - ETA: 1s - loss: 5.8281 - accuracy: 0.63 - ETA: 1s - loss: 5.8354 - accuracy: 0.63 - ETA: 1s - loss: 5.8372 - accuracy: 0.63 - ETA: 1s - loss: 5.8403 - accuracy: 0.63 - ETA: 1s - loss: 5.8375 - accuracy: 0.63 - ETA: 1s - loss: 5.8366 - accuracy: 0.63 - ETA: 1s - loss: 5.8326 - accuracy: 0.63 - ETA: 1s - loss: 5.8282 - accuracy: 0.63 - ETA: 1s - loss: 5.8278 - accuracy: 0.63 - ETA: 1s - loss: 5.8385 - accuracy: 0.63 - ETA: 1s - loss: 5.8386 - accuracy: 0.63 - ETA: 1s - loss: 5.8416 - accuracy: 0.63 - ETA: 1s - loss: 5.8437 - accuracy: 0.63 - ETA: 0s - loss: 5.8539 - accuracy: 0.63 - ETA: 0s - loss: 5.8568 - accuracy: 0.63 - ETA: 0s - loss: 5.8558 - accuracy: 0.63 - ETA: 0s - loss: 5.8611 - accuracy: 0.63 - ETA: 0s - loss: 5.8561 - accuracy: 0.63 - ETA: 0s - loss: 5.8564 - accuracy: 0.63 - ETA: 0s - loss: 5.8569 - accuracy: 0.63 - ETA: 0s - loss: 5.8605 - accuracy: 0.63 - ETA: 0s - loss: 5.8567 - accuracy: 0.63 - ETA: 0s - loss: 5.8509 - accuracy: 0.63 - ETA: 0s - loss: 5.8516 - accuracy: 0.63 - ETA: 0s - loss: 5.8549 - accuracy: 0.63 - ETA: 0s - loss: 5.8540 - accuracy: 0.63 - ETA: 0s - loss: 5.8478 - accuracy: 0.63 - ETA: 0s - loss: 5.8495 - accuracy: 0.63 - ETA: 0s - loss: 5.8468 - accuracy: 0.63 - ETA: 0s - loss: 5.8477 - accuracy: 0.63 - ETA: 0s - loss: 5.8518 - accuracy: 0.63 - 5s 71us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 11s - loss: 5.6413 - accuracy: 0.650 - ETA: 5s - loss: 6.4271 - accuracy: 0.601 - ETA: 5s - loss: 6.2256 - accuracy: 0.61 - ETA: 4s - loss: 6.0644 - accuracy: 0.62 - ETA: 4s - loss: 5.9013 - accuracy: 0.63 - ETA: 4s - loss: 5.8645 - accuracy: 0.63 - ETA: 4s - loss: 5.9088 - accuracy: 0.63 - ETA: 4s - loss: 5.8992 - accuracy: 0.63 - ETA: 4s - loss: 5.8767 - accuracy: 0.63 - ETA: 4s - loss: 5.8888 - accuracy: 0.63 - ETA: 4s - loss: 5.8698 - accuracy: 0.63 - ETA: 4s - loss: 5.8756 - accuracy: 0.63 - ETA: 4s - loss: 5.8814 - accuracy: 0.63 - ETA: 4s - loss: 5.8807 - accuracy: 0.63 - ETA: 4s - loss: 5.9031 - accuracy: 0.63 - ETA: 3s - loss: 5.9265 - accuracy: 0.63 - ETA: 3s - loss: 5.9547 - accuracy: 0.63 - ETA: 3s - loss: 5.9492 - accuracy: 0.63 - ETA: 3s - loss: 5.9305 - accuracy: 0.63 - ETA: 3s - loss: 5.9442 - accuracy: 0.63 - ETA: 3s - loss: 5.9350 - accuracy: 0.63 - ETA: 3s - loss: 5.9539 - accuracy: 0.63 - ETA: 3s - loss: 5.9441 - accuracy: 0.63 - ETA: 3s - loss: 5.9442 - accuracy: 0.63 - ETA: 3s - loss: 5.9433 - accuracy: 0.63 - ETA: 3s - loss: 5.9295 - accuracy: 0.63 - ETA: 3s - loss: 5.9175 - accuracy: 0.63 - ETA: 3s - loss: 5.9052 - accuracy: 0.63 - ETA: 3s - loss: 5.9059 - accuracy: 0.63 - ETA: 3s - loss: 5.9076 - accuracy: 0.63 - ETA: 3s - loss: 5.9043 - accuracy: 0.63 - ETA: 3s - loss: 5.8949 - accuracy: 0.63 - ETA: 2s - loss: 5.8780 - accuracy: 0.63 - ETA: 2s - loss: 5.8769 - accuracy: 0.63 - ETA: 2s - loss: 5.8813 - accuracy: 0.63 - ETA: 2s - loss: 5.8799 - accuracy: 0.63 - ETA: 2s - loss: 5.8760 - accuracy: 0.63 - ETA: 2s - loss: 5.8690 - accuracy: 0.63 - ETA: 2s - loss: 5.8604 - accuracy: 0.63 - ETA: 2s - loss: 5.8694 - accuracy: 0.63 - ETA: 2s - loss: 5.8653 - accuracy: 0.63 - ETA: 2s - loss: 5.8698 - accuracy: 0.63 - ETA: 2s - loss: 5.8592 - accuracy: 0.63 - ETA: 2s - loss: 5.8631 - accuracy: 0.63 - ETA: 2s - loss: 5.8649 - accuracy: 0.63 - ETA: 2s - loss: 5.8690 - accuracy: 0.63 - ETA: 2s - loss: 5.8619 - accuracy: 0.63 - ETA: 2s - loss: 5.8507 - accuracy: 0.63 - ETA: 2s - loss: 5.8484 - accuracy: 0.63 - ETA: 2s - loss: 5.8505 - accuracy: 0.63 - ETA: 2s - loss: 5.8462 - accuracy: 0.63 - ETA: 2s - loss: 5.8522 - accuracy: 0.63 - ETA: 1s - loss: 5.8599 - accuracy: 0.63 - ETA: 1s - loss: 5.8553 - accuracy: 0.63 - ETA: 1s - loss: 5.8528 - accuracy: 0.63 - ETA: 1s - loss: 5.8579 - accuracy: 0.63 - ETA: 1s - loss: 5.8583 - accuracy: 0.63 - ETA: 1s - loss: 5.8512 - accuracy: 0.63 - ETA: 1s - loss: 5.8483 - accuracy: 0.63 - ETA: 1s - loss: 5.8525 - accuracy: 0.63 - ETA: 1s - loss: 5.8514 - accuracy: 0.63 - ETA: 1s - loss: 5.8449 - accuracy: 0.63 - ETA: 1s - loss: 5.8446 - accuracy: 0.63 - ETA: 1s - loss: 5.8417 - accuracy: 0.63 - ETA: 1s - loss: 5.8388 - accuracy: 0.63 - ETA: 1s - loss: 5.8395 - accuracy: 0.63 - ETA: 1s - loss: 5.8452 - accuracy: 0.63 - ETA: 1s - loss: 5.8442 - accuracy: 0.63 - ETA: 1s - loss: 5.8421 - accuracy: 0.63 - ETA: 1s - loss: 5.8532 - accuracy: 0.63 - ETA: 1s - loss: 5.8540 - accuracy: 0.63 - ETA: 0s - loss: 5.8528 - accuracy: 0.63 - ETA: 0s - loss: 5.8504 - accuracy: 0.63 - ETA: 0s - loss: 5.8446 - accuracy: 0.63 - ETA: 0s - loss: 5.8446 - accuracy: 0.63 - ETA: 0s - loss: 5.8443 - accuracy: 0.63 - ETA: 0s - loss: 5.8472 - accuracy: 0.63 - ETA: 0s - loss: 5.8454 - accuracy: 0.63 - ETA: 0s - loss: 5.8467 - accuracy: 0.63 - ETA: 0s - loss: 5.8548 - accuracy: 0.63 - ETA: 0s - loss: 5.8490 - accuracy: 0.63 - ETA: 0s - loss: 5.8445 - accuracy: 0.63 - ETA: 0s - loss: 5.8412 - accuracy: 0.63 - ETA: 0s - loss: 5.8436 - accuracy: 0.63 - ETA: 0s - loss: 5.8433 - accuracy: 0.63 - ETA: 0s - loss: 5.8467 - accuracy: 0.63 - ETA: 0s - loss: 5.8537 - accuracy: 0.63 - ETA: 0s - loss: 5.8531 - accuracy: 0.63 - ETA: 0s - loss: 5.8520 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - 5s 67us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 29/50\n",
      "70000/70000 [==============================] - ETA: 5s - loss: 5.1578 - accuracy: 0.68 - ETA: 5s - loss: 6.0443 - accuracy: 0.62 - ETA: 5s - loss: 5.8240 - accuracy: 0.63 - ETA: 4s - loss: 5.8305 - accuracy: 0.63 - ETA: 4s - loss: 5.8857 - accuracy: 0.63 - ETA: 4s - loss: 5.9265 - accuracy: 0.63 - ETA: 4s - loss: 5.9465 - accuracy: 0.63 - ETA: 4s - loss: 5.9549 - accuracy: 0.63 - ETA: 4s - loss: 5.9056 - accuracy: 0.63 - ETA: 4s - loss: 5.9424 - accuracy: 0.63 - ETA: 4s - loss: 5.9164 - accuracy: 0.63 - ETA: 4s - loss: 5.9197 - accuracy: 0.63 - ETA: 4s - loss: 5.9334 - accuracy: 0.63 - ETA: 4s - loss: 5.8989 - accuracy: 0.63 - ETA: 4s - loss: 5.9170 - accuracy: 0.63 - ETA: 4s - loss: 5.9025 - accuracy: 0.63 - ETA: 4s - loss: 5.9118 - accuracy: 0.63 - ETA: 4s - loss: 5.9060 - accuracy: 0.63 - ETA: 4s - loss: 5.8962 - accuracy: 0.63 - ETA: 4s - loss: 5.8784 - accuracy: 0.63 - ETA: 4s - loss: 5.8854 - accuracy: 0.63 - ETA: 4s - loss: 5.8820 - accuracy: 0.63 - ETA: 3s - loss: 5.8908 - accuracy: 0.63 - ETA: 3s - loss: 5.8988 - accuracy: 0.63 - ETA: 3s - loss: 5.8704 - accuracy: 0.63 - ETA: 3s - loss: 5.8583 - accuracy: 0.63 - ETA: 3s - loss: 5.8469 - accuracy: 0.63 - ETA: 3s - loss: 5.8739 - accuracy: 0.63 - ETA: 3s - loss: 5.8767 - accuracy: 0.63 - ETA: 3s - loss: 5.8754 - accuracy: 0.63 - ETA: 3s - loss: 5.8595 - accuracy: 0.63 - ETA: 3s - loss: 5.8560 - accuracy: 0.63 - ETA: 3s - loss: 5.8383 - accuracy: 0.63 - ETA: 3s - loss: 5.8520 - accuracy: 0.63 - ETA: 3s - loss: 5.8595 - accuracy: 0.63 - ETA: 3s - loss: 5.8565 - accuracy: 0.63 - ETA: 3s - loss: 5.8462 - accuracy: 0.63 - ETA: 3s - loss: 5.8545 - accuracy: 0.63 - ETA: 3s - loss: 5.8520 - accuracy: 0.63 - ETA: 2s - loss: 5.8585 - accuracy: 0.63 - ETA: 2s - loss: 5.8537 - accuracy: 0.63 - ETA: 2s - loss: 5.8571 - accuracy: 0.63 - ETA: 2s - loss: 5.8517 - accuracy: 0.63 - ETA: 2s - loss: 5.8552 - accuracy: 0.63 - ETA: 2s - loss: 5.8534 - accuracy: 0.63 - ETA: 2s - loss: 5.8533 - accuracy: 0.63 - ETA: 2s - loss: 5.8492 - accuracy: 0.63 - ETA: 2s - loss: 5.8483 - accuracy: 0.63 - ETA: 2s - loss: 5.8437 - accuracy: 0.63 - ETA: 2s - loss: 5.8390 - accuracy: 0.63 - ETA: 2s - loss: 5.8325 - accuracy: 0.63 - ETA: 2s - loss: 5.8249 - accuracy: 0.63 - ETA: 2s - loss: 5.8358 - accuracy: 0.63 - ETA: 2s - loss: 5.8416 - accuracy: 0.63 - ETA: 2s - loss: 5.8379 - accuracy: 0.63 - ETA: 2s - loss: 5.8355 - accuracy: 0.63 - ETA: 2s - loss: 5.8262 - accuracy: 0.63 - ETA: 2s - loss: 5.8311 - accuracy: 0.63 - ETA: 1s - loss: 5.8335 - accuracy: 0.63 - ETA: 1s - loss: 5.8411 - accuracy: 0.63 - ETA: 1s - loss: 5.8375 - accuracy: 0.63 - ETA: 1s - loss: 5.8340 - accuracy: 0.63 - ETA: 1s - loss: 5.8334 - accuracy: 0.63 - ETA: 1s - loss: 5.8399 - accuracy: 0.63 - ETA: 1s - loss: 5.8410 - accuracy: 0.63 - ETA: 1s - loss: 5.8387 - accuracy: 0.63 - ETA: 1s - loss: 5.8458 - accuracy: 0.63 - ETA: 1s - loss: 5.8451 - accuracy: 0.63 - ETA: 1s - loss: 5.8491 - accuracy: 0.63 - ETA: 1s - loss: 5.8520 - accuracy: 0.63 - ETA: 1s - loss: 5.8460 - accuracy: 0.63 - ETA: 1s - loss: 5.8537 - accuracy: 0.63 - ETA: 1s - loss: 5.8605 - accuracy: 0.63 - ETA: 1s - loss: 5.8621 - accuracy: 0.63 - ETA: 1s - loss: 5.8603 - accuracy: 0.63 - ETA: 1s - loss: 5.8566 - accuracy: 0.63 - ETA: 1s - loss: 5.8527 - accuracy: 0.63 - ETA: 0s - loss: 5.8575 - accuracy: 0.63 - ETA: 0s - loss: 5.8567 - accuracy: 0.63 - ETA: 0s - loss: 5.8540 - accuracy: 0.63 - ETA: 0s - loss: 5.8558 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - ETA: 0s - loss: 5.8463 - accuracy: 0.63 - ETA: 0s - loss: 5.8462 - accuracy: 0.63 - ETA: 0s - loss: 5.8455 - accuracy: 0.63 - ETA: 0s - loss: 5.8472 - accuracy: 0.63 - ETA: 0s - loss: 5.8469 - accuracy: 0.63 - ETA: 0s - loss: 5.8476 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - ETA: 0s - loss: 5.8608 - accuracy: 0.63 - ETA: 0s - loss: 5.8621 - accuracy: 0.63 - ETA: 0s - loss: 5.8667 - accuracy: 0.63 - ETA: 0s - loss: 5.8648 - accuracy: 0.63 - ETA: 0s - loss: 5.8620 - accuracy: 0.63 - ETA: 0s - loss: 5.8590 - accuracy: 0.63 - 5s 71us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 30/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 6.2861 - accuracy: 0.61 - ETA: 5s - loss: 6.0040 - accuracy: 0.62 - ETA: 5s - loss: 6.0926 - accuracy: 0.62 - ETA: 5s - loss: 5.8796 - accuracy: 0.63 - ETA: 4s - loss: 5.9689 - accuracy: 0.62 - ETA: 4s - loss: 5.9802 - accuracy: 0.62 - ETA: 4s - loss: 5.8540 - accuracy: 0.63 - ETA: 4s - loss: 5.8963 - accuracy: 0.63 - ETA: 4s - loss: 5.8389 - accuracy: 0.63 - ETA: 4s - loss: 5.8547 - accuracy: 0.63 - ETA: 4s - loss: 5.8515 - accuracy: 0.63 - ETA: 4s - loss: 5.8494 - accuracy: 0.63 - ETA: 4s - loss: 5.8568 - accuracy: 0.63 - ETA: 4s - loss: 5.8322 - accuracy: 0.63 - ETA: 3s - loss: 5.8780 - accuracy: 0.63 - ETA: 3s - loss: 5.9068 - accuracy: 0.63 - ETA: 3s - loss: 5.9218 - accuracy: 0.63 - ETA: 3s - loss: 5.9136 - accuracy: 0.63 - ETA: 3s - loss: 5.9103 - accuracy: 0.63 - ETA: 3s - loss: 5.8960 - accuracy: 0.63 - ETA: 3s - loss: 5.8974 - accuracy: 0.63 - ETA: 3s - loss: 5.8734 - accuracy: 0.63 - ETA: 3s - loss: 5.8720 - accuracy: 0.63 - ETA: 3s - loss: 5.8672 - accuracy: 0.63 - ETA: 3s - loss: 5.8695 - accuracy: 0.63 - ETA: 3s - loss: 5.8562 - accuracy: 0.63 - ETA: 3s - loss: 5.8643 - accuracy: 0.63 - ETA: 3s - loss: 5.8424 - accuracy: 0.63 - ETA: 3s - loss: 5.8434 - accuracy: 0.63 - ETA: 3s - loss: 5.8349 - accuracy: 0.63 - ETA: 3s - loss: 5.8230 - accuracy: 0.63 - ETA: 3s - loss: 5.8184 - accuracy: 0.63 - ETA: 3s - loss: 5.8167 - accuracy: 0.63 - ETA: 2s - loss: 5.8138 - accuracy: 0.63 - ETA: 2s - loss: 5.8257 - accuracy: 0.63 - ETA: 2s - loss: 5.8268 - accuracy: 0.63 - ETA: 2s - loss: 5.8278 - accuracy: 0.63 - ETA: 2s - loss: 5.8226 - accuracy: 0.63 - ETA: 2s - loss: 5.8177 - accuracy: 0.63 - ETA: 2s - loss: 5.8279 - accuracy: 0.63 - ETA: 2s - loss: 5.8254 - accuracy: 0.63 - ETA: 2s - loss: 5.8380 - accuracy: 0.63 - ETA: 2s - loss: 5.8332 - accuracy: 0.63 - ETA: 2s - loss: 5.8387 - accuracy: 0.63 - ETA: 2s - loss: 5.8228 - accuracy: 0.63 - ETA: 2s - loss: 5.8352 - accuracy: 0.63 - ETA: 2s - loss: 5.8358 - accuracy: 0.63 - ETA: 2s - loss: 5.8409 - accuracy: 0.63 - ETA: 2s - loss: 5.8414 - accuracy: 0.63 - ETA: 2s - loss: 5.8297 - accuracy: 0.63 - ETA: 2s - loss: 5.8328 - accuracy: 0.63 - ETA: 2s - loss: 5.8383 - accuracy: 0.63 - ETA: 2s - loss: 5.8496 - accuracy: 0.63 - ETA: 1s - loss: 5.8538 - accuracy: 0.63 - ETA: 1s - loss: 5.8543 - accuracy: 0.63 - ETA: 1s - loss: 5.8631 - accuracy: 0.63 - ETA: 1s - loss: 5.8580 - accuracy: 0.63 - ETA: 1s - loss: 5.8610 - accuracy: 0.63 - ETA: 1s - loss: 5.8631 - accuracy: 0.63 - ETA: 1s - loss: 5.8621 - accuracy: 0.63 - ETA: 1s - loss: 5.8635 - accuracy: 0.63 - ETA: 1s - loss: 5.8743 - accuracy: 0.63 - ETA: 1s - loss: 5.8738 - accuracy: 0.63 - ETA: 1s - loss: 5.8711 - accuracy: 0.63 - ETA: 1s - loss: 5.8611 - accuracy: 0.63 - ETA: 1s - loss: 5.8614 - accuracy: 0.63 - ETA: 1s - loss: 5.8604 - accuracy: 0.63 - ETA: 1s - loss: 5.8576 - accuracy: 0.63 - ETA: 1s - loss: 5.8569 - accuracy: 0.63 - ETA: 1s - loss: 5.8519 - accuracy: 0.63 - ETA: 1s - loss: 5.8597 - accuracy: 0.63 - ETA: 1s - loss: 5.8577 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8587 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8603 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8645 - accuracy: 0.63 - ETA: 0s - loss: 5.8668 - accuracy: 0.63 - ETA: 0s - loss: 5.8686 - accuracy: 0.63 - ETA: 0s - loss: 5.8680 - accuracy: 0.63 - ETA: 0s - loss: 5.8691 - accuracy: 0.63 - ETA: 0s - loss: 5.8637 - accuracy: 0.63 - ETA: 0s - loss: 5.8601 - accuracy: 0.63 - ETA: 0s - loss: 5.8527 - accuracy: 0.63 - ETA: 0s - loss: 5.8550 - accuracy: 0.63 - ETA: 0s - loss: 5.8480 - accuracy: 0.63 - ETA: 0s - loss: 5.8543 - accuracy: 0.63 - ETA: 0s - loss: 5.8588 - accuracy: 0.63 - ETA: 0s - loss: 5.8567 - accuracy: 0.63 - ETA: 0s - loss: 5.8577 - accuracy: 0.63 - 5s 68us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 31/50\n",
      "70000/70000 [==============================] - ETA: 8s - loss: 5.9637 - accuracy: 0.63 - ETA: 4s - loss: 5.6592 - accuracy: 0.64 - ETA: 4s - loss: 5.8689 - accuracy: 0.63 - ETA: 4s - loss: 5.9234 - accuracy: 0.63 - ETA: 4s - loss: 6.0370 - accuracy: 0.62 - ETA: 4s - loss: 6.0266 - accuracy: 0.62 - ETA: 4s - loss: 5.9176 - accuracy: 0.63 - ETA: 4s - loss: 5.8562 - accuracy: 0.63 - ETA: 4s - loss: 5.8471 - accuracy: 0.63 - ETA: 4s - loss: 5.9107 - accuracy: 0.63 - ETA: 4s - loss: 5.8801 - accuracy: 0.63 - ETA: 4s - loss: 5.8735 - accuracy: 0.63 - ETA: 4s - loss: 5.9017 - accuracy: 0.63 - ETA: 4s - loss: 5.8815 - accuracy: 0.63 - ETA: 4s - loss: 5.8436 - accuracy: 0.63 - ETA: 4s - loss: 5.8439 - accuracy: 0.63 - ETA: 4s - loss: 5.8625 - accuracy: 0.63 - ETA: 4s - loss: 5.8793 - accuracy: 0.63 - ETA: 3s - loss: 5.8539 - accuracy: 0.63 - ETA: 3s - loss: 5.8400 - accuracy: 0.63 - ETA: 3s - loss: 5.8209 - accuracy: 0.63 - ETA: 3s - loss: 5.8356 - accuracy: 0.63 - ETA: 3s - loss: 5.8292 - accuracy: 0.63 - ETA: 3s - loss: 5.8148 - accuracy: 0.63 - ETA: 3s - loss: 5.8089 - accuracy: 0.63 - ETA: 3s - loss: 5.8078 - accuracy: 0.63 - ETA: 3s - loss: 5.8093 - accuracy: 0.63 - ETA: 3s - loss: 5.7960 - accuracy: 0.64 - ETA: 3s - loss: 5.8064 - accuracy: 0.63 - ETA: 3s - loss: 5.8146 - accuracy: 0.63 - ETA: 3s - loss: 5.8098 - accuracy: 0.63 - ETA: 3s - loss: 5.8039 - accuracy: 0.63 - ETA: 3s - loss: 5.8039 - accuracy: 0.63 - ETA: 3s - loss: 5.8058 - accuracy: 0.63 - ETA: 3s - loss: 5.8174 - accuracy: 0.63 - ETA: 3s - loss: 5.8165 - accuracy: 0.63 - ETA: 3s - loss: 5.8111 - accuracy: 0.63 - ETA: 3s - loss: 5.8198 - accuracy: 0.63 - ETA: 3s - loss: 5.8419 - accuracy: 0.63 - ETA: 2s - loss: 5.8386 - accuracy: 0.63 - ETA: 2s - loss: 5.8513 - accuracy: 0.63 - ETA: 2s - loss: 5.8505 - accuracy: 0.63 - ETA: 2s - loss: 5.8618 - accuracy: 0.63 - ETA: 2s - loss: 5.8610 - accuracy: 0.63 - ETA: 2s - loss: 5.8536 - accuracy: 0.63 - ETA: 2s - loss: 5.8496 - accuracy: 0.63 - ETA: 2s - loss: 5.8409 - accuracy: 0.63 - ETA: 2s - loss: 5.8391 - accuracy: 0.63 - ETA: 2s - loss: 5.8438 - accuracy: 0.63 - ETA: 2s - loss: 5.8372 - accuracy: 0.63 - ETA: 2s - loss: 5.8260 - accuracy: 0.63 - ETA: 2s - loss: 5.8324 - accuracy: 0.63 - ETA: 2s - loss: 5.8327 - accuracy: 0.63 - ETA: 2s - loss: 5.8210 - accuracy: 0.63 - ETA: 2s - loss: 5.8130 - accuracy: 0.63 - ETA: 2s - loss: 5.8184 - accuracy: 0.63 - ETA: 2s - loss: 5.8189 - accuracy: 0.63 - ETA: 1s - loss: 5.8182 - accuracy: 0.63 - ETA: 1s - loss: 5.8164 - accuracy: 0.63 - ETA: 1s - loss: 5.8257 - accuracy: 0.63 - ETA: 1s - loss: 5.8361 - accuracy: 0.63 - ETA: 1s - loss: 5.8413 - accuracy: 0.63 - ETA: 1s - loss: 5.8372 - accuracy: 0.63 - ETA: 1s - loss: 5.8342 - accuracy: 0.63 - ETA: 1s - loss: 5.8348 - accuracy: 0.63 - ETA: 1s - loss: 5.8363 - accuracy: 0.63 - ETA: 1s - loss: 5.8331 - accuracy: 0.63 - ETA: 1s - loss: 5.8411 - accuracy: 0.63 - ETA: 1s - loss: 5.8316 - accuracy: 0.63 - ETA: 1s - loss: 5.8321 - accuracy: 0.63 - ETA: 1s - loss: 5.8397 - accuracy: 0.63 - ETA: 1s - loss: 5.8355 - accuracy: 0.63 - ETA: 1s - loss: 5.8296 - accuracy: 0.63 - ETA: 1s - loss: 5.8319 - accuracy: 0.63 - ETA: 1s - loss: 5.8315 - accuracy: 0.63 - ETA: 0s - loss: 5.8299 - accuracy: 0.63 - ETA: 0s - loss: 5.8290 - accuracy: 0.63 - ETA: 0s - loss: 5.8287 - accuracy: 0.63 - ETA: 0s - loss: 5.8297 - accuracy: 0.63 - ETA: 0s - loss: 5.8267 - accuracy: 0.63 - ETA: 0s - loss: 5.8286 - accuracy: 0.63 - ETA: 0s - loss: 5.8310 - accuracy: 0.63 - ETA: 0s - loss: 5.8297 - accuracy: 0.63 - ETA: 0s - loss: 5.8249 - accuracy: 0.63 - ETA: 0s - loss: 5.8273 - accuracy: 0.63 - ETA: 0s - loss: 5.8257 - accuracy: 0.63 - ETA: 0s - loss: 5.8224 - accuracy: 0.63 - ETA: 0s - loss: 5.8249 - accuracy: 0.63 - ETA: 0s - loss: 5.8331 - accuracy: 0.63 - ETA: 0s - loss: 5.8310 - accuracy: 0.63 - ETA: 0s - loss: 5.8299 - accuracy: 0.63 - ETA: 0s - loss: 5.8308 - accuracy: 0.63 - ETA: 0s - loss: 5.8325 - accuracy: 0.63 - ETA: 0s - loss: 5.8388 - accuracy: 0.63 - ETA: 0s - loss: 5.8467 - accuracy: 0.63 - 5s 71us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 5s - loss: 6.4472 - accuracy: 0.60 - ETA: 5s - loss: 6.4472 - accuracy: 0.60 - ETA: 4s - loss: 6.2256 - accuracy: 0.61 - ETA: 4s - loss: 6.1585 - accuracy: 0.61 - ETA: 4s - loss: 6.1551 - accuracy: 0.61 - ETA: 4s - loss: 6.2153 - accuracy: 0.61 - ETA: 4s - loss: 6.1117 - accuracy: 0.62 - ETA: 4s - loss: 6.0875 - accuracy: 0.62 - ETA: 4s - loss: 6.0518 - accuracy: 0.62 - ETA: 4s - loss: 5.9747 - accuracy: 0.62 - ETA: 4s - loss: 5.9736 - accuracy: 0.62 - ETA: 4s - loss: 5.9619 - accuracy: 0.63 - ETA: 4s - loss: 5.9537 - accuracy: 0.63 - ETA: 3s - loss: 5.9192 - accuracy: 0.63 - ETA: 3s - loss: 5.9205 - accuracy: 0.63 - ETA: 3s - loss: 5.9261 - accuracy: 0.63 - ETA: 3s - loss: 5.9083 - accuracy: 0.63 - ETA: 3s - loss: 5.9112 - accuracy: 0.63 - ETA: 3s - loss: 5.9152 - accuracy: 0.63 - ETA: 3s - loss: 5.9061 - accuracy: 0.63 - ETA: 3s - loss: 5.9363 - accuracy: 0.63 - ETA: 3s - loss: 5.9328 - accuracy: 0.63 - ETA: 3s - loss: 5.9316 - accuracy: 0.63 - ETA: 3s - loss: 5.9330 - accuracy: 0.63 - ETA: 3s - loss: 5.9142 - accuracy: 0.63 - ETA: 3s - loss: 5.9008 - accuracy: 0.63 - ETA: 3s - loss: 5.9079 - accuracy: 0.63 - ETA: 3s - loss: 5.8995 - accuracy: 0.63 - ETA: 3s - loss: 5.8881 - accuracy: 0.63 - ETA: 3s - loss: 5.8935 - accuracy: 0.63 - ETA: 3s - loss: 5.8905 - accuracy: 0.63 - ETA: 2s - loss: 5.8942 - accuracy: 0.63 - ETA: 2s - loss: 5.9001 - accuracy: 0.63 - ETA: 2s - loss: 5.8984 - accuracy: 0.63 - ETA: 2s - loss: 5.8843 - accuracy: 0.63 - ETA: 2s - loss: 5.8872 - accuracy: 0.63 - ETA: 2s - loss: 5.8943 - accuracy: 0.63 - ETA: 2s - loss: 5.8962 - accuracy: 0.63 - ETA: 2s - loss: 5.9043 - accuracy: 0.63 - ETA: 2s - loss: 5.9160 - accuracy: 0.63 - ETA: 2s - loss: 5.9188 - accuracy: 0.63 - ETA: 2s - loss: 5.9088 - accuracy: 0.63 - ETA: 2s - loss: 5.9037 - accuracy: 0.63 - ETA: 2s - loss: 5.9037 - accuracy: 0.63 - ETA: 2s - loss: 5.8976 - accuracy: 0.63 - ETA: 2s - loss: 5.8994 - accuracy: 0.63 - ETA: 2s - loss: 5.9039 - accuracy: 0.63 - ETA: 2s - loss: 5.9029 - accuracy: 0.63 - ETA: 2s - loss: 5.8946 - accuracy: 0.63 - ETA: 2s - loss: 5.8876 - accuracy: 0.63 - ETA: 2s - loss: 5.8856 - accuracy: 0.63 - ETA: 2s - loss: 5.8864 - accuracy: 0.63 - ETA: 1s - loss: 5.8823 - accuracy: 0.63 - ETA: 1s - loss: 5.8847 - accuracy: 0.63 - ETA: 1s - loss: 5.8797 - accuracy: 0.63 - ETA: 1s - loss: 5.8769 - accuracy: 0.63 - ETA: 1s - loss: 5.8851 - accuracy: 0.63 - ETA: 1s - loss: 5.8909 - accuracy: 0.63 - ETA: 1s - loss: 5.8829 - accuracy: 0.63 - ETA: 1s - loss: 5.8861 - accuracy: 0.63 - ETA: 1s - loss: 5.8885 - accuracy: 0.63 - ETA: 1s - loss: 5.8904 - accuracy: 0.63 - ETA: 1s - loss: 5.8926 - accuracy: 0.63 - ETA: 1s - loss: 5.8913 - accuracy: 0.63 - ETA: 1s - loss: 5.8855 - accuracy: 0.63 - ETA: 1s - loss: 5.8876 - accuracy: 0.63 - ETA: 1s - loss: 5.8883 - accuracy: 0.63 - ETA: 1s - loss: 5.8937 - accuracy: 0.63 - ETA: 1s - loss: 5.9002 - accuracy: 0.63 - ETA: 1s - loss: 5.8981 - accuracy: 0.63 - ETA: 1s - loss: 5.8969 - accuracy: 0.63 - ETA: 1s - loss: 5.8930 - accuracy: 0.63 - ETA: 1s - loss: 5.8887 - accuracy: 0.63 - ETA: 0s - loss: 5.8858 - accuracy: 0.63 - ETA: 0s - loss: 5.8790 - accuracy: 0.63 - ETA: 0s - loss: 5.8766 - accuracy: 0.63 - ETA: 0s - loss: 5.8752 - accuracy: 0.63 - ETA: 0s - loss: 5.8782 - accuracy: 0.63 - ETA: 0s - loss: 5.8767 - accuracy: 0.63 - ETA: 0s - loss: 5.8794 - accuracy: 0.63 - ETA: 0s - loss: 5.8758 - accuracy: 0.63 - ETA: 0s - loss: 5.8745 - accuracy: 0.63 - ETA: 0s - loss: 5.8724 - accuracy: 0.63 - ETA: 0s - loss: 5.8731 - accuracy: 0.63 - ETA: 0s - loss: 5.8721 - accuracy: 0.63 - ETA: 0s - loss: 5.8716 - accuracy: 0.63 - ETA: 0s - loss: 5.8702 - accuracy: 0.63 - ETA: 0s - loss: 5.8702 - accuracy: 0.63 - ETA: 0s - loss: 5.8681 - accuracy: 0.63 - ETA: 0s - loss: 5.8638 - accuracy: 0.63 - ETA: 0s - loss: 5.8586 - accuracy: 0.63 - ETA: 0s - loss: 5.8565 - accuracy: 0.63 - ETA: 0s - loss: 5.8554 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - 5s 69us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 33/50\n",
      "70000/70000 [==============================] - ETA: 7s - loss: 4.9966 - accuracy: 0.69 - ETA: 5s - loss: 6.0241 - accuracy: 0.62 - ETA: 5s - loss: 6.0711 - accuracy: 0.62 - ETA: 5s - loss: 6.0077 - accuracy: 0.62 - ETA: 4s - loss: 5.9581 - accuracy: 0.63 - ETA: 4s - loss: 5.9950 - accuracy: 0.62 - ETA: 4s - loss: 5.9450 - accuracy: 0.63 - ETA: 4s - loss: 5.9605 - accuracy: 0.63 - ETA: 4s - loss: 5.8872 - accuracy: 0.63 - ETA: 4s - loss: 5.9315 - accuracy: 0.63 - ETA: 4s - loss: 5.8820 - accuracy: 0.63 - ETA: 4s - loss: 5.9058 - accuracy: 0.63 - ETA: 4s - loss: 5.9485 - accuracy: 0.63 - ETA: 4s - loss: 5.9357 - accuracy: 0.63 - ETA: 4s - loss: 5.9460 - accuracy: 0.63 - ETA: 4s - loss: 5.9010 - accuracy: 0.63 - ETA: 4s - loss: 5.8642 - accuracy: 0.63 - ETA: 4s - loss: 5.8329 - accuracy: 0.63 - ETA: 4s - loss: 5.8238 - accuracy: 0.63 - ETA: 4s - loss: 5.8428 - accuracy: 0.63 - ETA: 4s - loss: 5.8465 - accuracy: 0.63 - ETA: 4s - loss: 5.8605 - accuracy: 0.63 - ETA: 4s - loss: 5.8438 - accuracy: 0.63 - ETA: 3s - loss: 5.8421 - accuracy: 0.63 - ETA: 3s - loss: 5.8385 - accuracy: 0.63 - ETA: 3s - loss: 5.8098 - accuracy: 0.63 - ETA: 3s - loss: 5.7990 - accuracy: 0.64 - ETA: 3s - loss: 5.8050 - accuracy: 0.63 - ETA: 3s - loss: 5.8178 - accuracy: 0.63 - ETA: 3s - loss: 5.8544 - accuracy: 0.63 - ETA: 3s - loss: 5.8290 - accuracy: 0.63 - ETA: 3s - loss: 5.8273 - accuracy: 0.63 - ETA: 3s - loss: 5.8287 - accuracy: 0.63 - ETA: 3s - loss: 5.8272 - accuracy: 0.63 - ETA: 3s - loss: 5.8383 - accuracy: 0.63 - ETA: 3s - loss: 5.8446 - accuracy: 0.63 - ETA: 3s - loss: 5.8495 - accuracy: 0.63 - ETA: 3s - loss: 5.8562 - accuracy: 0.63 - ETA: 3s - loss: 5.8536 - accuracy: 0.63 - ETA: 3s - loss: 5.8630 - accuracy: 0.63 - ETA: 3s - loss: 5.8591 - accuracy: 0.63 - ETA: 3s - loss: 5.8704 - accuracy: 0.63 - ETA: 2s - loss: 5.8670 - accuracy: 0.63 - ETA: 2s - loss: 5.8603 - accuracy: 0.63 - ETA: 2s - loss: 5.8734 - accuracy: 0.63 - ETA: 2s - loss: 5.8673 - accuracy: 0.63 - ETA: 2s - loss: 5.8595 - accuracy: 0.63 - ETA: 2s - loss: 5.8550 - accuracy: 0.63 - ETA: 2s - loss: 5.8529 - accuracy: 0.63 - ETA: 2s - loss: 5.8547 - accuracy: 0.63 - ETA: 2s - loss: 5.8605 - accuracy: 0.63 - ETA: 2s - loss: 5.8632 - accuracy: 0.63 - ETA: 2s - loss: 5.8633 - accuracy: 0.63 - ETA: 2s - loss: 5.8607 - accuracy: 0.63 - ETA: 2s - loss: 5.8615 - accuracy: 0.63 - ETA: 2s - loss: 5.8634 - accuracy: 0.63 - ETA: 2s - loss: 5.8603 - accuracy: 0.63 - ETA: 2s - loss: 5.8595 - accuracy: 0.63 - ETA: 2s - loss: 5.8614 - accuracy: 0.63 - ETA: 2s - loss: 5.8685 - accuracy: 0.63 - ETA: 2s - loss: 5.8667 - accuracy: 0.63 - ETA: 1s - loss: 5.8581 - accuracy: 0.63 - ETA: 1s - loss: 5.8568 - accuracy: 0.63 - ETA: 1s - loss: 5.8567 - accuracy: 0.63 - ETA: 1s - loss: 5.8527 - accuracy: 0.63 - ETA: 1s - loss: 5.8562 - accuracy: 0.63 - ETA: 1s - loss: 5.8511 - accuracy: 0.63 - ETA: 1s - loss: 5.8528 - accuracy: 0.63 - ETA: 1s - loss: 5.8519 - accuracy: 0.63 - ETA: 1s - loss: 5.8483 - accuracy: 0.63 - ETA: 1s - loss: 5.8529 - accuracy: 0.63 - ETA: 1s - loss: 5.8589 - accuracy: 0.63 - ETA: 1s - loss: 5.8553 - accuracy: 0.63 - ETA: 1s - loss: 5.8630 - accuracy: 0.63 - ETA: 1s - loss: 5.8588 - accuracy: 0.63 - ETA: 1s - loss: 5.8578 - accuracy: 0.63 - ETA: 1s - loss: 5.8535 - accuracy: 0.63 - ETA: 1s - loss: 5.8634 - accuracy: 0.63 - ETA: 1s - loss: 5.8609 - accuracy: 0.63 - ETA: 1s - loss: 5.8636 - accuracy: 0.63 - ETA: 1s - loss: 5.8628 - accuracy: 0.63 - ETA: 0s - loss: 5.8637 - accuracy: 0.63 - ETA: 0s - loss: 5.8658 - accuracy: 0.63 - ETA: 0s - loss: 5.8647 - accuracy: 0.63 - ETA: 0s - loss: 5.8596 - accuracy: 0.63 - ETA: 0s - loss: 5.8582 - accuracy: 0.63 - ETA: 0s - loss: 5.8587 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - ETA: 0s - loss: 5.8514 - accuracy: 0.63 - ETA: 0s - loss: 5.8531 - accuracy: 0.63 - ETA: 0s - loss: 5.8556 - accuracy: 0.63 - ETA: 0s - loss: 5.8571 - accuracy: 0.63 - ETA: 0s - loss: 5.8585 - accuracy: 0.63 - ETA: 0s - loss: 5.8588 - accuracy: 0.63 - ETA: 0s - loss: 5.8585 - accuracy: 0.63 - ETA: 0s - loss: 5.8593 - accuracy: 0.63 - ETA: 0s - loss: 5.8488 - accuracy: 0.63 - ETA: 0s - loss: 5.8471 - accuracy: 0.63 - ETA: 0s - loss: 5.8477 - accuracy: 0.63 - ETA: 0s - loss: 5.8505 - accuracy: 0.63 - ETA: 0s - loss: 5.8564 - accuracy: 0.63 - 5s 75us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 6s - loss: 6.2861 - accuracy: 0.61 - ETA: 5s - loss: 6.1450 - accuracy: 0.61 - ETA: 4s - loss: 6.1679 - accuracy: 0.61 - ETA: 4s - loss: 6.2160 - accuracy: 0.61 - ETA: 4s - loss: 6.1893 - accuracy: 0.61 - ETA: 4s - loss: 6.1162 - accuracy: 0.62 - ETA: 5s - loss: 6.0903 - accuracy: 0.62 - ETA: 4s - loss: 6.0475 - accuracy: 0.62 - ETA: 4s - loss: 6.0768 - accuracy: 0.62 - ETA: 4s - loss: 5.9637 - accuracy: 0.63 - ETA: 4s - loss: 5.9319 - accuracy: 0.63 - ETA: 4s - loss: 5.9575 - accuracy: 0.63 - ETA: 4s - loss: 5.9561 - accuracy: 0.63 - ETA: 4s - loss: 5.9269 - accuracy: 0.63 - ETA: 4s - loss: 5.9311 - accuracy: 0.63 - ETA: 4s - loss: 5.9470 - accuracy: 0.63 - ETA: 4s - loss: 5.9283 - accuracy: 0.63 - ETA: 4s - loss: 5.9131 - accuracy: 0.63 - ETA: 4s - loss: 5.8995 - accuracy: 0.63 - ETA: 4s - loss: 5.9104 - accuracy: 0.63 - ETA: 4s - loss: 5.9276 - accuracy: 0.63 - ETA: 4s - loss: 5.9057 - accuracy: 0.63 - ETA: 3s - loss: 5.8867 - accuracy: 0.63 - ETA: 3s - loss: 5.8900 - accuracy: 0.63 - ETA: 3s - loss: 5.8775 - accuracy: 0.63 - ETA: 3s - loss: 5.8682 - accuracy: 0.63 - ETA: 3s - loss: 5.8632 - accuracy: 0.63 - ETA: 3s - loss: 5.8626 - accuracy: 0.63 - ETA: 3s - loss: 5.8651 - accuracy: 0.63 - ETA: 3s - loss: 5.8599 - accuracy: 0.63 - ETA: 3s - loss: 5.8520 - accuracy: 0.63 - ETA: 3s - loss: 5.8419 - accuracy: 0.63 - ETA: 3s - loss: 5.8584 - accuracy: 0.63 - ETA: 3s - loss: 5.8660 - accuracy: 0.63 - ETA: 3s - loss: 5.8778 - accuracy: 0.63 - ETA: 3s - loss: 5.8767 - accuracy: 0.63 - ETA: 3s - loss: 5.8819 - accuracy: 0.63 - ETA: 3s - loss: 5.8779 - accuracy: 0.63 - ETA: 3s - loss: 5.8825 - accuracy: 0.63 - ETA: 3s - loss: 5.8926 - accuracy: 0.63 - ETA: 3s - loss: 5.8944 - accuracy: 0.63 - ETA: 2s - loss: 5.8922 - accuracy: 0.63 - ETA: 2s - loss: 5.8949 - accuracy: 0.63 - ETA: 2s - loss: 5.8918 - accuracy: 0.63 - ETA: 2s - loss: 5.8985 - accuracy: 0.63 - ETA: 2s - loss: 5.8950 - accuracy: 0.63 - ETA: 2s - loss: 5.8984 - accuracy: 0.63 - ETA: 2s - loss: 5.8925 - accuracy: 0.63 - ETA: 2s - loss: 5.8807 - accuracy: 0.63 - ETA: 2s - loss: 5.8782 - accuracy: 0.63 - ETA: 2s - loss: 5.8815 - accuracy: 0.63 - ETA: 2s - loss: 5.8815 - accuracy: 0.63 - ETA: 2s - loss: 5.8752 - accuracy: 0.63 - ETA: 2s - loss: 5.8777 - accuracy: 0.63 - ETA: 2s - loss: 5.8776 - accuracy: 0.63 - ETA: 2s - loss: 5.8825 - accuracy: 0.63 - ETA: 2s - loss: 5.8831 - accuracy: 0.63 - ETA: 2s - loss: 5.8801 - accuracy: 0.63 - ETA: 2s - loss: 5.8720 - accuracy: 0.63 - ETA: 2s - loss: 5.8701 - accuracy: 0.63 - ETA: 2s - loss: 5.8737 - accuracy: 0.63 - ETA: 2s - loss: 5.8773 - accuracy: 0.63 - ETA: 1s - loss: 5.8837 - accuracy: 0.63 - ETA: 1s - loss: 5.8829 - accuracy: 0.63 - ETA: 1s - loss: 5.8824 - accuracy: 0.63 - ETA: 1s - loss: 5.8824 - accuracy: 0.63 - ETA: 1s - loss: 5.8852 - accuracy: 0.63 - ETA: 1s - loss: 5.8848 - accuracy: 0.63 - ETA: 1s - loss: 5.8809 - accuracy: 0.63 - ETA: 1s - loss: 5.8863 - accuracy: 0.63 - ETA: 1s - loss: 5.8844 - accuracy: 0.63 - ETA: 1s - loss: 5.8820 - accuracy: 0.63 - ETA: 1s - loss: 5.8802 - accuracy: 0.63 - ETA: 1s - loss: 5.8826 - accuracy: 0.63 - ETA: 1s - loss: 5.8756 - accuracy: 0.63 - ETA: 1s - loss: 5.8731 - accuracy: 0.63 - ETA: 1s - loss: 5.8700 - accuracy: 0.63 - ETA: 1s - loss: 5.8759 - accuracy: 0.63 - ETA: 1s - loss: 5.8730 - accuracy: 0.63 - ETA: 1s - loss: 5.8755 - accuracy: 0.63 - ETA: 1s - loss: 5.8705 - accuracy: 0.63 - ETA: 1s - loss: 5.8691 - accuracy: 0.63 - ETA: 0s - loss: 5.8711 - accuracy: 0.63 - ETA: 0s - loss: 5.8644 - accuracy: 0.63 - ETA: 0s - loss: 5.8658 - accuracy: 0.63 - ETA: 0s - loss: 5.8680 - accuracy: 0.63 - ETA: 0s - loss: 5.8650 - accuracy: 0.63 - ETA: 0s - loss: 5.8683 - accuracy: 0.63 - ETA: 0s - loss: 5.8637 - accuracy: 0.63 - ETA: 0s - loss: 5.8623 - accuracy: 0.63 - ETA: 0s - loss: 5.8607 - accuracy: 0.63 - ETA: 0s - loss: 5.8608 - accuracy: 0.63 - ETA: 0s - loss: 5.8625 - accuracy: 0.63 - ETA: 0s - loss: 5.8633 - accuracy: 0.63 - ETA: 0s - loss: 5.8661 - accuracy: 0.63 - ETA: 0s - loss: 5.8667 - accuracy: 0.63 - ETA: 0s - loss: 5.8675 - accuracy: 0.63 - ETA: 0s - loss: 5.8630 - accuracy: 0.63 - ETA: 0s - loss: 5.8620 - accuracy: 0.63 - ETA: 0s - loss: 5.8621 - accuracy: 0.63 - ETA: 0s - loss: 5.8608 - accuracy: 0.63 - 5s 75us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 35/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 7.4143 - accuracy: 0.54 - ETA: 5s - loss: 6.0711 - accuracy: 0.62 - ETA: 5s - loss: 6.0040 - accuracy: 0.62 - ETA: 4s - loss: 5.9006 - accuracy: 0.63 - ETA: 4s - loss: 5.8649 - accuracy: 0.63 - ETA: 4s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 5.9112 - accuracy: 0.63 - ETA: 5s - loss: 5.8780 - accuracy: 0.63 - ETA: 5s - loss: 5.8728 - accuracy: 0.63 - ETA: 4s - loss: 5.8537 - accuracy: 0.63 - ETA: 4s - loss: 5.7707 - accuracy: 0.64 - ETA: 4s - loss: 5.7556 - accuracy: 0.64 - ETA: 4s - loss: 5.7286 - accuracy: 0.64 - ETA: 4s - loss: 5.7210 - accuracy: 0.64 - ETA: 4s - loss: 5.7104 - accuracy: 0.64 - ETA: 4s - loss: 5.7098 - accuracy: 0.64 - ETA: 4s - loss: 5.6699 - accuracy: 0.64 - ETA: 4s - loss: 5.6789 - accuracy: 0.64 - ETA: 4s - loss: 5.7068 - accuracy: 0.64 - ETA: 4s - loss: 5.7225 - accuracy: 0.64 - ETA: 4s - loss: 5.7349 - accuracy: 0.64 - ETA: 4s - loss: 5.7376 - accuracy: 0.64 - ETA: 4s - loss: 5.7302 - accuracy: 0.64 - ETA: 4s - loss: 5.7551 - accuracy: 0.64 - ETA: 3s - loss: 5.7286 - accuracy: 0.64 - ETA: 3s - loss: 5.7215 - accuracy: 0.64 - ETA: 3s - loss: 5.7359 - accuracy: 0.64 - ETA: 3s - loss: 5.7548 - accuracy: 0.64 - ETA: 3s - loss: 5.7581 - accuracy: 0.64 - ETA: 3s - loss: 5.7573 - accuracy: 0.64 - ETA: 3s - loss: 5.7670 - accuracy: 0.64 - ETA: 3s - loss: 5.7875 - accuracy: 0.64 - ETA: 3s - loss: 5.8061 - accuracy: 0.63 - ETA: 3s - loss: 5.7976 - accuracy: 0.64 - ETA: 3s - loss: 5.7936 - accuracy: 0.64 - ETA: 3s - loss: 5.7866 - accuracy: 0.64 - ETA: 3s - loss: 5.8006 - accuracy: 0.64 - ETA: 3s - loss: 5.7988 - accuracy: 0.64 - ETA: 3s - loss: 5.7915 - accuracy: 0.64 - ETA: 3s - loss: 5.7876 - accuracy: 0.64 - ETA: 3s - loss: 5.7921 - accuracy: 0.64 - ETA: 3s - loss: 5.7974 - accuracy: 0.64 - ETA: 3s - loss: 5.7915 - accuracy: 0.64 - ETA: 2s - loss: 5.7966 - accuracy: 0.64 - ETA: 2s - loss: 5.7857 - accuracy: 0.64 - ETA: 2s - loss: 5.7943 - accuracy: 0.64 - ETA: 2s - loss: 5.7975 - accuracy: 0.64 - ETA: 2s - loss: 5.8065 - accuracy: 0.63 - ETA: 2s - loss: 5.8040 - accuracy: 0.63 - ETA: 2s - loss: 5.8143 - accuracy: 0.63 - ETA: 2s - loss: 5.8136 - accuracy: 0.63 - ETA: 2s - loss: 5.8144 - accuracy: 0.63 - ETA: 2s - loss: 5.8133 - accuracy: 0.63 - ETA: 2s - loss: 5.8135 - accuracy: 0.63 - ETA: 2s - loss: 5.8154 - accuracy: 0.63 - ETA: 2s - loss: 5.8299 - accuracy: 0.63 - ETA: 2s - loss: 5.8381 - accuracy: 0.63 - ETA: 2s - loss: 5.8330 - accuracy: 0.63 - ETA: 2s - loss: 5.8329 - accuracy: 0.63 - ETA: 2s - loss: 5.8332 - accuracy: 0.63 - ETA: 2s - loss: 5.8316 - accuracy: 0.63 - ETA: 2s - loss: 5.8365 - accuracy: 0.63 - ETA: 2s - loss: 5.8329 - accuracy: 0.63 - ETA: 2s - loss: 5.8339 - accuracy: 0.63 - ETA: 1s - loss: 5.8379 - accuracy: 0.63 - ETA: 1s - loss: 5.8349 - accuracy: 0.63 - ETA: 1s - loss: 5.8365 - accuracy: 0.63 - ETA: 1s - loss: 5.8388 - accuracy: 0.63 - ETA: 1s - loss: 5.8386 - accuracy: 0.63 - ETA: 1s - loss: 5.8377 - accuracy: 0.63 - ETA: 1s - loss: 5.8469 - accuracy: 0.63 - ETA: 1s - loss: 5.8434 - accuracy: 0.63 - ETA: 1s - loss: 5.8478 - accuracy: 0.63 - ETA: 1s - loss: 5.8467 - accuracy: 0.63 - ETA: 1s - loss: 5.8537 - accuracy: 0.63 - ETA: 1s - loss: 5.8589 - accuracy: 0.63 - ETA: 1s - loss: 5.8594 - accuracy: 0.63 - ETA: 1s - loss: 5.8608 - accuracy: 0.63 - ETA: 1s - loss: 5.8543 - accuracy: 0.63 - ETA: 1s - loss: 5.8531 - accuracy: 0.63 - ETA: 1s - loss: 5.8565 - accuracy: 0.63 - ETA: 1s - loss: 5.8550 - accuracy: 0.63 - ETA: 1s - loss: 5.8521 - accuracy: 0.63 - ETA: 0s - loss: 5.8568 - accuracy: 0.63 - ETA: 0s - loss: 5.8583 - accuracy: 0.63 - ETA: 0s - loss: 5.8599 - accuracy: 0.63 - ETA: 0s - loss: 5.8622 - accuracy: 0.63 - ETA: 0s - loss: 5.8543 - accuracy: 0.63 - ETA: 0s - loss: 5.8553 - accuracy: 0.63 - ETA: 0s - loss: 5.8560 - accuracy: 0.63 - ETA: 0s - loss: 5.8512 - accuracy: 0.63 - ETA: 0s - loss: 5.8503 - accuracy: 0.63 - ETA: 0s - loss: 5.8460 - accuracy: 0.63 - ETA: 0s - loss: 5.8438 - accuracy: 0.63 - ETA: 0s - loss: 5.8458 - accuracy: 0.63 - ETA: 0s - loss: 5.8475 - accuracy: 0.63 - ETA: 0s - loss: 5.8500 - accuracy: 0.63 - ETA: 0s - loss: 5.8487 - accuracy: 0.63 - ETA: 0s - loss: 5.8508 - accuracy: 0.63 - ETA: 0s - loss: 5.8458 - accuracy: 0.63 - ETA: 0s - loss: 5.8528 - accuracy: 0.63 - ETA: 0s - loss: 5.8551 - accuracy: 0.63 - 5s 76us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 4s - loss: 5.8025 - accuracy: 0.64 - ETA: 4s - loss: 6.0532 - accuracy: 0.62 - ETA: 5s - loss: 6.2737 - accuracy: 0.61 - ETA: 5s - loss: 6.1652 - accuracy: 0.61 - ETA: 5s - loss: 6.0753 - accuracy: 0.62 - ETA: 5s - loss: 6.0077 - accuracy: 0.62 - ETA: 5s - loss: 6.0322 - accuracy: 0.62 - ETA: 5s - loss: 6.0254 - accuracy: 0.62 - ETA: 4s - loss: 6.0370 - accuracy: 0.62 - ETA: 4s - loss: 6.0417 - accuracy: 0.62 - ETA: 4s - loss: 6.0182 - accuracy: 0.62 - ETA: 4s - loss: 6.0196 - accuracy: 0.62 - ETA: 4s - loss: 6.0482 - accuracy: 0.62 - ETA: 4s - loss: 6.0138 - accuracy: 0.62 - ETA: 4s - loss: 5.9753 - accuracy: 0.62 - ETA: 4s - loss: 5.9528 - accuracy: 0.63 - ETA: 4s - loss: 5.9506 - accuracy: 0.63 - ETA: 4s - loss: 5.9514 - accuracy: 0.63 - ETA: 4s - loss: 5.9509 - accuracy: 0.63 - ETA: 4s - loss: 5.9310 - accuracy: 0.63 - ETA: 4s - loss: 5.9303 - accuracy: 0.63 - ETA: 4s - loss: 5.9144 - accuracy: 0.63 - ETA: 4s - loss: 5.9124 - accuracy: 0.63 - ETA: 3s - loss: 5.8966 - accuracy: 0.63 - ETA: 3s - loss: 5.8831 - accuracy: 0.63 - ETA: 3s - loss: 5.8845 - accuracy: 0.63 - ETA: 3s - loss: 5.8640 - accuracy: 0.63 - ETA: 3s - loss: 5.8551 - accuracy: 0.63 - ETA: 3s - loss: 5.8568 - accuracy: 0.63 - ETA: 3s - loss: 5.8560 - accuracy: 0.63 - ETA: 3s - loss: 5.8544 - accuracy: 0.63 - ETA: 3s - loss: 5.8683 - accuracy: 0.63 - ETA: 3s - loss: 5.8648 - accuracy: 0.63 - ETA: 3s - loss: 5.8693 - accuracy: 0.63 - ETA: 3s - loss: 5.8693 - accuracy: 0.63 - ETA: 3s - loss: 5.8594 - accuracy: 0.63 - ETA: 3s - loss: 5.8582 - accuracy: 0.63 - ETA: 3s - loss: 5.8503 - accuracy: 0.63 - ETA: 3s - loss: 5.8447 - accuracy: 0.63 - ETA: 3s - loss: 5.8448 - accuracy: 0.63 - ETA: 3s - loss: 5.8331 - accuracy: 0.63 - ETA: 3s - loss: 5.8289 - accuracy: 0.63 - ETA: 3s - loss: 5.8333 - accuracy: 0.63 - ETA: 3s - loss: 5.8408 - accuracy: 0.63 - ETA: 2s - loss: 5.8431 - accuracy: 0.63 - ETA: 2s - loss: 5.8301 - accuracy: 0.63 - ETA: 2s - loss: 5.8295 - accuracy: 0.63 - ETA: 2s - loss: 5.8184 - accuracy: 0.63 - ETA: 2s - loss: 5.8176 - accuracy: 0.63 - ETA: 2s - loss: 5.8221 - accuracy: 0.63 - ETA: 2s - loss: 5.8231 - accuracy: 0.63 - ETA: 2s - loss: 5.8094 - accuracy: 0.63 - ETA: 2s - loss: 5.8102 - accuracy: 0.63 - ETA: 2s - loss: 5.8180 - accuracy: 0.63 - ETA: 2s - loss: 5.8125 - accuracy: 0.63 - ETA: 2s - loss: 5.8012 - accuracy: 0.64 - ETA: 2s - loss: 5.8021 - accuracy: 0.64 - ETA: 2s - loss: 5.8058 - accuracy: 0.63 - ETA: 2s - loss: 5.8102 - accuracy: 0.63 - ETA: 2s - loss: 5.8069 - accuracy: 0.63 - ETA: 2s - loss: 5.8111 - accuracy: 0.63 - ETA: 2s - loss: 5.8048 - accuracy: 0.63 - ETA: 2s - loss: 5.8153 - accuracy: 0.63 - ETA: 1s - loss: 5.8192 - accuracy: 0.63 - ETA: 1s - loss: 5.8255 - accuracy: 0.63 - ETA: 1s - loss: 5.8241 - accuracy: 0.63 - ETA: 1s - loss: 5.8262 - accuracy: 0.63 - ETA: 1s - loss: 5.8325 - accuracy: 0.63 - ETA: 1s - loss: 5.8314 - accuracy: 0.63 - ETA: 1s - loss: 5.8310 - accuracy: 0.63 - ETA: 1s - loss: 5.8265 - accuracy: 0.63 - ETA: 1s - loss: 5.8233 - accuracy: 0.63 - ETA: 1s - loss: 5.8234 - accuracy: 0.63 - ETA: 1s - loss: 5.8224 - accuracy: 0.63 - ETA: 1s - loss: 5.8269 - accuracy: 0.63 - ETA: 1s - loss: 5.8238 - accuracy: 0.63 - ETA: 1s - loss: 5.8340 - accuracy: 0.63 - ETA: 1s - loss: 5.8354 - accuracy: 0.63 - ETA: 1s - loss: 5.8408 - accuracy: 0.63 - ETA: 1s - loss: 5.8428 - accuracy: 0.63 - ETA: 1s - loss: 5.8479 - accuracy: 0.63 - ETA: 1s - loss: 5.8488 - accuracy: 0.63 - ETA: 1s - loss: 5.8413 - accuracy: 0.63 - ETA: 0s - loss: 5.8471 - accuracy: 0.63 - ETA: 0s - loss: 5.8490 - accuracy: 0.63 - ETA: 0s - loss: 5.8543 - accuracy: 0.63 - ETA: 0s - loss: 5.8518 - accuracy: 0.63 - ETA: 0s - loss: 5.8501 - accuracy: 0.63 - ETA: 0s - loss: 5.8495 - accuracy: 0.63 - ETA: 0s - loss: 5.8484 - accuracy: 0.63 - ETA: 0s - loss: 5.8467 - accuracy: 0.63 - ETA: 0s - loss: 5.8458 - accuracy: 0.63 - ETA: 0s - loss: 5.8466 - accuracy: 0.63 - ETA: 0s - loss: 5.8519 - accuracy: 0.63 - ETA: 0s - loss: 5.8529 - accuracy: 0.63 - ETA: 0s - loss: 5.8533 - accuracy: 0.63 - ETA: 0s - loss: 5.8526 - accuracy: 0.63 - ETA: 0s - loss: 5.8541 - accuracy: 0.63 - ETA: 0s - loss: 5.8530 - accuracy: 0.63 - ETA: 0s - loss: 5.8539 - accuracy: 0.63 - ETA: 0s - loss: 5.8515 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - ETA: 0s - loss: 5.8583 - accuracy: 0.63 - 5s 76us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 37/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 6.4472 - accuracy: 0.60 - ETA: 5s - loss: 5.7421 - accuracy: 0.64 - ETA: 5s - loss: 6.1464 - accuracy: 0.61 - ETA: 5s - loss: 6.0338 - accuracy: 0.62 - ETA: 4s - loss: 5.9689 - accuracy: 0.62 - ETA: 4s - loss: 5.9679 - accuracy: 0.62 - ETA: 4s - loss: 5.9672 - accuracy: 0.62 - ETA: 4s - loss: 5.9338 - accuracy: 0.63 - ETA: 4s - loss: 5.9214 - accuracy: 0.63 - ETA: 4s - loss: 5.9132 - accuracy: 0.63 - ETA: 4s - loss: 5.9484 - accuracy: 0.63 - ETA: 4s - loss: 5.9395 - accuracy: 0.63 - ETA: 4s - loss: 5.9326 - accuracy: 0.63 - ETA: 4s - loss: 5.9382 - accuracy: 0.63 - ETA: 4s - loss: 5.9021 - accuracy: 0.63 - ETA: 4s - loss: 5.9208 - accuracy: 0.63 - ETA: 4s - loss: 5.9174 - accuracy: 0.63 - ETA: 4s - loss: 5.9064 - accuracy: 0.63 - ETA: 4s - loss: 5.9231 - accuracy: 0.63 - ETA: 4s - loss: 5.9358 - accuracy: 0.63 - ETA: 4s - loss: 5.9234 - accuracy: 0.63 - ETA: 4s - loss: 5.9089 - accuracy: 0.63 - ETA: 4s - loss: 5.9114 - accuracy: 0.63 - ETA: 4s - loss: 5.9186 - accuracy: 0.63 - ETA: 3s - loss: 5.9311 - accuracy: 0.63 - ETA: 3s - loss: 5.9407 - accuracy: 0.63 - ETA: 3s - loss: 5.9292 - accuracy: 0.63 - ETA: 3s - loss: 5.9236 - accuracy: 0.63 - ETA: 3s - loss: 5.9144 - accuracy: 0.63 - ETA: 3s - loss: 5.9184 - accuracy: 0.63 - ETA: 3s - loss: 5.9143 - accuracy: 0.63 - ETA: 3s - loss: 5.9082 - accuracy: 0.63 - ETA: 3s - loss: 5.9087 - accuracy: 0.63 - ETA: 3s - loss: 5.9081 - accuracy: 0.63 - ETA: 3s - loss: 5.9060 - accuracy: 0.63 - ETA: 3s - loss: 5.9129 - accuracy: 0.63 - ETA: 3s - loss: 5.9012 - accuracy: 0.63 - ETA: 3s - loss: 5.8995 - accuracy: 0.63 - ETA: 3s - loss: 5.9020 - accuracy: 0.63 - ETA: 3s - loss: 5.9026 - accuracy: 0.63 - ETA: 3s - loss: 5.9043 - accuracy: 0.63 - ETA: 3s - loss: 5.9066 - accuracy: 0.63 - ETA: 3s - loss: 5.9086 - accuracy: 0.63 - ETA: 3s - loss: 5.9133 - accuracy: 0.63 - ETA: 3s - loss: 5.9107 - accuracy: 0.63 - ETA: 3s - loss: 5.9176 - accuracy: 0.63 - ETA: 3s - loss: 5.9163 - accuracy: 0.63 - ETA: 3s - loss: 5.9161 - accuracy: 0.63 - ETA: 3s - loss: 5.9148 - accuracy: 0.63 - ETA: 3s - loss: 5.9122 - accuracy: 0.63 - ETA: 3s - loss: 5.9010 - accuracy: 0.63 - ETA: 3s - loss: 5.8960 - accuracy: 0.63 - ETA: 2s - loss: 5.8876 - accuracy: 0.63 - ETA: 2s - loss: 5.8866 - accuracy: 0.63 - ETA: 2s - loss: 5.8833 - accuracy: 0.63 - ETA: 2s - loss: 5.8700 - accuracy: 0.63 - ETA: 2s - loss: 5.8591 - accuracy: 0.63 - ETA: 2s - loss: 5.8650 - accuracy: 0.63 - ETA: 2s - loss: 5.8663 - accuracy: 0.63 - ETA: 2s - loss: 5.8642 - accuracy: 0.63 - ETA: 2s - loss: 5.8670 - accuracy: 0.63 - ETA: 2s - loss: 5.8728 - accuracy: 0.63 - ETA: 2s - loss: 5.8649 - accuracy: 0.63 - ETA: 2s - loss: 5.8597 - accuracy: 0.63 - ETA: 2s - loss: 5.8533 - accuracy: 0.63 - ETA: 2s - loss: 5.8542 - accuracy: 0.63 - ETA: 2s - loss: 5.8624 - accuracy: 0.63 - ETA: 2s - loss: 5.8696 - accuracy: 0.63 - ETA: 2s - loss: 5.8710 - accuracy: 0.63 - ETA: 2s - loss: 5.8715 - accuracy: 0.63 - ETA: 2s - loss: 5.8612 - accuracy: 0.63 - ETA: 2s - loss: 5.8593 - accuracy: 0.63 - ETA: 2s - loss: 5.8623 - accuracy: 0.63 - ETA: 1s - loss: 5.8660 - accuracy: 0.63 - ETA: 1s - loss: 5.8623 - accuracy: 0.63 - ETA: 1s - loss: 5.8585 - accuracy: 0.63 - ETA: 1s - loss: 5.8624 - accuracy: 0.63 - ETA: 1s - loss: 5.8603 - accuracy: 0.63 - ETA: 1s - loss: 5.8621 - accuracy: 0.63 - ETA: 1s - loss: 5.8667 - accuracy: 0.63 - ETA: 1s - loss: 5.8681 - accuracy: 0.63 - ETA: 1s - loss: 5.8683 - accuracy: 0.63 - ETA: 1s - loss: 5.8708 - accuracy: 0.63 - ETA: 1s - loss: 5.8723 - accuracy: 0.63 - ETA: 1s - loss: 5.8703 - accuracy: 0.63 - ETA: 1s - loss: 5.8722 - accuracy: 0.63 - ETA: 1s - loss: 5.8698 - accuracy: 0.63 - ETA: 1s - loss: 5.8619 - accuracy: 0.63 - ETA: 1s - loss: 5.8663 - accuracy: 0.63 - ETA: 1s - loss: 5.8678 - accuracy: 0.63 - ETA: 1s - loss: 5.8705 - accuracy: 0.63 - ETA: 1s - loss: 5.8614 - accuracy: 0.63 - ETA: 1s - loss: 5.8610 - accuracy: 0.63 - ETA: 1s - loss: 5.8578 - accuracy: 0.63 - ETA: 0s - loss: 5.8587 - accuracy: 0.63 - ETA: 0s - loss: 5.8629 - accuracy: 0.63 - ETA: 0s - loss: 5.8611 - accuracy: 0.63 - ETA: 0s - loss: 5.8588 - accuracy: 0.63 - ETA: 0s - loss: 5.8597 - accuracy: 0.63 - ETA: 0s - loss: 5.8554 - accuracy: 0.63 - ETA: 0s - loss: 5.8561 - accuracy: 0.63 - ETA: 0s - loss: 5.8561 - accuracy: 0.63 - ETA: 0s - loss: 5.8513 - accuracy: 0.63 - ETA: 0s - loss: 5.8566 - accuracy: 0.63 - ETA: 0s - loss: 5.8649 - accuracy: 0.63 - ETA: 0s - loss: 5.8634 - accuracy: 0.63 - ETA: 0s - loss: 5.8605 - accuracy: 0.63 - ETA: 0s - loss: 5.8643 - accuracy: 0.63 - ETA: 0s - loss: 5.8615 - accuracy: 0.63 - ETA: 0s - loss: 5.8614 - accuracy: 0.63 - ETA: 0s - loss: 5.8575 - accuracy: 0.63 - ETA: 0s - loss: 5.8560 - accuracy: 0.63 - 6s 84us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 5s - loss: 5.4802 - accuracy: 0.66 - ETA: 5s - loss: 5.5809 - accuracy: 0.65 - ETA: 4s - loss: 5.6816 - accuracy: 0.64 - ETA: 4s - loss: 5.8586 - accuracy: 0.63 - ETA: 4s - loss: 5.8857 - accuracy: 0.63 - ETA: 4s - loss: 5.9128 - accuracy: 0.63 - ETA: 4s - loss: 5.8706 - accuracy: 0.63 - ETA: 4s - loss: 5.8315 - accuracy: 0.63 - ETA: 4s - loss: 5.8630 - accuracy: 0.63 - ETA: 4s - loss: 5.8935 - accuracy: 0.63 - ETA: 4s - loss: 5.8831 - accuracy: 0.63 - ETA: 4s - loss: 5.8809 - accuracy: 0.63 - ETA: 4s - loss: 5.9335 - accuracy: 0.63 - ETA: 4s - loss: 5.9168 - accuracy: 0.63 - ETA: 5s - loss: 5.8921 - accuracy: 0.63 - ETA: 4s - loss: 5.8457 - accuracy: 0.63 - ETA: 4s - loss: 5.8351 - accuracy: 0.63 - ETA: 4s - loss: 5.8272 - accuracy: 0.63 - ETA: 4s - loss: 5.8271 - accuracy: 0.63 - ETA: 4s - loss: 5.8296 - accuracy: 0.63 - ETA: 4s - loss: 5.8464 - accuracy: 0.63 - ETA: 4s - loss: 5.8583 - accuracy: 0.63 - ETA: 4s - loss: 5.8486 - accuracy: 0.63 - ETA: 4s - loss: 5.8606 - accuracy: 0.63 - ETA: 4s - loss: 5.8486 - accuracy: 0.63 - ETA: 4s - loss: 5.8376 - accuracy: 0.63 - ETA: 4s - loss: 5.8355 - accuracy: 0.63 - ETA: 4s - loss: 5.8400 - accuracy: 0.63 - ETA: 4s - loss: 5.8327 - accuracy: 0.63 - ETA: 4s - loss: 5.8344 - accuracy: 0.63 - ETA: 4s - loss: 5.8291 - accuracy: 0.63 - ETA: 4s - loss: 5.8308 - accuracy: 0.63 - ETA: 4s - loss: 5.8434 - accuracy: 0.63 - ETA: 4s - loss: 5.8422 - accuracy: 0.63 - ETA: 4s - loss: 5.8448 - accuracy: 0.63 - ETA: 4s - loss: 5.8527 - accuracy: 0.63 - ETA: 4s - loss: 5.8614 - accuracy: 0.63 - ETA: 4s - loss: 5.8572 - accuracy: 0.63 - ETA: 4s - loss: 5.8553 - accuracy: 0.63 - ETA: 3s - loss: 5.8625 - accuracy: 0.63 - ETA: 3s - loss: 5.8621 - accuracy: 0.63 - ETA: 3s - loss: 5.8615 - accuracy: 0.63 - ETA: 3s - loss: 5.8682 - accuracy: 0.63 - ETA: 3s - loss: 5.8665 - accuracy: 0.63 - ETA: 3s - loss: 5.8539 - accuracy: 0.63 - ETA: 3s - loss: 5.8425 - accuracy: 0.63 - ETA: 3s - loss: 5.8445 - accuracy: 0.63 - ETA: 3s - loss: 5.8532 - accuracy: 0.63 - ETA: 3s - loss: 5.8499 - accuracy: 0.63 - ETA: 3s - loss: 5.8411 - accuracy: 0.63 - ETA: 3s - loss: 5.8541 - accuracy: 0.63 - ETA: 3s - loss: 5.8541 - accuracy: 0.63 - ETA: 3s - loss: 5.8525 - accuracy: 0.63 - ETA: 3s - loss: 5.8556 - accuracy: 0.63 - ETA: 3s - loss: 5.8645 - accuracy: 0.63 - ETA: 3s - loss: 5.8649 - accuracy: 0.63 - ETA: 3s - loss: 5.8712 - accuracy: 0.63 - ETA: 2s - loss: 5.8612 - accuracy: 0.63 - ETA: 2s - loss: 5.8624 - accuracy: 0.63 - ETA: 2s - loss: 5.8634 - accuracy: 0.63 - ETA: 2s - loss: 5.8638 - accuracy: 0.63 - ETA: 2s - loss: 5.8647 - accuracy: 0.63 - ETA: 2s - loss: 5.8644 - accuracy: 0.63 - ETA: 2s - loss: 5.8608 - accuracy: 0.63 - ETA: 2s - loss: 5.8504 - accuracy: 0.63 - ETA: 2s - loss: 5.8490 - accuracy: 0.63 - ETA: 2s - loss: 5.8510 - accuracy: 0.63 - ETA: 2s - loss: 5.8476 - accuracy: 0.63 - ETA: 2s - loss: 5.8520 - accuracy: 0.63 - ETA: 2s - loss: 5.8495 - accuracy: 0.63 - ETA: 2s - loss: 5.8545 - accuracy: 0.63 - ETA: 2s - loss: 5.8536 - accuracy: 0.63 - ETA: 2s - loss: 5.8495 - accuracy: 0.63 - ETA: 2s - loss: 5.8567 - accuracy: 0.63 - ETA: 2s - loss: 5.8525 - accuracy: 0.63 - ETA: 1s - loss: 5.8481 - accuracy: 0.63 - ETA: 1s - loss: 5.8481 - accuracy: 0.63 - ETA: 1s - loss: 5.8519 - accuracy: 0.63 - ETA: 1s - loss: 5.8600 - accuracy: 0.63 - ETA: 1s - loss: 5.8565 - accuracy: 0.63 - ETA: 1s - loss: 5.8556 - accuracy: 0.63 - ETA: 1s - loss: 5.8534 - accuracy: 0.63 - ETA: 1s - loss: 5.8546 - accuracy: 0.63 - ETA: 1s - loss: 5.8547 - accuracy: 0.63 - ETA: 1s - loss: 5.8538 - accuracy: 0.63 - ETA: 1s - loss: 5.8597 - accuracy: 0.63 - ETA: 1s - loss: 5.8613 - accuracy: 0.63 - ETA: 1s - loss: 5.8613 - accuracy: 0.63 - ETA: 1s - loss: 5.8607 - accuracy: 0.63 - ETA: 1s - loss: 5.8599 - accuracy: 0.63 - ETA: 1s - loss: 5.8632 - accuracy: 0.63 - ETA: 1s - loss: 5.8591 - accuracy: 0.63 - ETA: 1s - loss: 5.8561 - accuracy: 0.63 - ETA: 1s - loss: 5.8534 - accuracy: 0.63 - ETA: 0s - loss: 5.8512 - accuracy: 0.63 - ETA: 0s - loss: 5.8517 - accuracy: 0.63 - ETA: 0s - loss: 5.8509 - accuracy: 0.63 - ETA: 0s - loss: 5.8522 - accuracy: 0.63 - ETA: 0s - loss: 5.8483 - accuracy: 0.63 - ETA: 0s - loss: 5.8492 - accuracy: 0.63 - ETA: 0s - loss: 5.8520 - accuracy: 0.63 - ETA: 0s - loss: 5.8548 - accuracy: 0.63 - ETA: 0s - loss: 5.8557 - accuracy: 0.63 - ETA: 0s - loss: 5.8533 - accuracy: 0.63 - ETA: 0s - loss: 5.8537 - accuracy: 0.63 - ETA: 0s - loss: 5.8507 - accuracy: 0.63 - ETA: 0s - loss: 5.8521 - accuracy: 0.63 - ETA: 0s - loss: 5.8524 - accuracy: 0.63 - ETA: 0s - loss: 5.8530 - accuracy: 0.63 - ETA: 0s - loss: 5.8520 - accuracy: 0.63 - ETA: 0s - loss: 5.8561 - accuracy: 0.63 - ETA: 0s - loss: 5.8545 - accuracy: 0.63 - ETA: 0s - loss: 5.8534 - accuracy: 0.63 - 6s 86us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 39/50\n",
      "70000/70000 [==============================] - ETA: 11s - loss: 6.4472 - accuracy: 0.600 - ETA: 8s - loss: 5.8294 - accuracy: 0.638 - ETA: 8s - loss: 5.8670 - accuracy: 0.63 - ETA: 8s - loss: 5.7810 - accuracy: 0.64 - ETA: 8s - loss: 5.8267 - accuracy: 0.63 - ETA: 8s - loss: 5.8165 - accuracy: 0.63 - ETA: 8s - loss: 5.8742 - accuracy: 0.63 - ETA: 8s - loss: 5.8881 - accuracy: 0.63 - ETA: 7s - loss: 5.8746 - accuracy: 0.63 - ETA: 7s - loss: 5.8240 - accuracy: 0.63 - ETA: 6s - loss: 5.8304 - accuracy: 0.63 - ETA: 6s - loss: 5.8136 - accuracy: 0.63 - ETA: 6s - loss: 5.8428 - accuracy: 0.63 - ETA: 6s - loss: 5.7980 - accuracy: 0.64 - ETA: 6s - loss: 5.8294 - accuracy: 0.63 - ETA: 6s - loss: 5.8142 - accuracy: 0.63 - ETA: 5s - loss: 5.8276 - accuracy: 0.63 - ETA: 5s - loss: 5.8176 - accuracy: 0.63 - ETA: 6s - loss: 5.7946 - accuracy: 0.64 - ETA: 7s - loss: 5.8103 - accuracy: 0.63 - ETA: 7s - loss: 5.7996 - accuracy: 0.64 - ETA: 6s - loss: 5.7871 - accuracy: 0.64 - ETA: 6s - loss: 5.7853 - accuracy: 0.64 - ETA: 6s - loss: 5.7987 - accuracy: 0.64 - ETA: 6s - loss: 5.8001 - accuracy: 0.64 - ETA: 6s - loss: 5.7945 - accuracy: 0.64 - ETA: 6s - loss: 5.8025 - accuracy: 0.64 - ETA: 5s - loss: 5.7888 - accuracy: 0.64 - ETA: 5s - loss: 5.8127 - accuracy: 0.63 - ETA: 5s - loss: 5.8190 - accuracy: 0.63 - ETA: 5s - loss: 5.8100 - accuracy: 0.63 - ETA: 5s - loss: 5.8062 - accuracy: 0.63 - ETA: 5s - loss: 5.8166 - accuracy: 0.63 - ETA: 5s - loss: 5.8238 - accuracy: 0.63 - ETA: 5s - loss: 5.8108 - accuracy: 0.63 - ETA: 5s - loss: 5.8210 - accuracy: 0.63 - ETA: 5s - loss: 5.8521 - accuracy: 0.63 - ETA: 4s - loss: 5.8674 - accuracy: 0.63 - ETA: 4s - loss: 5.8616 - accuracy: 0.63 - ETA: 4s - loss: 5.8551 - accuracy: 0.63 - ETA: 4s - loss: 5.8466 - accuracy: 0.63 - ETA: 4s - loss: 5.8560 - accuracy: 0.63 - ETA: 4s - loss: 5.8660 - accuracy: 0.63 - ETA: 4s - loss: 5.8787 - accuracy: 0.63 - ETA: 4s - loss: 5.8699 - accuracy: 0.63 - ETA: 4s - loss: 5.8618 - accuracy: 0.63 - ETA: 4s - loss: 5.8533 - accuracy: 0.63 - ETA: 4s - loss: 5.8551 - accuracy: 0.63 - ETA: 3s - loss: 5.8463 - accuracy: 0.63 - ETA: 4s - loss: 5.8455 - accuracy: 0.63 - ETA: 3s - loss: 5.8504 - accuracy: 0.63 - ETA: 3s - loss: 5.8393 - accuracy: 0.63 - ETA: 3s - loss: 5.8338 - accuracy: 0.63 - ETA: 3s - loss: 5.8327 - accuracy: 0.63 - ETA: 3s - loss: 5.8298 - accuracy: 0.63 - ETA: 3s - loss: 5.8201 - accuracy: 0.63 - ETA: 3s - loss: 5.8222 - accuracy: 0.63 - ETA: 3s - loss: 5.8228 - accuracy: 0.63 - ETA: 3s - loss: 5.8243 - accuracy: 0.63 - ETA: 3s - loss: 5.8230 - accuracy: 0.63 - ETA: 3s - loss: 5.8222 - accuracy: 0.63 - ETA: 3s - loss: 5.8214 - accuracy: 0.63 - ETA: 3s - loss: 5.8259 - accuracy: 0.63 - ETA: 3s - loss: 5.8268 - accuracy: 0.63 - ETA: 3s - loss: 5.8302 - accuracy: 0.63 - ETA: 2s - loss: 5.8342 - accuracy: 0.63 - ETA: 2s - loss: 5.8320 - accuracy: 0.63 - ETA: 2s - loss: 5.8275 - accuracy: 0.63 - ETA: 2s - loss: 5.8227 - accuracy: 0.63 - ETA: 2s - loss: 5.8283 - accuracy: 0.63 - ETA: 2s - loss: 5.8352 - accuracy: 0.63 - ETA: 2s - loss: 5.8310 - accuracy: 0.63 - ETA: 2s - loss: 5.8333 - accuracy: 0.63 - ETA: 2s - loss: 5.8317 - accuracy: 0.63 - ETA: 2s - loss: 5.8299 - accuracy: 0.63 - ETA: 2s - loss: 5.8284 - accuracy: 0.63 - ETA: 2s - loss: 5.8309 - accuracy: 0.63 - ETA: 2s - loss: 5.8315 - accuracy: 0.63 - ETA: 2s - loss: 5.8359 - accuracy: 0.63 - ETA: 2s - loss: 5.8323 - accuracy: 0.63 - ETA: 2s - loss: 5.8383 - accuracy: 0.63 - ETA: 1s - loss: 5.8365 - accuracy: 0.63 - ETA: 1s - loss: 5.8360 - accuracy: 0.63 - ETA: 1s - loss: 5.8390 - accuracy: 0.63 - ETA: 1s - loss: 5.8385 - accuracy: 0.63 - ETA: 1s - loss: 5.8336 - accuracy: 0.63 - ETA: 1s - loss: 5.8357 - accuracy: 0.63 - ETA: 1s - loss: 5.8365 - accuracy: 0.63 - ETA: 1s - loss: 5.8374 - accuracy: 0.63 - ETA: 1s - loss: 5.8375 - accuracy: 0.63 - ETA: 1s - loss: 5.8362 - accuracy: 0.63 - ETA: 1s - loss: 5.8427 - accuracy: 0.63 - ETA: 1s - loss: 5.8465 - accuracy: 0.63 - ETA: 1s - loss: 5.8400 - accuracy: 0.63 - ETA: 1s - loss: 5.8426 - accuracy: 0.63 - ETA: 1s - loss: 5.8419 - accuracy: 0.63 - ETA: 1s - loss: 5.8429 - accuracy: 0.63 - ETA: 0s - loss: 5.8498 - accuracy: 0.63 - ETA: 0s - loss: 5.8539 - accuracy: 0.63 - ETA: 0s - loss: 5.8542 - accuracy: 0.63 - ETA: 0s - loss: 5.8539 - accuracy: 0.63 - ETA: 0s - loss: 5.8522 - accuracy: 0.63 - ETA: 0s - loss: 5.8481 - accuracy: 0.63 - ETA: 0s - loss: 5.8505 - accuracy: 0.63 - ETA: 0s - loss: 5.8462 - accuracy: 0.63 - ETA: 0s - loss: 5.8410 - accuracy: 0.63 - ETA: 0s - loss: 5.8431 - accuracy: 0.63 - ETA: 0s - loss: 5.8420 - accuracy: 0.63 - ETA: 0s - loss: 5.8423 - accuracy: 0.63 - ETA: 0s - loss: 5.8388 - accuracy: 0.63 - ETA: 0s - loss: 5.8430 - accuracy: 0.63 - ETA: 0s - loss: 5.8460 - accuracy: 0.63 - ETA: 0s - loss: 5.8514 - accuracy: 0.63 - ETA: 0s - loss: 5.8540 - accuracy: 0.63 - 6s 89us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 5s - loss: 6.6084 - accuracy: 0.59 - ETA: 6s - loss: 6.4242 - accuracy: 0.60 - ETA: 5s - loss: 5.9637 - accuracy: 0.63 - ETA: 5s - loss: 5.9879 - accuracy: 0.62 - ETA: 5s - loss: 5.9279 - accuracy: 0.63 - ETA: 5s - loss: 5.7788 - accuracy: 0.64 - ETA: 5s - loss: 5.8929 - accuracy: 0.63 - ETA: 5s - loss: 5.9335 - accuracy: 0.63 - ETA: 5s - loss: 5.9059 - accuracy: 0.63 - ETA: 5s - loss: 5.8213 - accuracy: 0.63 - ETA: 5s - loss: 5.8104 - accuracy: 0.63 - ETA: 5s - loss: 5.8049 - accuracy: 0.63 - ETA: 5s - loss: 5.8227 - accuracy: 0.63 - ETA: 5s - loss: 5.7904 - accuracy: 0.64 - ETA: 5s - loss: 5.7784 - accuracy: 0.64 - ETA: 5s - loss: 5.7922 - accuracy: 0.64 - ETA: 5s - loss: 5.7977 - accuracy: 0.64 - ETA: 5s - loss: 5.7754 - accuracy: 0.64 - ETA: 5s - loss: 5.7749 - accuracy: 0.64 - ETA: 5s - loss: 5.7915 - accuracy: 0.64 - ETA: 5s - loss: 5.7947 - accuracy: 0.64 - ETA: 4s - loss: 5.8075 - accuracy: 0.63 - ETA: 4s - loss: 5.8037 - accuracy: 0.63 - ETA: 4s - loss: 5.8071 - accuracy: 0.63 - ETA: 4s - loss: 5.8156 - accuracy: 0.63 - ETA: 4s - loss: 5.8296 - accuracy: 0.63 - ETA: 4s - loss: 5.8423 - accuracy: 0.63 - ETA: 4s - loss: 5.8342 - accuracy: 0.63 - ETA: 4s - loss: 5.8229 - accuracy: 0.63 - ETA: 4s - loss: 5.8242 - accuracy: 0.63 - ETA: 4s - loss: 5.8165 - accuracy: 0.63 - ETA: 4s - loss: 5.8311 - accuracy: 0.63 - ETA: 4s - loss: 5.8398 - accuracy: 0.63 - ETA: 4s - loss: 5.8469 - accuracy: 0.63 - ETA: 4s - loss: 5.8420 - accuracy: 0.63 - ETA: 4s - loss: 5.8454 - accuracy: 0.63 - ETA: 4s - loss: 5.8445 - accuracy: 0.63 - ETA: 4s - loss: 5.8367 - accuracy: 0.63 - ETA: 4s - loss: 5.8477 - accuracy: 0.63 - ETA: 4s - loss: 5.8506 - accuracy: 0.63 - ETA: 4s - loss: 5.8600 - accuracy: 0.63 - ETA: 4s - loss: 5.8584 - accuracy: 0.63 - ETA: 3s - loss: 5.8611 - accuracy: 0.63 - ETA: 3s - loss: 5.8641 - accuracy: 0.63 - ETA: 3s - loss: 5.8694 - accuracy: 0.63 - ETA: 3s - loss: 5.8695 - accuracy: 0.63 - ETA: 3s - loss: 5.8572 - accuracy: 0.63 - ETA: 3s - loss: 5.8652 - accuracy: 0.63 - ETA: 3s - loss: 5.8564 - accuracy: 0.63 - ETA: 3s - loss: 5.8660 - accuracy: 0.63 - ETA: 3s - loss: 5.8626 - accuracy: 0.63 - ETA: 3s - loss: 5.8618 - accuracy: 0.63 - ETA: 3s - loss: 5.8630 - accuracy: 0.63 - ETA: 3s - loss: 5.8528 - accuracy: 0.63 - ETA: 3s - loss: 5.8592 - accuracy: 0.63 - ETA: 3s - loss: 5.8704 - accuracy: 0.63 - ETA: 3s - loss: 5.8709 - accuracy: 0.63 - ETA: 3s - loss: 5.8618 - accuracy: 0.63 - ETA: 3s - loss: 5.8597 - accuracy: 0.63 - ETA: 2s - loss: 5.8619 - accuracy: 0.63 - ETA: 2s - loss: 5.8615 - accuracy: 0.63 - ETA: 2s - loss: 5.8632 - accuracy: 0.63 - ETA: 2s - loss: 5.8680 - accuracy: 0.63 - ETA: 2s - loss: 5.8602 - accuracy: 0.63 - ETA: 2s - loss: 5.8678 - accuracy: 0.63 - ETA: 2s - loss: 5.8614 - accuracy: 0.63 - ETA: 2s - loss: 5.8640 - accuracy: 0.63 - ETA: 2s - loss: 5.8564 - accuracy: 0.63 - ETA: 2s - loss: 5.8552 - accuracy: 0.63 - ETA: 2s - loss: 5.8545 - accuracy: 0.63 - ETA: 2s - loss: 5.8596 - accuracy: 0.63 - ETA: 2s - loss: 5.8631 - accuracy: 0.63 - ETA: 2s - loss: 5.8561 - accuracy: 0.63 - ETA: 2s - loss: 5.8560 - accuracy: 0.63 - ETA: 2s - loss: 5.8524 - accuracy: 0.63 - ETA: 2s - loss: 5.8521 - accuracy: 0.63 - ETA: 2s - loss: 5.8542 - accuracy: 0.63 - ETA: 1s - loss: 5.8580 - accuracy: 0.63 - ETA: 1s - loss: 5.8559 - accuracy: 0.63 - ETA: 1s - loss: 5.8581 - accuracy: 0.63 - ETA: 1s - loss: 5.8636 - accuracy: 0.63 - ETA: 1s - loss: 5.8706 - accuracy: 0.63 - ETA: 1s - loss: 5.8719 - accuracy: 0.63 - ETA: 1s - loss: 5.8700 - accuracy: 0.63 - ETA: 1s - loss: 5.8713 - accuracy: 0.63 - ETA: 1s - loss: 5.8757 - accuracy: 0.63 - ETA: 1s - loss: 5.8784 - accuracy: 0.63 - ETA: 1s - loss: 5.8777 - accuracy: 0.63 - ETA: 1s - loss: 5.8764 - accuracy: 0.63 - ETA: 1s - loss: 5.8784 - accuracy: 0.63 - ETA: 1s - loss: 5.8736 - accuracy: 0.63 - ETA: 1s - loss: 5.8767 - accuracy: 0.63 - ETA: 1s - loss: 5.8711 - accuracy: 0.63 - ETA: 1s - loss: 5.8787 - accuracy: 0.63 - ETA: 1s - loss: 5.8779 - accuracy: 0.63 - ETA: 1s - loss: 5.8706 - accuracy: 0.63 - ETA: 0s - loss: 5.8748 - accuracy: 0.63 - ETA: 0s - loss: 5.8729 - accuracy: 0.63 - ETA: 0s - loss: 5.8678 - accuracy: 0.63 - ETA: 0s - loss: 5.8671 - accuracy: 0.63 - ETA: 0s - loss: 5.8668 - accuracy: 0.63 - ETA: 0s - loss: 5.8662 - accuracy: 0.63 - ETA: 0s - loss: 5.8627 - accuracy: 0.63 - ETA: 0s - loss: 5.8655 - accuracy: 0.63 - ETA: 0s - loss: 5.8635 - accuracy: 0.63 - ETA: 0s - loss: 5.8579 - accuracy: 0.63 - ETA: 0s - loss: 5.8585 - accuracy: 0.63 - ETA: 0s - loss: 5.8606 - accuracy: 0.63 - ETA: 0s - loss: 5.8587 - accuracy: 0.63 - ETA: 0s - loss: 5.8571 - accuracy: 0.63 - ETA: 0s - loss: 5.8568 - accuracy: 0.63 - ETA: 0s - loss: 5.8531 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - ETA: 0s - loss: 5.8579 - accuracy: 0.63 - ETA: 0s - loss: 5.8551 - accuracy: 0.63 - 6s 87us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 41/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 6.1249 - accuracy: 0.62 - ETA: 5s - loss: 5.5003 - accuracy: 0.65 - ETA: 5s - loss: 5.7273 - accuracy: 0.64 - ETA: 5s - loss: 5.9417 - accuracy: 0.63 - ETA: 5s - loss: 5.9915 - accuracy: 0.62 - ETA: 5s - loss: 5.9246 - accuracy: 0.63 - ETA: 5s - loss: 5.8670 - accuracy: 0.63 - ETA: 5s - loss: 5.8162 - accuracy: 0.63 - ETA: 5s - loss: 5.8204 - accuracy: 0.63 - ETA: 5s - loss: 5.7971 - accuracy: 0.64 - ETA: 5s - loss: 5.8049 - accuracy: 0.63 - ETA: 5s - loss: 5.7959 - accuracy: 0.64 - ETA: 5s - loss: 5.7904 - accuracy: 0.64 - ETA: 4s - loss: 5.7692 - accuracy: 0.64 - ETA: 4s - loss: 5.7661 - accuracy: 0.64 - ETA: 4s - loss: 5.7732 - accuracy: 0.64 - ETA: 4s - loss: 5.7396 - accuracy: 0.64 - ETA: 4s - loss: 5.7752 - accuracy: 0.64 - ETA: 4s - loss: 5.7605 - accuracy: 0.64 - ETA: 4s - loss: 5.7820 - accuracy: 0.64 - ETA: 4s - loss: 5.7989 - accuracy: 0.64 - ETA: 4s - loss: 5.7832 - accuracy: 0.64 - ETA: 4s - loss: 5.7874 - accuracy: 0.64 - ETA: 4s - loss: 5.8036 - accuracy: 0.63 - ETA: 4s - loss: 5.7925 - accuracy: 0.64 - ETA: 4s - loss: 5.8015 - accuracy: 0.64 - ETA: 4s - loss: 5.8016 - accuracy: 0.64 - ETA: 4s - loss: 5.7997 - accuracy: 0.64 - ETA: 4s - loss: 5.8052 - accuracy: 0.63 - ETA: 4s - loss: 5.7947 - accuracy: 0.64 - ETA: 4s - loss: 5.7866 - accuracy: 0.64 - ETA: 4s - loss: 5.7977 - accuracy: 0.64 - ETA: 4s - loss: 5.7893 - accuracy: 0.64 - ETA: 4s - loss: 5.7775 - accuracy: 0.64 - ETA: 4s - loss: 5.7735 - accuracy: 0.64 - ETA: 4s - loss: 5.7736 - accuracy: 0.64 - ETA: 4s - loss: 5.7715 - accuracy: 0.64 - ETA: 4s - loss: 5.7874 - accuracy: 0.64 - ETA: 3s - loss: 5.8211 - accuracy: 0.63 - ETA: 3s - loss: 5.8265 - accuracy: 0.63 - ETA: 3s - loss: 5.8271 - accuracy: 0.63 - ETA: 3s - loss: 5.8399 - accuracy: 0.63 - ETA: 3s - loss: 5.8461 - accuracy: 0.63 - ETA: 3s - loss: 5.8475 - accuracy: 0.63 - ETA: 3s - loss: 5.8454 - accuracy: 0.63 - ETA: 3s - loss: 5.8540 - accuracy: 0.63 - ETA: 3s - loss: 5.8681 - accuracy: 0.63 - ETA: 3s - loss: 5.8580 - accuracy: 0.63 - ETA: 3s - loss: 5.8630 - accuracy: 0.63 - ETA: 3s - loss: 5.8641 - accuracy: 0.63 - ETA: 3s - loss: 5.8616 - accuracy: 0.63 - ETA: 3s - loss: 5.8587 - accuracy: 0.63 - ETA: 3s - loss: 5.8569 - accuracy: 0.63 - ETA: 3s - loss: 5.8699 - accuracy: 0.63 - ETA: 3s - loss: 5.8663 - accuracy: 0.63 - ETA: 3s - loss: 5.8687 - accuracy: 0.63 - ETA: 2s - loss: 5.8745 - accuracy: 0.63 - ETA: 2s - loss: 5.8752 - accuracy: 0.63 - ETA: 2s - loss: 5.8796 - accuracy: 0.63 - ETA: 2s - loss: 5.8768 - accuracy: 0.63 - ETA: 2s - loss: 5.8780 - accuracy: 0.63 - ETA: 2s - loss: 5.8712 - accuracy: 0.63 - ETA: 2s - loss: 5.8657 - accuracy: 0.63 - ETA: 2s - loss: 5.8708 - accuracy: 0.63 - ETA: 2s - loss: 5.8656 - accuracy: 0.63 - ETA: 2s - loss: 5.8649 - accuracy: 0.63 - ETA: 2s - loss: 5.8600 - accuracy: 0.63 - ETA: 2s - loss: 5.8606 - accuracy: 0.63 - ETA: 2s - loss: 5.8634 - accuracy: 0.63 - ETA: 2s - loss: 5.8640 - accuracy: 0.63 - ETA: 2s - loss: 5.8701 - accuracy: 0.63 - ETA: 2s - loss: 5.8696 - accuracy: 0.63 - ETA: 2s - loss: 5.8604 - accuracy: 0.63 - ETA: 2s - loss: 5.8600 - accuracy: 0.63 - ETA: 2s - loss: 5.8662 - accuracy: 0.63 - ETA: 1s - loss: 5.8694 - accuracy: 0.63 - ETA: 1s - loss: 5.8668 - accuracy: 0.63 - ETA: 1s - loss: 5.8643 - accuracy: 0.63 - ETA: 1s - loss: 5.8580 - accuracy: 0.63 - ETA: 1s - loss: 5.8612 - accuracy: 0.63 - ETA: 1s - loss: 5.8588 - accuracy: 0.63 - ETA: 1s - loss: 5.8594 - accuracy: 0.63 - ETA: 1s - loss: 5.8552 - accuracy: 0.63 - ETA: 1s - loss: 5.8545 - accuracy: 0.63 - ETA: 1s - loss: 5.8511 - accuracy: 0.63 - ETA: 1s - loss: 5.8451 - accuracy: 0.63 - ETA: 1s - loss: 5.8490 - accuracy: 0.63 - ETA: 1s - loss: 5.8503 - accuracy: 0.63 - ETA: 1s - loss: 5.8440 - accuracy: 0.63 - ETA: 1s - loss: 5.8493 - accuracy: 0.63 - ETA: 1s - loss: 5.8489 - accuracy: 0.63 - ETA: 1s - loss: 5.8495 - accuracy: 0.63 - ETA: 1s - loss: 5.8488 - accuracy: 0.63 - ETA: 1s - loss: 5.8509 - accuracy: 0.63 - ETA: 0s - loss: 5.8496 - accuracy: 0.63 - ETA: 0s - loss: 5.8507 - accuracy: 0.63 - ETA: 0s - loss: 5.8541 - accuracy: 0.63 - ETA: 0s - loss: 5.8567 - accuracy: 0.63 - ETA: 0s - loss: 5.8576 - accuracy: 0.63 - ETA: 0s - loss: 5.8614 - accuracy: 0.63 - ETA: 0s - loss: 5.8620 - accuracy: 0.63 - ETA: 0s - loss: 5.8586 - accuracy: 0.63 - ETA: 0s - loss: 5.8582 - accuracy: 0.63 - ETA: 0s - loss: 5.8554 - accuracy: 0.63 - ETA: 0s - loss: 5.8540 - accuracy: 0.63 - ETA: 0s - loss: 5.8540 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - ETA: 0s - loss: 5.8535 - accuracy: 0.63 - ETA: 0s - loss: 5.8572 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - ETA: 0s - loss: 5.8541 - accuracy: 0.63 - ETA: 0s - loss: 5.8544 - accuracy: 0.63 - 6s 86us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 9s - loss: 6.4472 - accuracy: 0.60 - ETA: 5s - loss: 5.9458 - accuracy: 0.63 - ETA: 5s - loss: 5.9522 - accuracy: 0.63 - ETA: 5s - loss: 5.8992 - accuracy: 0.63 - ETA: 6s - loss: 5.8541 - accuracy: 0.63 - ETA: 5s - loss: 5.8493 - accuracy: 0.63 - ETA: 5s - loss: 5.8619 - accuracy: 0.63 - ETA: 5s - loss: 5.8240 - accuracy: 0.63 - ETA: 5s - loss: 5.8459 - accuracy: 0.63 - ETA: 5s - loss: 5.8626 - accuracy: 0.63 - ETA: 5s - loss: 5.8546 - accuracy: 0.63 - ETA: 5s - loss: 5.8343 - accuracy: 0.63 - ETA: 5s - loss: 5.8088 - accuracy: 0.63 - ETA: 5s - loss: 5.8101 - accuracy: 0.63 - ETA: 4s - loss: 5.8233 - accuracy: 0.63 - ETA: 4s - loss: 5.8138 - accuracy: 0.63 - ETA: 4s - loss: 5.8402 - accuracy: 0.63 - ETA: 4s - loss: 5.8704 - accuracy: 0.63 - ETA: 4s - loss: 5.8638 - accuracy: 0.63 - ETA: 4s - loss: 5.8365 - accuracy: 0.63 - ETA: 4s - loss: 5.8274 - accuracy: 0.63 - ETA: 4s - loss: 5.8341 - accuracy: 0.63 - ETA: 4s - loss: 5.8455 - accuracy: 0.63 - ETA: 4s - loss: 5.8487 - accuracy: 0.63 - ETA: 4s - loss: 5.8500 - accuracy: 0.63 - ETA: 4s - loss: 5.8461 - accuracy: 0.63 - ETA: 4s - loss: 5.8270 - accuracy: 0.63 - ETA: 3s - loss: 5.8234 - accuracy: 0.63 - ETA: 3s - loss: 5.8267 - accuracy: 0.63 - ETA: 3s - loss: 5.8162 - accuracy: 0.63 - ETA: 3s - loss: 5.8451 - accuracy: 0.63 - ETA: 3s - loss: 5.8428 - accuracy: 0.63 - ETA: 3s - loss: 5.8414 - accuracy: 0.63 - ETA: 3s - loss: 5.8305 - accuracy: 0.63 - ETA: 3s - loss: 5.8331 - accuracy: 0.63 - ETA: 3s - loss: 5.8217 - accuracy: 0.63 - ETA: 3s - loss: 5.8277 - accuracy: 0.63 - ETA: 3s - loss: 5.8270 - accuracy: 0.63 - ETA: 3s - loss: 5.8221 - accuracy: 0.63 - ETA: 3s - loss: 5.8150 - accuracy: 0.63 - ETA: 3s - loss: 5.8060 - accuracy: 0.63 - ETA: 3s - loss: 5.8167 - accuracy: 0.63 - ETA: 3s - loss: 5.8086 - accuracy: 0.63 - ETA: 3s - loss: 5.8101 - accuracy: 0.63 - ETA: 2s - loss: 5.8146 - accuracy: 0.63 - ETA: 2s - loss: 5.8133 - accuracy: 0.63 - ETA: 2s - loss: 5.8081 - accuracy: 0.63 - ETA: 2s - loss: 5.8030 - accuracy: 0.64 - ETA: 2s - loss: 5.8030 - accuracy: 0.64 - ETA: 2s - loss: 5.7944 - accuracy: 0.64 - ETA: 2s - loss: 5.7936 - accuracy: 0.64 - ETA: 2s - loss: 5.7909 - accuracy: 0.64 - ETA: 2s - loss: 5.7866 - accuracy: 0.64 - ETA: 2s - loss: 5.7914 - accuracy: 0.64 - ETA: 2s - loss: 5.7977 - accuracy: 0.64 - ETA: 2s - loss: 5.8029 - accuracy: 0.64 - ETA: 2s - loss: 5.7962 - accuracy: 0.64 - ETA: 2s - loss: 5.7971 - accuracy: 0.64 - ETA: 2s - loss: 5.7959 - accuracy: 0.64 - ETA: 2s - loss: 5.7972 - accuracy: 0.64 - ETA: 2s - loss: 5.8025 - accuracy: 0.64 - ETA: 2s - loss: 5.8129 - accuracy: 0.63 - ETA: 2s - loss: 5.8182 - accuracy: 0.63 - ETA: 2s - loss: 5.8269 - accuracy: 0.63 - ETA: 2s - loss: 5.8349 - accuracy: 0.63 - ETA: 2s - loss: 5.8363 - accuracy: 0.63 - ETA: 2s - loss: 5.8325 - accuracy: 0.63 - ETA: 2s - loss: 5.8329 - accuracy: 0.63 - ETA: 2s - loss: 5.8415 - accuracy: 0.63 - ETA: 1s - loss: 5.8398 - accuracy: 0.63 - ETA: 1s - loss: 5.8404 - accuracy: 0.63 - ETA: 1s - loss: 5.8439 - accuracy: 0.63 - ETA: 1s - loss: 5.8382 - accuracy: 0.63 - ETA: 1s - loss: 5.8417 - accuracy: 0.63 - ETA: 1s - loss: 5.8389 - accuracy: 0.63 - ETA: 1s - loss: 5.8438 - accuracy: 0.63 - ETA: 1s - loss: 5.8411 - accuracy: 0.63 - ETA: 1s - loss: 5.8433 - accuracy: 0.63 - ETA: 1s - loss: 5.8438 - accuracy: 0.63 - ETA: 1s - loss: 5.8435 - accuracy: 0.63 - ETA: 1s - loss: 5.8407 - accuracy: 0.63 - ETA: 1s - loss: 5.8439 - accuracy: 0.63 - ETA: 1s - loss: 5.8487 - accuracy: 0.63 - ETA: 1s - loss: 5.8477 - accuracy: 0.63 - ETA: 1s - loss: 5.8430 - accuracy: 0.63 - ETA: 1s - loss: 5.8414 - accuracy: 0.63 - ETA: 1s - loss: 5.8404 - accuracy: 0.63 - ETA: 1s - loss: 5.8386 - accuracy: 0.63 - ETA: 1s - loss: 5.8432 - accuracy: 0.63 - ETA: 0s - loss: 5.8410 - accuracy: 0.63 - ETA: 0s - loss: 5.8502 - accuracy: 0.63 - ETA: 0s - loss: 5.8501 - accuracy: 0.63 - ETA: 0s - loss: 5.8511 - accuracy: 0.63 - ETA: 0s - loss: 5.8466 - accuracy: 0.63 - ETA: 0s - loss: 5.8452 - accuracy: 0.63 - ETA: 0s - loss: 5.8456 - accuracy: 0.63 - ETA: 0s - loss: 5.8445 - accuracy: 0.63 - ETA: 0s - loss: 5.8460 - accuracy: 0.63 - ETA: 0s - loss: 5.8501 - accuracy: 0.63 - ETA: 0s - loss: 5.8482 - accuracy: 0.63 - ETA: 0s - loss: 5.8527 - accuracy: 0.63 - ETA: 0s - loss: 5.8543 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - ETA: 0s - loss: 5.8572 - accuracy: 0.63 - ETA: 0s - loss: 5.8489 - accuracy: 0.63 - ETA: 0s - loss: 5.8537 - accuracy: 0.63 - ETA: 0s - loss: 5.8613 - accuracy: 0.63 - ETA: 0s - loss: 5.8591 - accuracy: 0.63 - ETA: 0s - loss: 5.8553 - accuracy: 0.63 - ETA: 0s - loss: 5.8549 - accuracy: 0.63 - 6s 83us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 43/50\n",
      "70000/70000 [==============================] - ETA: 8s - loss: 4.9966 - accuracy: 0.69 - ETA: 7s - loss: 5.6951 - accuracy: 0.64 - ETA: 7s - loss: 5.7293 - accuracy: 0.64 - ETA: 7s - loss: 5.8499 - accuracy: 0.63 - ETA: 6s - loss: 5.8235 - accuracy: 0.63 - ETA: 6s - loss: 5.7680 - accuracy: 0.64 - ETA: 6s - loss: 5.6935 - accuracy: 0.64 - ETA: 6s - loss: 5.6695 - accuracy: 0.64 - ETA: 6s - loss: 5.6653 - accuracy: 0.64 - ETA: 5s - loss: 5.7204 - accuracy: 0.64 - ETA: 5s - loss: 5.7561 - accuracy: 0.64 - ETA: 5s - loss: 5.7728 - accuracy: 0.64 - ETA: 5s - loss: 5.7321 - accuracy: 0.64 - ETA: 5s - loss: 5.7302 - accuracy: 0.64 - ETA: 5s - loss: 5.7085 - accuracy: 0.64 - ETA: 5s - loss: 5.7524 - accuracy: 0.64 - ETA: 5s - loss: 5.7723 - accuracy: 0.64 - ETA: 5s - loss: 5.7738 - accuracy: 0.64 - ETA: 5s - loss: 5.7573 - accuracy: 0.64 - ETA: 5s - loss: 5.7843 - accuracy: 0.64 - ETA: 5s - loss: 5.7906 - accuracy: 0.64 - ETA: 5s - loss: 5.7889 - accuracy: 0.64 - ETA: 5s - loss: 5.7813 - accuracy: 0.64 - ETA: 5s - loss: 5.7563 - accuracy: 0.64 - ETA: 4s - loss: 5.7495 - accuracy: 0.64 - ETA: 4s - loss: 5.7617 - accuracy: 0.64 - ETA: 4s - loss: 5.7548 - accuracy: 0.64 - ETA: 4s - loss: 5.7581 - accuracy: 0.64 - ETA: 4s - loss: 5.7634 - accuracy: 0.64 - ETA: 4s - loss: 5.7764 - accuracy: 0.64 - ETA: 4s - loss: 5.7903 - accuracy: 0.64 - ETA: 4s - loss: 5.8017 - accuracy: 0.64 - ETA: 4s - loss: 5.8017 - accuracy: 0.64 - ETA: 4s - loss: 5.7937 - accuracy: 0.64 - ETA: 4s - loss: 5.8088 - accuracy: 0.63 - ETA: 4s - loss: 5.7873 - accuracy: 0.64 - ETA: 4s - loss: 5.7996 - accuracy: 0.64 - ETA: 4s - loss: 5.7867 - accuracy: 0.64 - ETA: 4s - loss: 5.7913 - accuracy: 0.64 - ETA: 4s - loss: 5.7957 - accuracy: 0.64 - ETA: 4s - loss: 5.7946 - accuracy: 0.64 - ETA: 4s - loss: 5.8051 - accuracy: 0.63 - ETA: 4s - loss: 5.8140 - accuracy: 0.63 - ETA: 4s - loss: 5.8181 - accuracy: 0.63 - ETA: 3s - loss: 5.8111 - accuracy: 0.63 - ETA: 3s - loss: 5.8121 - accuracy: 0.63 - ETA: 3s - loss: 5.8161 - accuracy: 0.63 - ETA: 3s - loss: 5.8142 - accuracy: 0.63 - ETA: 3s - loss: 5.8187 - accuracy: 0.63 - ETA: 3s - loss: 5.8145 - accuracy: 0.63 - ETA: 3s - loss: 5.8271 - accuracy: 0.63 - ETA: 3s - loss: 5.8245 - accuracy: 0.63 - ETA: 3s - loss: 5.8181 - accuracy: 0.63 - ETA: 3s - loss: 5.8341 - accuracy: 0.63 - ETA: 3s - loss: 5.8331 - accuracy: 0.63 - ETA: 3s - loss: 5.8355 - accuracy: 0.63 - ETA: 3s - loss: 5.8396 - accuracy: 0.63 - ETA: 3s - loss: 5.8364 - accuracy: 0.63 - ETA: 3s - loss: 5.8458 - accuracy: 0.63 - ETA: 3s - loss: 5.8400 - accuracy: 0.63 - ETA: 3s - loss: 5.8366 - accuracy: 0.63 - ETA: 3s - loss: 5.8411 - accuracy: 0.63 - ETA: 3s - loss: 5.8476 - accuracy: 0.63 - ETA: 3s - loss: 5.8506 - accuracy: 0.63 - ETA: 3s - loss: 5.8450 - accuracy: 0.63 - ETA: 3s - loss: 5.8447 - accuracy: 0.63 - ETA: 2s - loss: 5.8457 - accuracy: 0.63 - ETA: 2s - loss: 5.8443 - accuracy: 0.63 - ETA: 2s - loss: 5.8404 - accuracy: 0.63 - ETA: 2s - loss: 5.8402 - accuracy: 0.63 - ETA: 2s - loss: 5.8384 - accuracy: 0.63 - ETA: 2s - loss: 5.8390 - accuracy: 0.63 - ETA: 2s - loss: 5.8395 - accuracy: 0.63 - ETA: 2s - loss: 5.8420 - accuracy: 0.63 - ETA: 2s - loss: 5.8379 - accuracy: 0.63 - ETA: 2s - loss: 5.8338 - accuracy: 0.63 - ETA: 2s - loss: 5.8370 - accuracy: 0.63 - ETA: 2s - loss: 5.8385 - accuracy: 0.63 - ETA: 2s - loss: 5.8423 - accuracy: 0.63 - ETA: 2s - loss: 5.8432 - accuracy: 0.63 - ETA: 2s - loss: 5.8444 - accuracy: 0.63 - ETA: 2s - loss: 5.8457 - accuracy: 0.63 - ETA: 2s - loss: 5.8506 - accuracy: 0.63 - ETA: 2s - loss: 5.8527 - accuracy: 0.63 - ETA: 2s - loss: 5.8529 - accuracy: 0.63 - ETA: 1s - loss: 5.8548 - accuracy: 0.63 - ETA: 1s - loss: 5.8549 - accuracy: 0.63 - ETA: 1s - loss: 5.8576 - accuracy: 0.63 - ETA: 1s - loss: 5.8511 - accuracy: 0.63 - ETA: 1s - loss: 5.8382 - accuracy: 0.63 - ETA: 1s - loss: 5.8405 - accuracy: 0.63 - ETA: 1s - loss: 5.8406 - accuracy: 0.63 - ETA: 1s - loss: 5.8422 - accuracy: 0.63 - ETA: 1s - loss: 5.8430 - accuracy: 0.63 - ETA: 1s - loss: 5.8449 - accuracy: 0.63 - ETA: 1s - loss: 5.8449 - accuracy: 0.63 - ETA: 1s - loss: 5.8491 - accuracy: 0.63 - ETA: 1s - loss: 5.8507 - accuracy: 0.63 - ETA: 1s - loss: 5.8515 - accuracy: 0.63 - ETA: 1s - loss: 5.8549 - accuracy: 0.63 - ETA: 1s - loss: 5.8502 - accuracy: 0.63 - ETA: 1s - loss: 5.8514 - accuracy: 0.63 - ETA: 1s - loss: 5.8563 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - ETA: 0s - loss: 5.8571 - accuracy: 0.63 - ETA: 0s - loss: 5.8566 - accuracy: 0.63 - ETA: 0s - loss: 5.8554 - accuracy: 0.63 - ETA: 0s - loss: 5.8544 - accuracy: 0.63 - ETA: 0s - loss: 5.8523 - accuracy: 0.63 - ETA: 0s - loss: 5.8586 - accuracy: 0.63 - ETA: 0s - loss: 5.8631 - accuracy: 0.63 - ETA: 0s - loss: 5.8603 - accuracy: 0.63 - ETA: 0s - loss: 5.8602 - accuracy: 0.63 - ETA: 0s - loss: 5.8578 - accuracy: 0.63 - ETA: 0s - loss: 5.8571 - accuracy: 0.63 - ETA: 0s - loss: 5.8542 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - ETA: 0s - loss: 5.8547 - accuracy: 0.63 - ETA: 0s - loss: 5.8523 - accuracy: 0.63 - ETA: 0s - loss: 5.8549 - accuracy: 0.63 - 7s 93us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 5s - loss: 6.1249 - accuracy: 0.62 - ETA: 6s - loss: 5.6644 - accuracy: 0.64 - ETA: 5s - loss: 5.8831 - accuracy: 0.63 - ETA: 5s - loss: 5.8409 - accuracy: 0.63 - ETA: 5s - loss: 5.7565 - accuracy: 0.64 - ETA: 5s - loss: 5.7488 - accuracy: 0.64 - ETA: 5s - loss: 5.7139 - accuracy: 0.64 - ETA: 5s - loss: 5.7442 - accuracy: 0.64 - ETA: 5s - loss: 5.7721 - accuracy: 0.64 - ETA: 5s - loss: 5.7469 - accuracy: 0.64 - ETA: 5s - loss: 5.7068 - accuracy: 0.64 - ETA: 5s - loss: 5.7717 - accuracy: 0.64 - ETA: 5s - loss: 5.7804 - accuracy: 0.64 - ETA: 5s - loss: 5.7576 - accuracy: 0.64 - ETA: 5s - loss: 5.7812 - accuracy: 0.64 - ETA: 5s - loss: 5.7627 - accuracy: 0.64 - ETA: 5s - loss: 5.7720 - accuracy: 0.64 - ETA: 5s - loss: 5.7869 - accuracy: 0.64 - ETA: 5s - loss: 5.7938 - accuracy: 0.64 - ETA: 5s - loss: 5.7942 - accuracy: 0.64 - ETA: 4s - loss: 5.7973 - accuracy: 0.64 - ETA: 4s - loss: 5.7963 - accuracy: 0.64 - ETA: 4s - loss: 5.8061 - accuracy: 0.63 - ETA: 4s - loss: 5.7890 - accuracy: 0.64 - ETA: 4s - loss: 5.7928 - accuracy: 0.64 - ETA: 4s - loss: 5.8159 - accuracy: 0.63 - ETA: 4s - loss: 5.8173 - accuracy: 0.63 - ETA: 4s - loss: 5.8091 - accuracy: 0.63 - ETA: 4s - loss: 5.7980 - accuracy: 0.64 - ETA: 4s - loss: 5.7955 - accuracy: 0.64 - ETA: 4s - loss: 5.7940 - accuracy: 0.64 - ETA: 4s - loss: 5.7959 - accuracy: 0.64 - ETA: 4s - loss: 5.8183 - accuracy: 0.63 - ETA: 4s - loss: 5.8239 - accuracy: 0.63 - ETA: 4s - loss: 5.8300 - accuracy: 0.63 - ETA: 4s - loss: 5.8327 - accuracy: 0.63 - ETA: 3s - loss: 5.8555 - accuracy: 0.63 - ETA: 3s - loss: 5.8492 - accuracy: 0.63 - ETA: 3s - loss: 5.8315 - accuracy: 0.63 - ETA: 3s - loss: 5.8326 - accuracy: 0.63 - ETA: 3s - loss: 5.8300 - accuracy: 0.63 - ETA: 3s - loss: 5.8298 - accuracy: 0.63 - ETA: 3s - loss: 5.8309 - accuracy: 0.63 - ETA: 3s - loss: 5.8261 - accuracy: 0.63 - ETA: 3s - loss: 5.8188 - accuracy: 0.63 - ETA: 3s - loss: 5.8129 - accuracy: 0.63 - ETA: 3s - loss: 5.8101 - accuracy: 0.63 - ETA: 3s - loss: 5.8089 - accuracy: 0.63 - ETA: 3s - loss: 5.8140 - accuracy: 0.63 - ETA: 3s - loss: 5.8076 - accuracy: 0.63 - ETA: 3s - loss: 5.8106 - accuracy: 0.63 - ETA: 3s - loss: 5.8134 - accuracy: 0.63 - ETA: 3s - loss: 5.8108 - accuracy: 0.63 - ETA: 3s - loss: 5.8121 - accuracy: 0.63 - ETA: 3s - loss: 5.8063 - accuracy: 0.63 - ETA: 2s - loss: 5.8057 - accuracy: 0.63 - ETA: 2s - loss: 5.7985 - accuracy: 0.64 - ETA: 2s - loss: 5.7972 - accuracy: 0.64 - ETA: 2s - loss: 5.7947 - accuracy: 0.64 - ETA: 2s - loss: 5.8021 - accuracy: 0.64 - ETA: 2s - loss: 5.8042 - accuracy: 0.63 - ETA: 2s - loss: 5.8103 - accuracy: 0.63 - ETA: 2s - loss: 5.8123 - accuracy: 0.63 - ETA: 2s - loss: 5.8169 - accuracy: 0.63 - ETA: 2s - loss: 5.8174 - accuracy: 0.63 - ETA: 2s - loss: 5.8156 - accuracy: 0.63 - ETA: 2s - loss: 5.8272 - accuracy: 0.63 - ETA: 2s - loss: 5.8223 - accuracy: 0.63 - ETA: 2s - loss: 5.8206 - accuracy: 0.63 - ETA: 2s - loss: 5.8175 - accuracy: 0.63 - ETA: 2s - loss: 5.8173 - accuracy: 0.63 - ETA: 2s - loss: 5.8224 - accuracy: 0.63 - ETA: 2s - loss: 5.8256 - accuracy: 0.63 - ETA: 1s - loss: 5.8271 - accuracy: 0.63 - ETA: 1s - loss: 5.8274 - accuracy: 0.63 - ETA: 1s - loss: 5.8267 - accuracy: 0.63 - ETA: 1s - loss: 5.8318 - accuracy: 0.63 - ETA: 1s - loss: 5.8307 - accuracy: 0.63 - ETA: 1s - loss: 5.8375 - accuracy: 0.63 - ETA: 1s - loss: 5.8364 - accuracy: 0.63 - ETA: 1s - loss: 5.8389 - accuracy: 0.63 - ETA: 1s - loss: 5.8394 - accuracy: 0.63 - ETA: 1s - loss: 5.8381 - accuracy: 0.63 - ETA: 1s - loss: 5.8372 - accuracy: 0.63 - ETA: 1s - loss: 5.8341 - accuracy: 0.63 - ETA: 1s - loss: 5.8361 - accuracy: 0.63 - ETA: 1s - loss: 5.8377 - accuracy: 0.63 - ETA: 1s - loss: 5.8441 - accuracy: 0.63 - ETA: 1s - loss: 5.8417 - accuracy: 0.63 - ETA: 1s - loss: 5.8445 - accuracy: 0.63 - ETA: 1s - loss: 5.8462 - accuracy: 0.63 - ETA: 1s - loss: 5.8497 - accuracy: 0.63 - ETA: 1s - loss: 5.8514 - accuracy: 0.63 - ETA: 1s - loss: 5.8501 - accuracy: 0.63 - ETA: 0s - loss: 5.8525 - accuracy: 0.63 - ETA: 0s - loss: 5.8539 - accuracy: 0.63 - ETA: 0s - loss: 5.8540 - accuracy: 0.63 - ETA: 0s - loss: 5.8567 - accuracy: 0.63 - ETA: 0s - loss: 5.8516 - accuracy: 0.63 - ETA: 0s - loss: 5.8552 - accuracy: 0.63 - ETA: 0s - loss: 5.8578 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - ETA: 0s - loss: 5.8587 - accuracy: 0.63 - ETA: 0s - loss: 5.8567 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - ETA: 0s - loss: 5.8513 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - ETA: 0s - loss: 5.8566 - accuracy: 0.63 - ETA: 0s - loss: 5.8533 - accuracy: 0.63 - ETA: 0s - loss: 5.8545 - accuracy: 0.63 - ETA: 0s - loss: 5.8537 - accuracy: 0.63 - ETA: 0s - loss: 5.8570 - accuracy: 0.63 - ETA: 0s - loss: 5.8560 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - 6s 89us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 45/50\n",
      "70000/70000 [==============================] - ETA: 10s - loss: 5.8025 - accuracy: 0.640 - ETA: 5s - loss: 5.6413 - accuracy: 0.650 - ETA: 6s - loss: 5.7653 - accuracy: 0.64 - ETA: 6s - loss: 5.7130 - accuracy: 0.64 - ETA: 6s - loss: 5.8092 - accuracy: 0.63 - ETA: 6s - loss: 5.8773 - accuracy: 0.63 - ETA: 6s - loss: 5.7683 - accuracy: 0.64 - ETA: 6s - loss: 5.8356 - accuracy: 0.63 - ETA: 6s - loss: 5.8312 - accuracy: 0.63 - ETA: 6s - loss: 5.8366 - accuracy: 0.63 - ETA: 6s - loss: 5.8336 - accuracy: 0.63 - ETA: 5s - loss: 5.8639 - accuracy: 0.63 - ETA: 5s - loss: 5.8463 - accuracy: 0.63 - ETA: 5s - loss: 5.8369 - accuracy: 0.63 - ETA: 6s - loss: 5.8862 - accuracy: 0.63 - ETA: 6s - loss: 5.8472 - accuracy: 0.63 - ETA: 6s - loss: 5.8688 - accuracy: 0.63 - ETA: 5s - loss: 5.8723 - accuracy: 0.63 - ETA: 5s - loss: 5.8986 - accuracy: 0.63 - ETA: 5s - loss: 5.9065 - accuracy: 0.63 - ETA: 5s - loss: 5.9234 - accuracy: 0.63 - ETA: 5s - loss: 5.9188 - accuracy: 0.63 - ETA: 5s - loss: 5.9196 - accuracy: 0.63 - ETA: 5s - loss: 5.9286 - accuracy: 0.63 - ETA: 5s - loss: 5.9508 - accuracy: 0.63 - ETA: 5s - loss: 5.9389 - accuracy: 0.63 - ETA: 5s - loss: 5.9388 - accuracy: 0.63 - ETA: 5s - loss: 5.9461 - accuracy: 0.63 - ETA: 5s - loss: 5.9419 - accuracy: 0.63 - ETA: 4s - loss: 5.9315 - accuracy: 0.63 - ETA: 4s - loss: 5.9437 - accuracy: 0.63 - ETA: 4s - loss: 5.9400 - accuracy: 0.63 - ETA: 4s - loss: 5.9159 - accuracy: 0.63 - ETA: 4s - loss: 5.9169 - accuracy: 0.63 - ETA: 4s - loss: 5.9261 - accuracy: 0.63 - ETA: 4s - loss: 5.9244 - accuracy: 0.63 - ETA: 4s - loss: 5.9173 - accuracy: 0.63 - ETA: 4s - loss: 5.9199 - accuracy: 0.63 - ETA: 4s - loss: 5.9115 - accuracy: 0.63 - ETA: 4s - loss: 5.9158 - accuracy: 0.63 - ETA: 4s - loss: 5.9149 - accuracy: 0.63 - ETA: 4s - loss: 5.9010 - accuracy: 0.63 - ETA: 4s - loss: 5.9026 - accuracy: 0.63 - ETA: 4s - loss: 5.9172 - accuracy: 0.63 - ETA: 4s - loss: 5.9036 - accuracy: 0.63 - ETA: 4s - loss: 5.8925 - accuracy: 0.63 - ETA: 4s - loss: 5.8957 - accuracy: 0.63 - ETA: 4s - loss: 5.8969 - accuracy: 0.63 - ETA: 4s - loss: 5.8958 - accuracy: 0.63 - ETA: 4s - loss: 5.8941 - accuracy: 0.63 - ETA: 3s - loss: 5.8740 - accuracy: 0.63 - ETA: 3s - loss: 5.8748 - accuracy: 0.63 - ETA: 3s - loss: 5.8752 - accuracy: 0.63 - ETA: 3s - loss: 5.8799 - accuracy: 0.63 - ETA: 3s - loss: 5.8795 - accuracy: 0.63 - ETA: 3s - loss: 5.8879 - accuracy: 0.63 - ETA: 3s - loss: 5.8896 - accuracy: 0.63 - ETA: 3s - loss: 5.8916 - accuracy: 0.63 - ETA: 3s - loss: 5.8881 - accuracy: 0.63 - ETA: 3s - loss: 5.8937 - accuracy: 0.63 - ETA: 3s - loss: 5.8958 - accuracy: 0.63 - ETA: 3s - loss: 5.8915 - accuracy: 0.63 - ETA: 3s - loss: 5.8956 - accuracy: 0.63 - ETA: 3s - loss: 5.9011 - accuracy: 0.63 - ETA: 2s - loss: 5.8960 - accuracy: 0.63 - ETA: 2s - loss: 5.8960 - accuracy: 0.63 - ETA: 2s - loss: 5.8860 - accuracy: 0.63 - ETA: 2s - loss: 5.8784 - accuracy: 0.63 - ETA: 2s - loss: 5.8799 - accuracy: 0.63 - ETA: 2s - loss: 5.8746 - accuracy: 0.63 - ETA: 2s - loss: 5.8714 - accuracy: 0.63 - ETA: 2s - loss: 5.8733 - accuracy: 0.63 - ETA: 2s - loss: 5.8740 - accuracy: 0.63 - ETA: 2s - loss: 5.8686 - accuracy: 0.63 - ETA: 2s - loss: 5.8723 - accuracy: 0.63 - ETA: 2s - loss: 5.8702 - accuracy: 0.63 - ETA: 2s - loss: 5.8813 - accuracy: 0.63 - ETA: 2s - loss: 5.8787 - accuracy: 0.63 - ETA: 2s - loss: 5.8796 - accuracy: 0.63 - ETA: 2s - loss: 5.8740 - accuracy: 0.63 - ETA: 2s - loss: 5.8746 - accuracy: 0.63 - ETA: 2s - loss: 5.8683 - accuracy: 0.63 - ETA: 2s - loss: 5.8725 - accuracy: 0.63 - ETA: 1s - loss: 5.8721 - accuracy: 0.63 - ETA: 1s - loss: 5.8701 - accuracy: 0.63 - ETA: 1s - loss: 5.8663 - accuracy: 0.63 - ETA: 1s - loss: 5.8650 - accuracy: 0.63 - ETA: 1s - loss: 5.8635 - accuracy: 0.63 - ETA: 1s - loss: 5.8616 - accuracy: 0.63 - ETA: 1s - loss: 5.8586 - accuracy: 0.63 - ETA: 1s - loss: 5.8584 - accuracy: 0.63 - ETA: 1s - loss: 5.8558 - accuracy: 0.63 - ETA: 1s - loss: 5.8566 - accuracy: 0.63 - ETA: 1s - loss: 5.8607 - accuracy: 0.63 - ETA: 1s - loss: 5.8650 - accuracy: 0.63 - ETA: 1s - loss: 5.8629 - accuracy: 0.63 - ETA: 1s - loss: 5.8588 - accuracy: 0.63 - ETA: 1s - loss: 5.8649 - accuracy: 0.63 - ETA: 1s - loss: 5.8626 - accuracy: 0.63 - ETA: 1s - loss: 5.8570 - accuracy: 0.63 - ETA: 1s - loss: 5.8611 - accuracy: 0.63 - ETA: 0s - loss: 5.8630 - accuracy: 0.63 - ETA: 0s - loss: 5.8675 - accuracy: 0.63 - ETA: 0s - loss: 5.8722 - accuracy: 0.63 - ETA: 0s - loss: 5.8748 - accuracy: 0.63 - ETA: 0s - loss: 5.8738 - accuracy: 0.63 - ETA: 0s - loss: 5.8727 - accuracy: 0.63 - ETA: 0s - loss: 5.8729 - accuracy: 0.63 - ETA: 0s - loss: 5.8697 - accuracy: 0.63 - ETA: 0s - loss: 5.8677 - accuracy: 0.63 - ETA: 0s - loss: 5.8646 - accuracy: 0.63 - ETA: 0s - loss: 5.8618 - accuracy: 0.63 - ETA: 0s - loss: 5.8652 - accuracy: 0.63 - ETA: 0s - loss: 5.8682 - accuracy: 0.63 - ETA: 0s - loss: 5.8667 - accuracy: 0.63 - ETA: 0s - loss: 5.8637 - accuracy: 0.63 - ETA: 0s - loss: 5.8623 - accuracy: 0.63 - ETA: 0s - loss: 5.8609 - accuracy: 0.63 - ETA: 0s - loss: 5.8592 - accuracy: 0.63 - ETA: 0s - loss: 5.8583 - accuracy: 0.63 - 6s 91us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 9s - loss: 7.0920 - accuracy: 0.56 - ETA: 4s - loss: 6.3219 - accuracy: 0.60 - ETA: 5s - loss: 6.1350 - accuracy: 0.61 - ETA: 5s - loss: 6.2201 - accuracy: 0.61 - ETA: 5s - loss: 6.1607 - accuracy: 0.61 - ETA: 5s - loss: 6.1395 - accuracy: 0.61 - ETA: 5s - loss: 6.0282 - accuracy: 0.62 - ETA: 5s - loss: 6.0014 - accuracy: 0.62 - ETA: 5s - loss: 5.9971 - accuracy: 0.62 - ETA: 6s - loss: 6.0473 - accuracy: 0.62 - ETA: 5s - loss: 6.0641 - accuracy: 0.62 - ETA: 5s - loss: 6.0609 - accuracy: 0.62 - ETA: 5s - loss: 6.0761 - accuracy: 0.62 - ETA: 5s - loss: 6.0759 - accuracy: 0.62 - ETA: 5s - loss: 6.0813 - accuracy: 0.62 - ETA: 5s - loss: 6.1039 - accuracy: 0.62 - ETA: 5s - loss: 6.1331 - accuracy: 0.61 - ETA: 5s - loss: 6.0970 - accuracy: 0.62 - ETA: 5s - loss: 6.0682 - accuracy: 0.62 - ETA: 5s - loss: 6.0739 - accuracy: 0.62 - ETA: 5s - loss: 6.0755 - accuracy: 0.62 - ETA: 4s - loss: 6.0468 - accuracy: 0.62 - ETA: 4s - loss: 6.0449 - accuracy: 0.62 - ETA: 4s - loss: 6.0291 - accuracy: 0.62 - ETA: 4s - loss: 6.0318 - accuracy: 0.62 - ETA: 4s - loss: 5.9978 - accuracy: 0.62 - ETA: 4s - loss: 5.9816 - accuracy: 0.62 - ETA: 4s - loss: 5.9695 - accuracy: 0.62 - ETA: 4s - loss: 5.9599 - accuracy: 0.63 - ETA: 4s - loss: 5.9402 - accuracy: 0.63 - ETA: 4s - loss: 5.9498 - accuracy: 0.63 - ETA: 4s - loss: 5.9375 - accuracy: 0.63 - ETA: 4s - loss: 5.9344 - accuracy: 0.63 - ETA: 4s - loss: 5.9188 - accuracy: 0.63 - ETA: 4s - loss: 5.9157 - accuracy: 0.63 - ETA: 4s - loss: 5.9236 - accuracy: 0.63 - ETA: 4s - loss: 5.9159 - accuracy: 0.63 - ETA: 4s - loss: 5.9126 - accuracy: 0.63 - ETA: 4s - loss: 5.9104 - accuracy: 0.63 - ETA: 4s - loss: 5.9063 - accuracy: 0.63 - ETA: 4s - loss: 5.9030 - accuracy: 0.63 - ETA: 4s - loss: 5.8957 - accuracy: 0.63 - ETA: 4s - loss: 5.9012 - accuracy: 0.63 - ETA: 4s - loss: 5.8903 - accuracy: 0.63 - ETA: 3s - loss: 5.8932 - accuracy: 0.63 - ETA: 3s - loss: 5.8918 - accuracy: 0.63 - ETA: 3s - loss: 5.8822 - accuracy: 0.63 - ETA: 3s - loss: 5.8831 - accuracy: 0.63 - ETA: 3s - loss: 5.8825 - accuracy: 0.63 - ETA: 3s - loss: 5.8792 - accuracy: 0.63 - ETA: 3s - loss: 5.8820 - accuracy: 0.63 - ETA: 3s - loss: 5.8685 - accuracy: 0.63 - ETA: 3s - loss: 5.8732 - accuracy: 0.63 - ETA: 3s - loss: 5.8821 - accuracy: 0.63 - ETA: 3s - loss: 5.8831 - accuracy: 0.63 - ETA: 3s - loss: 5.8814 - accuracy: 0.63 - ETA: 3s - loss: 5.8795 - accuracy: 0.63 - ETA: 3s - loss: 5.8838 - accuracy: 0.63 - ETA: 3s - loss: 5.8831 - accuracy: 0.63 - ETA: 2s - loss: 5.8860 - accuracy: 0.63 - ETA: 2s - loss: 5.8875 - accuracy: 0.63 - ETA: 2s - loss: 5.8829 - accuracy: 0.63 - ETA: 2s - loss: 5.8844 - accuracy: 0.63 - ETA: 2s - loss: 5.8883 - accuracy: 0.63 - ETA: 2s - loss: 5.8886 - accuracy: 0.63 - ETA: 2s - loss: 5.8903 - accuracy: 0.63 - ETA: 2s - loss: 5.8877 - accuracy: 0.63 - ETA: 2s - loss: 5.8868 - accuracy: 0.63 - ETA: 2s - loss: 5.8790 - accuracy: 0.63 - ETA: 2s - loss: 5.8785 - accuracy: 0.63 - ETA: 2s - loss: 5.8779 - accuracy: 0.63 - ETA: 2s - loss: 5.8785 - accuracy: 0.63 - ETA: 2s - loss: 5.8774 - accuracy: 0.63 - ETA: 2s - loss: 5.8720 - accuracy: 0.63 - ETA: 2s - loss: 5.8684 - accuracy: 0.63 - ETA: 2s - loss: 5.8682 - accuracy: 0.63 - ETA: 2s - loss: 5.8697 - accuracy: 0.63 - ETA: 1s - loss: 5.8675 - accuracy: 0.63 - ETA: 1s - loss: 5.8694 - accuracy: 0.63 - ETA: 1s - loss: 5.8671 - accuracy: 0.63 - ETA: 1s - loss: 5.8670 - accuracy: 0.63 - ETA: 1s - loss: 5.8644 - accuracy: 0.63 - ETA: 1s - loss: 5.8692 - accuracy: 0.63 - ETA: 1s - loss: 5.8692 - accuracy: 0.63 - ETA: 1s - loss: 5.8680 - accuracy: 0.63 - ETA: 1s - loss: 5.8656 - accuracy: 0.63 - ETA: 1s - loss: 5.8685 - accuracy: 0.63 - ETA: 1s - loss: 5.8643 - accuracy: 0.63 - ETA: 1s - loss: 5.8657 - accuracy: 0.63 - ETA: 1s - loss: 5.8681 - accuracy: 0.63 - ETA: 1s - loss: 5.8664 - accuracy: 0.63 - ETA: 1s - loss: 5.8720 - accuracy: 0.63 - ETA: 1s - loss: 5.8649 - accuracy: 0.63 - ETA: 1s - loss: 5.8604 - accuracy: 0.63 - ETA: 1s - loss: 5.8695 - accuracy: 0.63 - ETA: 1s - loss: 5.8681 - accuracy: 0.63 - ETA: 0s - loss: 5.8694 - accuracy: 0.63 - ETA: 0s - loss: 5.8707 - accuracy: 0.63 - ETA: 0s - loss: 5.8710 - accuracy: 0.63 - ETA: 0s - loss: 5.8710 - accuracy: 0.63 - ETA: 0s - loss: 5.8716 - accuracy: 0.63 - ETA: 0s - loss: 5.8682 - accuracy: 0.63 - ETA: 0s - loss: 5.8724 - accuracy: 0.63 - ETA: 0s - loss: 5.8642 - accuracy: 0.63 - ETA: 0s - loss: 5.8674 - accuracy: 0.63 - ETA: 0s - loss: 5.8723 - accuracy: 0.63 - ETA: 0s - loss: 5.8707 - accuracy: 0.63 - ETA: 0s - loss: 5.8674 - accuracy: 0.63 - ETA: 0s - loss: 5.8660 - accuracy: 0.63 - ETA: 0s - loss: 5.8633 - accuracy: 0.63 - ETA: 0s - loss: 5.8616 - accuracy: 0.63 - ETA: 0s - loss: 5.8655 - accuracy: 0.63 - ETA: 0s - loss: 5.8616 - accuracy: 0.63 - ETA: 0s - loss: 5.8575 - accuracy: 0.63 - 6s 87us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 47/50\n",
      "70000/70000 [==============================] - ETA: 9s - loss: 7.5755 - accuracy: 0.53 - ETA: 7s - loss: 6.1786 - accuracy: 0.61 - ETA: 7s - loss: 6.3300 - accuracy: 0.60 - ETA: 7s - loss: 6.2387 - accuracy: 0.61 - ETA: 6s - loss: 6.1739 - accuracy: 0.61 - ETA: 6s - loss: 6.0213 - accuracy: 0.62 - ETA: 6s - loss: 5.8992 - accuracy: 0.63 - ETA: 6s - loss: 5.8851 - accuracy: 0.63 - ETA: 5s - loss: 5.9066 - accuracy: 0.63 - ETA: 5s - loss: 5.8592 - accuracy: 0.63 - ETA: 5s - loss: 5.8670 - accuracy: 0.63 - ETA: 5s - loss: 5.8943 - accuracy: 0.63 - ETA: 5s - loss: 5.8992 - accuracy: 0.63 - ETA: 6s - loss: 5.8921 - accuracy: 0.63 - ETA: 6s - loss: 5.8810 - accuracy: 0.63 - ETA: 6s - loss: 5.8637 - accuracy: 0.63 - ETA: 6s - loss: 5.8381 - accuracy: 0.63 - ETA: 6s - loss: 5.8632 - accuracy: 0.63 - ETA: 5s - loss: 5.8328 - accuracy: 0.63 - ETA: 5s - loss: 5.8402 - accuracy: 0.63 - ETA: 5s - loss: 5.7996 - accuracy: 0.64 - ETA: 5s - loss: 5.7998 - accuracy: 0.64 - ETA: 5s - loss: 5.8117 - accuracy: 0.63 - ETA: 5s - loss: 5.8365 - accuracy: 0.63 - ETA: 5s - loss: 5.8264 - accuracy: 0.63 - ETA: 5s - loss: 5.8431 - accuracy: 0.63 - ETA: 5s - loss: 5.8466 - accuracy: 0.63 - ETA: 5s - loss: 5.8580 - accuracy: 0.63 - ETA: 4s - loss: 5.8250 - accuracy: 0.63 - ETA: 4s - loss: 5.8241 - accuracy: 0.63 - ETA: 4s - loss: 5.8133 - accuracy: 0.63 - ETA: 4s - loss: 5.8276 - accuracy: 0.63 - ETA: 4s - loss: 5.8468 - accuracy: 0.63 - ETA: 4s - loss: 5.8541 - accuracy: 0.63 - ETA: 4s - loss: 5.8542 - accuracy: 0.63 - ETA: 4s - loss: 5.8438 - accuracy: 0.63 - ETA: 4s - loss: 5.8370 - accuracy: 0.63 - ETA: 4s - loss: 5.8251 - accuracy: 0.63 - ETA: 4s - loss: 5.8268 - accuracy: 0.63 - ETA: 4s - loss: 5.8281 - accuracy: 0.63 - ETA: 4s - loss: 5.8348 - accuracy: 0.63 - ETA: 4s - loss: 5.8293 - accuracy: 0.63 - ETA: 3s - loss: 5.8292 - accuracy: 0.63 - ETA: 3s - loss: 5.8431 - accuracy: 0.63 - ETA: 3s - loss: 5.8348 - accuracy: 0.63 - ETA: 3s - loss: 5.8367 - accuracy: 0.63 - ETA: 3s - loss: 5.8398 - accuracy: 0.63 - ETA: 3s - loss: 5.8406 - accuracy: 0.63 - ETA: 3s - loss: 5.8355 - accuracy: 0.63 - ETA: 3s - loss: 5.8400 - accuracy: 0.63 - ETA: 3s - loss: 5.8356 - accuracy: 0.63 - ETA: 3s - loss: 5.8273 - accuracy: 0.63 - ETA: 3s - loss: 5.8322 - accuracy: 0.63 - ETA: 3s - loss: 5.8409 - accuracy: 0.63 - ETA: 3s - loss: 5.8348 - accuracy: 0.63 - ETA: 3s - loss: 5.8380 - accuracy: 0.63 - ETA: 3s - loss: 5.8430 - accuracy: 0.63 - ETA: 2s - loss: 5.8532 - accuracy: 0.63 - ETA: 2s - loss: 5.8485 - accuracy: 0.63 - ETA: 2s - loss: 5.8471 - accuracy: 0.63 - ETA: 2s - loss: 5.8461 - accuracy: 0.63 - ETA: 2s - loss: 5.8475 - accuracy: 0.63 - ETA: 2s - loss: 5.8501 - accuracy: 0.63 - ETA: 2s - loss: 5.8486 - accuracy: 0.63 - ETA: 2s - loss: 5.8527 - accuracy: 0.63 - ETA: 2s - loss: 5.8533 - accuracy: 0.63 - ETA: 2s - loss: 5.8586 - accuracy: 0.63 - ETA: 2s - loss: 5.8459 - accuracy: 0.63 - ETA: 2s - loss: 5.8472 - accuracy: 0.63 - ETA: 2s - loss: 5.8519 - accuracy: 0.63 - ETA: 2s - loss: 5.8527 - accuracy: 0.63 - ETA: 2s - loss: 5.8571 - accuracy: 0.63 - ETA: 2s - loss: 5.8520 - accuracy: 0.63 - ETA: 2s - loss: 5.8491 - accuracy: 0.63 - ETA: 2s - loss: 5.8564 - accuracy: 0.63 - ETA: 2s - loss: 5.8611 - accuracy: 0.63 - ETA: 2s - loss: 5.8589 - accuracy: 0.63 - ETA: 1s - loss: 5.8621 - accuracy: 0.63 - ETA: 1s - loss: 5.8616 - accuracy: 0.63 - ETA: 1s - loss: 5.8657 - accuracy: 0.63 - ETA: 1s - loss: 5.8671 - accuracy: 0.63 - ETA: 1s - loss: 5.8620 - accuracy: 0.63 - ETA: 1s - loss: 5.8620 - accuracy: 0.63 - ETA: 1s - loss: 5.8625 - accuracy: 0.63 - ETA: 1s - loss: 5.8648 - accuracy: 0.63 - ETA: 1s - loss: 5.8688 - accuracy: 0.63 - ETA: 1s - loss: 5.8651 - accuracy: 0.63 - ETA: 1s - loss: 5.8620 - accuracy: 0.63 - ETA: 1s - loss: 5.8612 - accuracy: 0.63 - ETA: 1s - loss: 5.8595 - accuracy: 0.63 - ETA: 1s - loss: 5.8653 - accuracy: 0.63 - ETA: 1s - loss: 5.8678 - accuracy: 0.63 - ETA: 0s - loss: 5.8648 - accuracy: 0.63 - ETA: 0s - loss: 5.8690 - accuracy: 0.63 - ETA: 0s - loss: 5.8688 - accuracy: 0.63 - ETA: 0s - loss: 5.8675 - accuracy: 0.63 - ETA: 0s - loss: 5.8699 - accuracy: 0.63 - ETA: 0s - loss: 5.8733 - accuracy: 0.63 - ETA: 0s - loss: 5.8752 - accuracy: 0.63 - ETA: 0s - loss: 5.8799 - accuracy: 0.63 - ETA: 0s - loss: 5.8747 - accuracy: 0.63 - ETA: 0s - loss: 5.8753 - accuracy: 0.63 - ETA: 0s - loss: 5.8732 - accuracy: 0.63 - ETA: 0s - loss: 5.8722 - accuracy: 0.63 - ETA: 0s - loss: 5.8728 - accuracy: 0.63 - ETA: 0s - loss: 5.8695 - accuracy: 0.63 - ETA: 0s - loss: 5.8647 - accuracy: 0.63 - ETA: 0s - loss: 5.8613 - accuracy: 0.63 - ETA: 0s - loss: 5.8592 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - ETA: 0s - loss: 5.8579 - accuracy: 0.63 - 6s 84us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 5s - loss: 6.4472 - accuracy: 0.60 - ETA: 5s - loss: 6.4703 - accuracy: 0.59 - ETA: 5s - loss: 6.3357 - accuracy: 0.60 - ETA: 5s - loss: 6.1571 - accuracy: 0.61 - ETA: 5s - loss: 6.1893 - accuracy: 0.61 - ETA: 6s - loss: 6.1638 - accuracy: 0.61 - ETA: 6s - loss: 6.0742 - accuracy: 0.62 - ETA: 5s - loss: 6.0404 - accuracy: 0.62 - ETA: 5s - loss: 5.9801 - accuracy: 0.62 - ETA: 6s - loss: 5.9761 - accuracy: 0.62 - ETA: 6s - loss: 5.9493 - accuracy: 0.63 - ETA: 6s - loss: 5.9279 - accuracy: 0.63 - ETA: 5s - loss: 5.9427 - accuracy: 0.63 - ETA: 5s - loss: 5.8992 - accuracy: 0.63 - ETA: 5s - loss: 5.9047 - accuracy: 0.63 - ETA: 5s - loss: 5.9039 - accuracy: 0.63 - ETA: 5s - loss: 5.9281 - accuracy: 0.63 - ETA: 5s - loss: 5.9334 - accuracy: 0.63 - ETA: 5s - loss: 5.9189 - accuracy: 0.63 - ETA: 5s - loss: 5.9109 - accuracy: 0.63 - ETA: 5s - loss: 5.8973 - accuracy: 0.63 - ETA: 5s - loss: 5.8882 - accuracy: 0.63 - ETA: 5s - loss: 5.8825 - accuracy: 0.63 - ETA: 5s - loss: 5.8837 - accuracy: 0.63 - ETA: 4s - loss: 5.8809 - accuracy: 0.63 - ETA: 5s - loss: 5.8906 - accuracy: 0.63 - ETA: 4s - loss: 5.8908 - accuracy: 0.63 - ETA: 4s - loss: 5.9031 - accuracy: 0.63 - ETA: 4s - loss: 5.9018 - accuracy: 0.63 - ETA: 4s - loss: 5.9016 - accuracy: 0.63 - ETA: 4s - loss: 5.9094 - accuracy: 0.63 - ETA: 4s - loss: 5.9153 - accuracy: 0.63 - ETA: 4s - loss: 5.9037 - accuracy: 0.63 - ETA: 4s - loss: 5.9041 - accuracy: 0.63 - ETA: 4s - loss: 5.8995 - accuracy: 0.63 - ETA: 4s - loss: 5.8729 - accuracy: 0.63 - ETA: 4s - loss: 5.8812 - accuracy: 0.63 - ETA: 4s - loss: 5.8712 - accuracy: 0.63 - ETA: 4s - loss: 5.8729 - accuracy: 0.63 - ETA: 4s - loss: 5.8817 - accuracy: 0.63 - ETA: 4s - loss: 5.8671 - accuracy: 0.63 - ETA: 4s - loss: 5.8601 - accuracy: 0.63 - ETA: 3s - loss: 5.8604 - accuracy: 0.63 - ETA: 3s - loss: 5.8626 - accuracy: 0.63 - ETA: 3s - loss: 5.8592 - accuracy: 0.63 - ETA: 3s - loss: 5.8562 - accuracy: 0.63 - ETA: 3s - loss: 5.8501 - accuracy: 0.63 - ETA: 3s - loss: 5.8589 - accuracy: 0.63 - ETA: 3s - loss: 5.8550 - accuracy: 0.63 - ETA: 3s - loss: 5.8586 - accuracy: 0.63 - ETA: 3s - loss: 5.8633 - accuracy: 0.63 - ETA: 3s - loss: 5.8668 - accuracy: 0.63 - ETA: 3s - loss: 5.8640 - accuracy: 0.63 - ETA: 3s - loss: 5.8617 - accuracy: 0.63 - ETA: 3s - loss: 5.8572 - accuracy: 0.63 - ETA: 3s - loss: 5.8566 - accuracy: 0.63 - ETA: 3s - loss: 5.8537 - accuracy: 0.63 - ETA: 3s - loss: 5.8549 - accuracy: 0.63 - ETA: 3s - loss: 5.8520 - accuracy: 0.63 - ETA: 3s - loss: 5.8493 - accuracy: 0.63 - ETA: 2s - loss: 5.8450 - accuracy: 0.63 - ETA: 2s - loss: 5.8387 - accuracy: 0.63 - ETA: 2s - loss: 5.8333 - accuracy: 0.63 - ETA: 2s - loss: 5.8407 - accuracy: 0.63 - ETA: 2s - loss: 5.8390 - accuracy: 0.63 - ETA: 2s - loss: 5.8402 - accuracy: 0.63 - ETA: 2s - loss: 5.8412 - accuracy: 0.63 - ETA: 2s - loss: 5.8508 - accuracy: 0.63 - ETA: 2s - loss: 5.8526 - accuracy: 0.63 - ETA: 2s - loss: 5.8468 - accuracy: 0.63 - ETA: 2s - loss: 5.8476 - accuracy: 0.63 - ETA: 2s - loss: 5.8458 - accuracy: 0.63 - ETA: 2s - loss: 5.8458 - accuracy: 0.63 - ETA: 2s - loss: 5.8488 - accuracy: 0.63 - ETA: 2s - loss: 5.8475 - accuracy: 0.63 - ETA: 2s - loss: 5.8525 - accuracy: 0.63 - ETA: 2s - loss: 5.8546 - accuracy: 0.63 - ETA: 1s - loss: 5.8562 - accuracy: 0.63 - ETA: 1s - loss: 5.8635 - accuracy: 0.63 - ETA: 1s - loss: 5.8633 - accuracy: 0.63 - ETA: 1s - loss: 5.8641 - accuracy: 0.63 - ETA: 1s - loss: 5.8606 - accuracy: 0.63 - ETA: 1s - loss: 5.8586 - accuracy: 0.63 - ETA: 1s - loss: 5.8583 - accuracy: 0.63 - ETA: 1s - loss: 5.8556 - accuracy: 0.63 - ETA: 1s - loss: 5.8536 - accuracy: 0.63 - ETA: 1s - loss: 5.8595 - accuracy: 0.63 - ETA: 1s - loss: 5.8574 - accuracy: 0.63 - ETA: 1s - loss: 5.8573 - accuracy: 0.63 - ETA: 1s - loss: 5.8552 - accuracy: 0.63 - ETA: 1s - loss: 5.8571 - accuracy: 0.63 - ETA: 1s - loss: 5.8559 - accuracy: 0.63 - ETA: 1s - loss: 5.8545 - accuracy: 0.63 - ETA: 1s - loss: 5.8541 - accuracy: 0.63 - ETA: 0s - loss: 5.8557 - accuracy: 0.63 - ETA: 0s - loss: 5.8577 - accuracy: 0.63 - ETA: 0s - loss: 5.8597 - accuracy: 0.63 - ETA: 0s - loss: 5.8562 - accuracy: 0.63 - ETA: 0s - loss: 5.8615 - accuracy: 0.63 - ETA: 0s - loss: 5.8605 - accuracy: 0.63 - ETA: 0s - loss: 5.8592 - accuracy: 0.63 - ETA: 0s - loss: 5.8614 - accuracy: 0.63 - ETA: 0s - loss: 5.8637 - accuracy: 0.63 - ETA: 0s - loss: 5.8673 - accuracy: 0.63 - ETA: 0s - loss: 5.8667 - accuracy: 0.63 - ETA: 0s - loss: 5.8651 - accuracy: 0.63 - ETA: 0s - loss: 5.8621 - accuracy: 0.63 - ETA: 0s - loss: 5.8636 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - ETA: 0s - loss: 5.8559 - accuracy: 0.63 - ETA: 0s - loss: 5.8558 - accuracy: 0.63 - 6s 85us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 49/50\n",
      "70000/70000 [==============================] - ETA: 10s - loss: 6.1249 - accuracy: 0.620 - ETA: 5s - loss: 5.7219 - accuracy: 0.645 - ETA: 5s - loss: 5.8601 - accuracy: 0.63 - ETA: 6s - loss: 5.8294 - accuracy: 0.63 - ETA: 5s - loss: 5.8412 - accuracy: 0.63 - ETA: 5s - loss: 5.8126 - accuracy: 0.63 - ETA: 5s - loss: 5.8852 - accuracy: 0.63 - ETA: 5s - loss: 5.9462 - accuracy: 0.63 - ETA: 5s - loss: 5.9394 - accuracy: 0.63 - ETA: 5s - loss: 5.9261 - accuracy: 0.63 - ETA: 4s - loss: 5.9471 - accuracy: 0.63 - ETA: 4s - loss: 5.9551 - accuracy: 0.63 - ETA: 4s - loss: 5.9677 - accuracy: 0.62 - ETA: 5s - loss: 5.9734 - accuracy: 0.62 - ETA: 5s - loss: 5.9765 - accuracy: 0.62 - ETA: 5s - loss: 5.9690 - accuracy: 0.62 - ETA: 5s - loss: 5.9706 - accuracy: 0.62 - ETA: 5s - loss: 5.9414 - accuracy: 0.63 - ETA: 5s - loss: 5.9456 - accuracy: 0.63 - ETA: 5s - loss: 5.9425 - accuracy: 0.63 - ETA: 5s - loss: 5.9301 - accuracy: 0.63 - ETA: 5s - loss: 5.9234 - accuracy: 0.63 - ETA: 5s - loss: 5.9100 - accuracy: 0.63 - ETA: 5s - loss: 5.9312 - accuracy: 0.63 - ETA: 5s - loss: 5.9196 - accuracy: 0.63 - ETA: 5s - loss: 5.8921 - accuracy: 0.63 - ETA: 5s - loss: 5.8782 - accuracy: 0.63 - ETA: 5s - loss: 5.8701 - accuracy: 0.63 - ETA: 4s - loss: 5.8866 - accuracy: 0.63 - ETA: 4s - loss: 5.8937 - accuracy: 0.63 - ETA: 4s - loss: 5.8910 - accuracy: 0.63 - ETA: 4s - loss: 5.8913 - accuracy: 0.63 - ETA: 4s - loss: 5.8954 - accuracy: 0.63 - ETA: 4s - loss: 5.8907 - accuracy: 0.63 - ETA: 4s - loss: 5.8823 - accuracy: 0.63 - ETA: 4s - loss: 5.8767 - accuracy: 0.63 - ETA: 4s - loss: 5.8905 - accuracy: 0.63 - ETA: 4s - loss: 5.8877 - accuracy: 0.63 - ETA: 4s - loss: 5.9078 - accuracy: 0.63 - ETA: 4s - loss: 5.8956 - accuracy: 0.63 - ETA: 4s - loss: 5.8901 - accuracy: 0.63 - ETA: 4s - loss: 5.8943 - accuracy: 0.63 - ETA: 4s - loss: 5.8844 - accuracy: 0.63 - ETA: 4s - loss: 5.8873 - accuracy: 0.63 - ETA: 4s - loss: 5.8828 - accuracy: 0.63 - ETA: 3s - loss: 5.8889 - accuracy: 0.63 - ETA: 3s - loss: 5.8807 - accuracy: 0.63 - ETA: 3s - loss: 5.8843 - accuracy: 0.63 - ETA: 3s - loss: 5.8840 - accuracy: 0.63 - ETA: 3s - loss: 5.8859 - accuracy: 0.63 - ETA: 3s - loss: 5.8755 - accuracy: 0.63 - ETA: 3s - loss: 5.8871 - accuracy: 0.63 - ETA: 3s - loss: 5.8791 - accuracy: 0.63 - ETA: 3s - loss: 5.8803 - accuracy: 0.63 - ETA: 3s - loss: 5.8805 - accuracy: 0.63 - ETA: 3s - loss: 5.8811 - accuracy: 0.63 - ETA: 3s - loss: 5.8809 - accuracy: 0.63 - ETA: 3s - loss: 5.8817 - accuracy: 0.63 - ETA: 3s - loss: 5.8796 - accuracy: 0.63 - ETA: 3s - loss: 5.8813 - accuracy: 0.63 - ETA: 3s - loss: 5.8915 - accuracy: 0.63 - ETA: 3s - loss: 5.9012 - accuracy: 0.63 - ETA: 2s - loss: 5.8952 - accuracy: 0.63 - ETA: 2s - loss: 5.8911 - accuracy: 0.63 - ETA: 2s - loss: 5.8916 - accuracy: 0.63 - ETA: 2s - loss: 5.8900 - accuracy: 0.63 - ETA: 2s - loss: 5.8847 - accuracy: 0.63 - ETA: 2s - loss: 5.8803 - accuracy: 0.63 - ETA: 2s - loss: 5.8742 - accuracy: 0.63 - ETA: 2s - loss: 5.8821 - accuracy: 0.63 - ETA: 2s - loss: 5.8885 - accuracy: 0.63 - ETA: 2s - loss: 5.8887 - accuracy: 0.63 - ETA: 2s - loss: 5.8905 - accuracy: 0.63 - ETA: 2s - loss: 5.8885 - accuracy: 0.63 - ETA: 2s - loss: 5.8844 - accuracy: 0.63 - ETA: 2s - loss: 5.8846 - accuracy: 0.63 - ETA: 2s - loss: 5.8827 - accuracy: 0.63 - ETA: 2s - loss: 5.8785 - accuracy: 0.63 - ETA: 2s - loss: 5.8819 - accuracy: 0.63 - ETA: 2s - loss: 5.8794 - accuracy: 0.63 - ETA: 2s - loss: 5.8730 - accuracy: 0.63 - ETA: 2s - loss: 5.8728 - accuracy: 0.63 - ETA: 1s - loss: 5.8752 - accuracy: 0.63 - ETA: 1s - loss: 5.8765 - accuracy: 0.63 - ETA: 1s - loss: 5.8774 - accuracy: 0.63 - ETA: 1s - loss: 5.8709 - accuracy: 0.63 - ETA: 1s - loss: 5.8681 - accuracy: 0.63 - ETA: 1s - loss: 5.8622 - accuracy: 0.63 - ETA: 1s - loss: 5.8633 - accuracy: 0.63 - ETA: 1s - loss: 5.8628 - accuracy: 0.63 - ETA: 1s - loss: 5.8612 - accuracy: 0.63 - ETA: 1s - loss: 5.8569 - accuracy: 0.63 - ETA: 1s - loss: 5.8572 - accuracy: 0.63 - ETA: 1s - loss: 5.8602 - accuracy: 0.63 - ETA: 1s - loss: 5.8639 - accuracy: 0.63 - ETA: 1s - loss: 5.8683 - accuracy: 0.63 - ETA: 1s - loss: 5.8675 - accuracy: 0.63 - ETA: 1s - loss: 5.8614 - accuracy: 0.63 - ETA: 1s - loss: 5.8604 - accuracy: 0.63 - ETA: 0s - loss: 5.8583 - accuracy: 0.63 - ETA: 0s - loss: 5.8598 - accuracy: 0.63 - ETA: 0s - loss: 5.8572 - accuracy: 0.63 - ETA: 0s - loss: 5.8584 - accuracy: 0.63 - ETA: 0s - loss: 5.8634 - accuracy: 0.63 - ETA: 0s - loss: 5.8597 - accuracy: 0.63 - ETA: 0s - loss: 5.8592 - accuracy: 0.63 - ETA: 0s - loss: 5.8575 - accuracy: 0.63 - ETA: 0s - loss: 5.8564 - accuracy: 0.63 - ETA: 0s - loss: 5.8568 - accuracy: 0.63 - ETA: 0s - loss: 5.8541 - accuracy: 0.63 - ETA: 0s - loss: 5.8538 - accuracy: 0.63 - ETA: 0s - loss: 5.8553 - accuracy: 0.63 - ETA: 0s - loss: 5.8541 - accuracy: 0.63 - ETA: 0s - loss: 5.8492 - accuracy: 0.63 - ETA: 0s - loss: 5.8545 - accuracy: 0.63 - 6s 86us/sample - loss: 5.8557 - accuracy: 0.6367\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000/70000 [==============================] - ETA: 9s - loss: 4.8354 - accuracy: 0.70 - ETA: 4s - loss: 5.5160 - accuracy: 0.65 - ETA: 4s - loss: 5.7551 - accuracy: 0.64 - ETA: 5s - loss: 5.8318 - accuracy: 0.63 - ETA: 4s - loss: 5.7649 - accuracy: 0.64 - ETA: 4s - loss: 5.8374 - accuracy: 0.63 - ETA: 4s - loss: 5.9350 - accuracy: 0.63 - ETA: 4s - loss: 5.8877 - accuracy: 0.63 - ETA: 4s - loss: 5.8804 - accuracy: 0.63 - ETA: 4s - loss: 5.8807 - accuracy: 0.63 - ETA: 5s - loss: 5.8693 - accuracy: 0.63 - ETA: 5s - loss: 5.8842 - accuracy: 0.63 - ETA: 5s - loss: 5.8754 - accuracy: 0.63 - ETA: 5s - loss: 5.8796 - accuracy: 0.63 - ETA: 4s - loss: 5.8611 - accuracy: 0.63 - ETA: 4s - loss: 5.8900 - accuracy: 0.63 - ETA: 4s - loss: 5.8824 - accuracy: 0.63 - ETA: 4s - loss: 5.8531 - accuracy: 0.63 - ETA: 4s - loss: 5.8313 - accuracy: 0.63 - ETA: 4s - loss: 5.8225 - accuracy: 0.63 - ETA: 4s - loss: 5.8341 - accuracy: 0.63 - ETA: 4s - loss: 5.8292 - accuracy: 0.63 - ETA: 4s - loss: 5.8159 - accuracy: 0.63 - ETA: 4s - loss: 5.8153 - accuracy: 0.63 - ETA: 4s - loss: 5.7997 - accuracy: 0.64 - ETA: 4s - loss: 5.8062 - accuracy: 0.63 - ETA: 4s - loss: 5.8016 - accuracy: 0.64 - ETA: 4s - loss: 5.8119 - accuracy: 0.63 - ETA: 4s - loss: 5.8134 - accuracy: 0.63 - ETA: 4s - loss: 5.8155 - accuracy: 0.63 - ETA: 4s - loss: 5.8236 - accuracy: 0.63 - ETA: 3s - loss: 5.8266 - accuracy: 0.63 - ETA: 3s - loss: 5.8215 - accuracy: 0.63 - ETA: 3s - loss: 5.8307 - accuracy: 0.63 - ETA: 3s - loss: 5.8120 - accuracy: 0.63 - ETA: 3s - loss: 5.7933 - accuracy: 0.64 - ETA: 3s - loss: 5.7980 - accuracy: 0.64 - ETA: 3s - loss: 5.8088 - accuracy: 0.63 - ETA: 3s - loss: 5.8110 - accuracy: 0.63 - ETA: 3s - loss: 5.8084 - accuracy: 0.63 - ETA: 3s - loss: 5.8101 - accuracy: 0.63 - ETA: 3s - loss: 5.8088 - accuracy: 0.63 - ETA: 3s - loss: 5.8127 - accuracy: 0.63 - ETA: 3s - loss: 5.8252 - accuracy: 0.63 - ETA: 3s - loss: 5.8427 - accuracy: 0.63 - ETA: 3s - loss: 5.8409 - accuracy: 0.63 - ETA: 3s - loss: 5.8552 - accuracy: 0.63 - ETA: 3s - loss: 5.8583 - accuracy: 0.63 - ETA: 3s - loss: 5.8564 - accuracy: 0.63 - ETA: 3s - loss: 5.8460 - accuracy: 0.63 - ETA: 3s - loss: 5.8517 - accuracy: 0.63 - ETA: 3s - loss: 5.8473 - accuracy: 0.63 - ETA: 2s - loss: 5.8506 - accuracy: 0.63 - ETA: 2s - loss: 5.8527 - accuracy: 0.63 - ETA: 2s - loss: 5.8490 - accuracy: 0.63 - ETA: 2s - loss: 5.8486 - accuracy: 0.63 - ETA: 2s - loss: 5.8464 - accuracy: 0.63 - ETA: 2s - loss: 5.8429 - accuracy: 0.63 - ETA: 2s - loss: 5.8498 - accuracy: 0.63 - ETA: 2s - loss: 5.8498 - accuracy: 0.63 - ETA: 2s - loss: 5.8480 - accuracy: 0.63 - ETA: 2s - loss: 5.8500 - accuracy: 0.63 - ETA: 2s - loss: 5.8608 - accuracy: 0.63 - ETA: 2s - loss: 5.8575 - accuracy: 0.63 - ETA: 2s - loss: 5.8462 - accuracy: 0.63 - ETA: 2s - loss: 5.8375 - accuracy: 0.63 - ETA: 2s - loss: 5.8434 - accuracy: 0.63 - ETA: 2s - loss: 5.8454 - accuracy: 0.63 - ETA: 2s - loss: 5.8460 - accuracy: 0.63 - ETA: 1s - loss: 5.8477 - accuracy: 0.63 - ETA: 1s - loss: 5.8458 - accuracy: 0.63 - ETA: 1s - loss: 5.8549 - accuracy: 0.63 - ETA: 1s - loss: 5.8582 - accuracy: 0.63 - ETA: 1s - loss: 5.8592 - accuracy: 0.63 - ETA: 1s - loss: 5.8592 - accuracy: 0.63 - ETA: 1s - loss: 5.8615 - accuracy: 0.63 - ETA: 1s - loss: 5.8596 - accuracy: 0.63 - ETA: 1s - loss: 5.8630 - accuracy: 0.63 - ETA: 1s - loss: 5.8642 - accuracy: 0.63 - ETA: 1s - loss: 5.8632 - accuracy: 0.63 - ETA: 1s - loss: 5.8664 - accuracy: 0.63 - ETA: 1s - loss: 5.8656 - accuracy: 0.63 - ETA: 1s - loss: 5.8620 - accuracy: 0.63 - ETA: 1s - loss: 5.8634 - accuracy: 0.63 - ETA: 1s - loss: 5.8617 - accuracy: 0.63 - ETA: 1s - loss: 5.8602 - accuracy: 0.63 - ETA: 1s - loss: 5.8615 - accuracy: 0.63 - ETA: 0s - loss: 5.8603 - accuracy: 0.63 - ETA: 0s - loss: 5.8621 - accuracy: 0.63 - ETA: 0s - loss: 5.8587 - accuracy: 0.63 - ETA: 0s - loss: 5.8568 - accuracy: 0.63 - ETA: 0s - loss: 5.8556 - accuracy: 0.63 - ETA: 0s - loss: 5.8555 - accuracy: 0.63 - ETA: 0s - loss: 5.8617 - accuracy: 0.63 - ETA: 0s - loss: 5.8644 - accuracy: 0.63 - ETA: 0s - loss: 5.8628 - accuracy: 0.63 - ETA: 0s - loss: 5.8674 - accuracy: 0.63 - ETA: 0s - loss: 5.8699 - accuracy: 0.63 - ETA: 0s - loss: 5.8657 - accuracy: 0.63 - ETA: 0s - loss: 5.8663 - accuracy: 0.63 - ETA: 0s - loss: 5.8661 - accuracy: 0.63 - ETA: 0s - loss: 5.8640 - accuracy: 0.63 - ETA: 0s - loss: 5.8682 - accuracy: 0.63 - ETA: 0s - loss: 5.8644 - accuracy: 0.63 - ETA: 0s - loss: 5.8615 - accuracy: 0.63 - ETA: 0s - loss: 5.8599 - accuracy: 0.63 - 6s 81us/sample - loss: 5.8557 - accuracy: 0.6367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1405c988>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_reco.fit(X, Y,\n",
    "                epochs=50,\n",
    "                batch_size=100,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
